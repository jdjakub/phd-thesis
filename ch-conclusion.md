\hypertarget{future-work-and-conclusions}{%
\chapter{Future Work and Conclusions}\label{future-work-and-conclusions}}

Having followed the development of BootstrapLab in Chapter\ \ref{bl} and its evaluation along the Technical Dimensions from Chapter\ \ref{tech-dims}, we now turn to the limitations of these two contributions and sketch the future work that they suggest. Some of the forthcoming points have already been introduced by necessity as part of earlier chapters, but here we have an opportunity to expand on them in more detail. We first address our Technical Dimensions framework, acknowledging the pragmatic simplifications we had to make and exploring the challenges of making it more rigorous. Subsequently, we acknowledge BootstrapLab's state as a work-in-progress, suggesting how to continue its development and apply its approach to other domains. Finally, we bring this work to a close by reviewing what we have presented and how it relates to the broader vision from Section\ \ref{how-should-things-work}.

# Improving the Technical Dimensions
In Chapter\ \ref{tech-dims}, we proposed a systematic approach to analysing programming systems that go beyond languages. We took our complex and qualitative Three Properties and derived quantitative *dimensions* to act as a proxy for them. These dimensions were narrow enough to apply to BootstrapLab. However, we were limited by scope to *argue* for the scores we gave, which is far from the everyday process of self-evident "measurement" that we ideally desire to have.

In this discussion, we will take approach of prioritising *conceptual* clarity. We will put practical issues to one side and inquire about what a rigorously perfected Technical Dimensions would look like, even if the answer would be practically infeasible to work with. Then we will add the practical concerns back in. In the end, future work consists both of improving the theoretical concepts *and* developing practical methods of using them. We note that some of the following issues were acknowledged in the Appendix of our Technical Dimensions paper\ \parencite{TechDims}. However, the discussion here should be taken to be a more updated version which supersedes that of the paper wherever they overlap.

## Scoping The Dimensions
Even if some property fails to hold for an entire programming system, it may well still hold for some part of the system. For example, take our *persistence effort* dimension from Section\ \ref{dimensions-constituting-self-sustainability} and imagine a Smalltalk-like system where everything is automatically persisted except for a single, special global called `x`. It would be unhelpful to characterise this system as having infinite persistence effort simply because it is technically impossible to persist the entire state. Informally, we see that it has *mostly* minimal persistence effort with the sole exception of `x`, for which it is infinite. This example was deliberately extreme, but a more realistic one is the Web platform whose JavaScript stack cannot be referenced or traversed by JavaScript code.

The true scope of a dimension like "persistence effort" is more of a *field* in the physical sense, defined at every atomic piece of state in the system (the *field points*). Similarly, "custom syntax effort" from Section\ \ref{dimensions-constituting-notational-freedom} is defined for individual syntaxes that a user may wish to use in the system, whether they already exist or merely potentially could exist. This highlights the additional difficulty that we may wish to characterise a system not only by how it happens to be right now, but by how it would perform across many *potential* use cases. We mentioned the complexity of considering "actual" vs. "potential" field points when defining *string wrangling effort* in Section\ \ref{dimensions-constituting-explicit-structure}; this dimension properly applies per "situation" consisting of a specific user, programming against a specific string format, in a specific program. These terms (user, string format, program created with the programming system) all invite further definition.

Making all this more precise, and establishing the minimal scope of the other dimensions we have proposed, is an open problem. As the next best option, we gave scores for BootstrapLab as a whole in Section \ref{evaluation} while elaborating on any relevant complications in prose.

## Aggregation Functions and Weights
Having realised that the dimensions apply as more of a "field", we could recover the simpler coarser-level score that we want as some sort of *aggregation* of the finer-level scores. We mentioned this in Section\ \ref{aggregation-and-simplification} to pre-empt any concerns about our simplified approach to the dimensions: in the absence of a rigorous treatment of the "scoping problem" just discussed, we were forced to do the aggregation *intuitively* based on our understanding of BootstrapLab.

Future work would consider what the aggregation function should be: a simple addition (even an integral) over scores, an average, or something else? Where *potential* field points (users, programs, notations, etc) are concerned, the infinite possibilities mean some sort of weighted aggregation would be necessary. We might compress the infinite range into a finite number of categories, one of which is a catch-all "other" category, and assign a weight for the probability or relevance of each category. This introduces a further question of how these weights are established or justified; intuitively, we know that programming systems have strengths and weaknesses and are built to cater to different problem domains or types of user, but how could this be made more rigorous? We must leave this, and the full development of the other ideas we have sketched here, as open questions.

## Defining Quantitative Measures or Resolution Criteria
So far, our concerns have been conceptual; we have been talking about hypothetical "scores" and "weights". In our evaluation of BootstrapLab, we remained at this "almost-quantitative" level: we scored using the terms "minimal", "moderate", and so on (or "present" / "absent" for boolean criteria). We justified these scores by means of argument and intuition. This is suboptimal from a research perspective; a fully developed dimensions framework should enable researchers to agree or at least productively disagree (perhaps leading to new dimensions or definitions on which they *do* agree).

One improvement would be to further define *resolution criteria* for our score terms to the point that two parties, following the same definitions, would independently converge on the same scores. Alternatively, we might pursue *real* quantitative scores with concrete numbers. The challenge here would be avoiding the trap of properties that are easily quantifiable yet irrelevant or uninteresting. A good quantification (or set of quantified dimensions) should feel like a strict *improvement* on the qualitative description, rather than something that has lost an important feature of the qualitative description. In its absence, we would err on the side of staying with the qualitative and holding out for a future quantitative definition, instead of committing to the suboptimal quantitive definition for the sake of having numbers at all.

## Obtaining Consensus on Scores
Even with narrow, precise definitions of how a dimension should be scored, it is a further task to establish consensus on *what* the score is for a given system. A perfectly crisp definition would be followed the same way by all parties and lead to the same conclusion, but we would not expect this in practice. Variations could arise from researchers interpreting terms in the definitions differently, aggregating differently over field points, or circumscribing systems differently (see the following Section\ \ref{the-circumscription-problem-of-systems}).

The point of the Technical Dimensions framework is to edge towards an *objective* analysis of programming systems, on which different researchers can readily agree. A situation where there is an implicit "subject" parameter (system S scores X along dimension D *according to person P*) may be a necessary evil in the short term, but researchers should strive to debug their disagreements and improve the dimensions to the point where the subject can be dropped.

## The Circumscription Problem of Systems
One issue that has been present throughout this dissertation, and touched on in Section\ \ref{systems-based-around-languages}, concerns what exactly we refer to with the names "Smalltalk", "Lisp", "Java", and so on. Definition\ \ref{def:programming-system} certainly helps, but there is still a lot of freedom in how we draw the boundary around named programming systems. 

For example, there are different distributions and implementations of Smalltalk, different versions of each one, and different concrete running instances used by people including different libraries and personal tweaks. We have implicitly taken "Smalltalk" to be some suitable aggregation over these, evoking what is common to all of them and smoothing over rare variations that would complicate our analyses. If one Smalltalk user modified their system to no longer be self-sustainable, this does not change the fact that the "typical" Smalltalk is self-sustainable. On the other hand, suppose we discovered a widely-used Smalltalk distribution that was deliberately diminished in this property; perhaps this should force us to drop the term "Smalltalk" and split our analysis into two systems instead. Making these points explicit and rigorous would involve similar work to the aforementioned issues with dimensions and their scoring.

We see this issue as no *worse* than the parallel in programming languages, where people routinely talk about "C++" or "Python" even though these have different implementations, versions and individual installations. However, it is slightly easier to point to the "essence" of a programming language due to its definition in terms of formal syntax and semantics, or at least an official specification by a standards body. In contrast, programming systems have more of a *de facto* existence as running software \parencite{PLrev} which invites appeals to popularity, community size, or influence as a substitute for formal or official definitions.

# Improving BootstrapLab
In Chapter\ \ref{bl} we closely and carefully followed the construction of our prototype programming system, BootstrapLab. We then evaluated it against our Three Properties (as sets of dimensions) in Section\ \ref{evaluating-bootstraplab}. While it shows promise in demonstrating the technical feasibility of custom notations and innovation feedback, its capabilities are not as impressive as we would like, owing to its early stage of development. However, this was for a worthy cause. If we had sped ahead with its development, we would have fallen into the trap we noted in Section\ \ref{self-sustainability-and-its-theory}, adding another impressive programming system to the list without any transferrable knowledge. Instead, by taking our slower approach---reflecting on how we made design and implementation decisions and making them explicit---we have contributed a *method* that is easier to understand than BootstrapLab's source code or commit history. From a position of being satisfied with this tradeoff, we can set out the next steps for BootstrapLab.

## Pay Off Substrate Debt
BootstrapLab currently sits between the final two steps of the journey, described in Sections\ \ref{pay-off-outstanding-substrate-debt}--\ref{provide-for-domain-specific-notations}. We provided isolated examples of Notational Freedom (Section\ \ref{real-example-colour-preview}) and of Self-Sustainability (evidenced by the Innovation Feedback in Figure\ \ref{fig:grey-box}). This does succeed at establishing BootstrapLab as a proof-of-concept, but to go further we would need to finish paying the "substrate debts" we incurred. These consist of porting the Masp interpreter to Assembler and the Tree Editor to Masp. Additionally, the system will inevitably need access to more and more of the functionality available in the platform such as audio, networking, and threading. These could be exposed through the substrate, as we did for graphics via the `scene` tree.

## Make Assembler More Usable
With the benefit of hindsight, we would recommend going for an instruction set that is convenient enough to *use* that immediately building programs in-system is a worthwhile endeavour. As we admitted at the end of Section\ \ref{designing-the-instruction-set}, our own wild adventure in minimality was a mistake in this regard, causing us to stay in JavaScript, implement the high-level language there and port it later. It would be interesting to see the process of gradually building each component of a high-level language engine interactively in-system. Out of the four possibilities in Section\ \ref{choosing-an-appropriate-implementation}, we chose the *platform interpreter*, so exploring the others would be illuminating---particularly the *platform compiler*, which could self-host relatively quickly.

## Alternative Implementation Strategies
It would be interesting to forego any temporary infrastructure (Section\ \ref{implement-temporary-infrastructure}) at all, or build up entirely in-system without using platform tools. This would require more careful substrate design to get this process going effectively. While it could give some insight or appreciation for the hardships of early computing, its practical value in the modern environment is unclear and may be best considered a challenge for hacker wizardry.

## Make the System Less Fragile
Because self-sustainability by definition exposes core infrastructure to potential user modification, the risks from mistakes or bugs are magnified. Smalltalk is famously capable of executing the code `true become: false` which results in it breaking. We encountered an instance of this class of issue in BootstrapLab. In the process of replacing a keyboard handler in-system, we typed a small change which immediately took effect. This edit was supposed to be only a part of a larger change, which in hindsight should have been committed to the system atomically. Because it was applied immediately, the new keyboard handler effectively became an incomplete function and typing was no longer possible.

This highlights the need, in any practical realisation of self-sustainability, for "guardrails" securing accidental changes to core infrastructure or "versioning" that allows changes to be directed at "the next version of the system" and applied atomically. This complements the COLA authors' recommendation\ \parencite[p. 23]{COLAs} for stable "points of reference" in a system in which everything is flexible and homogenous, which would likely be disorienting for a newcomer accustomed to traditional programming.

## Import From Related Work
To reduce the custom syntax, language and notation effort from its present score of "moderate", we would seek to learn from the approaches of OMeta\ \parencite{OMeta} Eco\ \parencite{Eco} and MPS\ \parencite{MPS}, particularly as regards implementation (since we already agree that their end-results are desirable). Similarly for self-sustainability, we would like to build COLA's object model\ \parencite{OROM} in the graphical substrate of BootstrapLab^[We already built the object model in a different system \parencite{CCS20}, but its shortcomings motivated the approach we took in BootstrapLab instead.]  and see if we can implement the COLA design that way.

\tomas{Possibly draw a diagram of what are all the things that have to match? Like code-data in substrate, substrate-highLevelLanguage etc.}

## Bootstrap on Other Platforms and Substrates
At every step of the development journey, there were choice points where we naturally could only move forward with one of the options. Future work could explore the other branches. We cannot provide an exhaustive listing here, but will give some examples.

At the first step (Choose A Platform), all sorts of other platforms could be chosen. While COLA built on top of one "slice" of Unix---files, build tools and process memory---we see another possibility in focusing on the hierarchical *file system* as a state model to inherit through to a substrate. This is one obvious *structured* substrate lurking within Unix and some of our work here is no doubt applicable to it: directories act as maps, filenames as keys and file contents as values. Symlinks could add graph structure to this tree where needed. Similar ideas can found in the Hull design \parencite{Hull}.

We acknowledge that it might feel perverse to have files contain "primitive" values, such as a single number, or to represent instructions as directory trees, since files are normally used as "large" objects. However, it must be noted that there is precedent for using them more generally for data large and small, such as in Plan 9\ \parencite{Plan9} and `procfs`\ \parencite{PAF}. If this was still too much to stomach, the default option for "code" (shell scripts) could simply be inherited on the understanding that this would impose a dependency on implicitly-structured text at the core of the system. What is most unclear is how graphics would be displayed and interacted with---possibly requiring a special binary as part of the substrate, for opening and synchronising a main window.

Supposing we keep our chosen web-based platform, we could still consider alternative substrates. One possibility is inheriting the DOM as the state model. This is the choice made by Webstrates\ \parencite{Webstrates}, which stores textual JavaScript code for programmatic change. Following our approach, we might want a lower-level and structured instruction set instead. This would, at the very least, need to be capable of changing parent/child/sibling relationships, node attributes, and inner textual content. One warning is that the rest of the DOM API that would need to be exposed, in order to be able to produce a functional modern web page or web app, is somewhat daunting in scope. It would also be necessary to have some way of listening for changes to DOM nodes so that any constraints can be maintained or dependencies can be updated. Webstrates does provide synchronisation between networked clients on the same page, so perhaps its methods could be adapted.

\joel{
We believe that, by identifying which parts of our journey ought to be transferrable to other contexts, it should be possible to develop a *general technique* for interactively bootstrapping self-sustainable systems from any starting platform.
}

# Conclusion
We began in Chapter\ \ref{intro} with a vision of open software that can be adapted by its users without expending disproportionate work on accidental complexity. We introduced the key concept of a *programming system* along with Three Properties that would contribute to this vision: Self-Sustainability, Notational Freedom, and Explicit Structure. Our thesis was that it is possible to build a programming system with these properties on top of our chosen starting platform, the Web browser.

We then went on to establish the terms and concepts in which we would frame our work fulfilling this claim. In Chapter\ \ref{background} we defined programming systems as a generalisation of languages, giving examples of the diverse types of systems we are interested in. We then showed how the Three Properties have precedent in existing patterns and concepts. These "precursor" properties are well-adapted to a certain set of assumptions about how programming works, but do not tell us much about how to achieve the Properties in interactive, graphical systems with Explicit Structure. We categorised different sets of assumptions about how programming works as "paradigms" in Chapter\ \ref{analysis} and explained why the Batch-Mode assumptions, as inherited through Unix, make our goals more difficult. We also introduced ideas that would help us understand our task, such as the differences between low-level and minimally human-friendly state models (Section\ \ref{two-fundamentals-state-and-change}), and the basic structure of a self-sustainable system as *platform*, *substrate* and *product* (Section\ \ref{user-vs.-implementation-levels}).

With these important concepts understood, we presented our proof of the thesis statement in Chapter\ \ref{bl}: an account of the design forces and decisions involved in creating *BootstrapLab*, whose development steps are sufficiently general to act as a template for alternative paths through the design space. We then proposed *technical dimensions* in Chapter\ \ref{tech-dims} as a means to verify the extent of our Three Properties, plus more generally other properties of programming systems, and evaluated BootstrapLab using this framework.

Our efforts taught us that the process of developing a self-sustainable system roughly mirrors the historical development of programming that shaped much of how we do things today. Technology like the assembler and the compiler was born from a truly impoverished platform of flat memory, numerical instructions, printed output and rows of switches. Self-sustainable systems like Unix were gradually raised out of this primordial world, yet it still has a tendency to show through and force human minds to wrestle with it.

This work can be interpreted as a sketch of how we might build similar infrastructure on the back of modern computing environments with explicitly structured representation of data and graphical interfaces. In other words, we have opened an investigation into what programming could look like if it were *re*-bootstrapped today, not on top of flat memory, but on a richer base platform such as that provided by web technologies.

In his 1997 OOPSLA keynote "The Computer Revolution Hasn't Happened Yet"\ \parencite{CompRev}, Alan Kay hoped that future users of Squeak/Smalltalk would use it to start a virtuous cycle of innovation: "Think of how you can obsolete the damn thing by using its own mechanisms for getting the next version of itself." Twenty-six years later, the self-sustainability pioneered by Smalltalk remains as elusive as ever outside of its communities. Our hope is that through our contribution here, we have increased the range of its potential beneficiaries. We wish to empower programmers to add self-sustainability to their own preferred systems by following the steps we discovered, advancing that much further in the struggle against accidental complexity.
