\RequirePackage{silence} \WarningFilter{scrreprt}{Usage of package `titlesec'}
\WarningFilter{titlesec}{Non standard sectioning command detected}
\documentclass[ twoside,openright,titlepage,numbers=noenddot,headinclude,footinclude,cleardoublepage=empty,abstract=on,
                BCOR=5mm,paper=a4,fontsize=11pt
                ]{scrreprt}




\PassOptionsToPackage{utf8}{inputenc}
  \usepackage{inputenc}

\PassOptionsToPackage{T1}{fontenc} \usepackage{fontenc}


\PassOptionsToPackage{
  parts=false,
  drafting=false,    tocaligned=false, dottedtoc=false,  eulerchapternumbers=true, linedheaders=false,       floatperchapter=true,     eulermath=false,  beramono=true,    palatino=true,    style=classicthesis }{classicthesis}


\newcommand{\myTitle}{Achieving Self-Sustainability in Interactive Graphical Programming Systems\xspace}
\newcommand{\mySubtitle}{\xspace}
\newcommand{\myDegree}{Doctor of Philosophy (PhD)\xspace}
\newcommand{\myName}{Joel Jakubovic\xspace}
\newcommand{\myProf}{Tomas Petricek\xspace}
\newcommand{\myOtherProf}{Stefan Marr\xspace}
\newcommand{\mySupervisor}{Put name here\xspace}
\newcommand{\myFaculty}{School of Computing\xspace}
\newcommand{\myDepartment}{Computing, Engineering and Mathematical Sciences\xspace}
\newcommand{\myUni}{University of Kent\xspace}
\newcommand{\myLocation}{Canterbury, Kent\xspace}
\newcommand{\myTime}{September 2019--June 2023\xspace}
\newcommand{\myVersion}{\classicthesis}

\providecommand{\mLyX}{L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
\newcommand{\ie}{i.\,e.}
\newcommand{\Ie}{I.\,e.}
\newcommand{\eg}{e.\,g.}
\newcommand{\Eg}{E.\,g.}

\newcommand{\joel}[1]{}
\newcommand{\tomas}[1]{}
\newcommand{\tp}[1]{}
\newcommand{\note}[1]{}
\newcommand{\notes}[1]{}
\newcommand{\todo}[1]{\textbf{TODO: #1}}
\newcommand{\delete}[1]{\textbf{DELETE:}#1}
\newcommand{\naive}{na\"ive}
\newcommand{\OROM}{Id}
\newcommand{\svgel}[1]{\texttt{\textless{}#1\textgreater{}}}
\newcommand{\RTFJ}{Right Tool For The Job}
\newcommand{\URTFJ}{Use The \RTFJ}
\newcommand{\OSFA}{One-Size-Fits-All}
\newcommand{\xywh}{\texttt{x},\texttt{y},\texttt{width},\texttt{height}}
\newcommand{\criterion}{\paragraph}
\NewDocumentCommand{\rot}{O{45} O{1em} m}{\makebox[#2][l]{\rotatebox{#1}{#3}}}\newcommand{\mybox}[1]{\noindent\fbox{\parbox{\textwidth}{#1}}}
\providecommand{\tightlist}{}\newenvironment{longtable}[2]{\begin{tabular}}{\end{tabular}}
\newenvironment{head}{}{}


\usepackage[shortcuts]{extdash}
\hyphenation{self\-sus-tain-abil-ity}
\hyphenation{Self\-sus-tain-abil-ity}
\hyphenation{Self\-Sus-tain-abil-ity}

\makeatletter
\AtBeginDocument{\renewcommand*{\AC@hyperlink}[2]{\begingroup
      \hypersetup{hidelinks}\hyperlink{#1}{#2}\endgroup
  }}
\makeatother



\PassOptionsToPackage{ngerman,american}{babel} \usepackage{babel}

\usepackage{csquotes}
\PassOptionsToPackage{backend=biber,bibencoding=utf8, language=auto,style=authoryear-comp, sorting=nyt, maxbibnames=10, natbib=false }{biblatex}
    \usepackage{biblatex}

\PassOptionsToPackage{fleqn}{amsmath}       \usepackage{amsmath}
\usepackage{amsthm}

\theoremstyle{definition}
\newtheorem{heuristic}{Heuristic}
\newtheorem{defn}{Definition}

\usepackage{graphicx} \graphicspath{{../../img/}}
\usepackage{scrhack} \usepackage{xspace} \PassOptionsToPackage{printonlyused,smaller}{acronym}
  \usepackage{acronym} \def\bflabel#1{{\acsfont{#1}\hfill}}
  \def\aclabelfont#1{\acsfont{#1}}

\usepackage{mathdots}
\usepackage{yhmath}
\usepackage{cancel}
\usepackage{color}
\usepackage{siunitx}
\usepackage{array}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{extarrows}
\PassOptionsToPackage{dvipsnames}{xcolor}
    \RequirePackage{xcolor} \usepackage{tikz}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}
\tikzset{every picture/.style={line width=0.75pt}} 


\usepackage{tabularx} \setlength{\extrarowheight}{3pt} \newcommand{\tableheadline}[1]{\multicolumn{1}{l}{\spacedlowsmallcaps{#1}}}
\newcommand{\myfloatalign}{\centering} \usepackage{subfig}



\usepackage{listings}
\lstset{language=[LaTeX]Tex,morekeywords={PassOptionsToPackage,selectlanguage},
  keywordstyle=\color{RoyalBlue},basicstyle=\small\ttfamily,
commentstyle=\color{Green}\ttfamily,
  stringstyle=\rmfamily,
  numbers=none,numberstyle=\scriptsize,stepnumber=5,
  numbersep=8pt,
  showstringspaces=false,
  breaklines=true,
belowcaptionskip=.75\baselineskip
}
\lstset{breaklines=true, columns=fullflexible, breakatwhitespace=true, basicstyle=\ttfamily\footnotesize}
\lstdefinelanguage{JavaScript}{
  keywords={break, case, catch, continue, debugger, default, delete, do, else,
  finally, for, function, if, in, instanceof, new, return, switch, this, throw,
  try, typeof, var, void, while, with, let, false, true},
  morecomment=[l]{//},
  morecomment=[s]{/*}{*/},
  morestring=[b]',
  morestring=[b]",
  sensitive=true
}
\lstset{
  language=JavaScript,
  numbers=none,
  columns=fullflexible,
  basicstyle=\ttfamily,
}





\usepackage{classicthesis}


\hypersetup{colorlinks=true, linktocpage=true, pdfstartpage=3, pdfstartview=FitV,breaklinks=true, pageanchor=true,pdfpagemode=UseNone, plainpages=false, bookmarksnumbered, bookmarksopen=true, bookmarksopenlevel=1,hypertexnames=true, pdfhighlight=/O,urlcolor=CTurl, linkcolor=CTlink, citecolor=CTcitation, pdftitle={\myTitle},pdfauthor={\textcopyright\ \myName, \myUni, \myFaculty},pdfsubject={},pdfkeywords={},pdfcreator={pdfLaTeX},pdfproducer={LaTeX with hyperref and classicthesis}}


\makeatletter
\@ifpackageloaded{babel}{\addto\extrasamerican{\renewcommand*{\figureautorefname}{Figure}\renewcommand*{\tableautorefname}{Table}\renewcommand*{\partautorefname}{Part}\renewcommand*{\chapterautorefname}{Chapter}\renewcommand*{\sectionautorefname}{Section}\renewcommand*{\subsectionautorefname}{Section}\renewcommand*{\subsubsectionautorefname}{Section}}\addto\extrasngerman{\renewcommand*{\paragraphautorefname}{Absatz}\renewcommand*{\subparagraphautorefname}{Unterabsatz}\renewcommand*{\footnoteautorefname}{Fu\"snote}\renewcommand*{\FancyVerbLineautorefname}{Zeile}\renewcommand*{\theoremautorefname}{Theorem}\renewcommand*{\appendixautorefname}{Anhang}\renewcommand*{\equationautorefname}{Gleichung}\renewcommand*{\itemautorefname}{Punkt}}\providecommand{\subfigureautorefname}{\figureautorefname}}{\relax}
\makeatother


\listfiles







\usepackage{changepage} \usepackage{pdfpages}  
\addbibresource{../thesis.bib}
\addbibresource[label=ownpubs]{OwnPublications.bib}



\begin{document}
\frenchspacing
\raggedbottom
\selectlanguage{american} \pagenumbering{roman}
\pagestyle{plain}
\clearpage{}\thispagestyle{empty}
\begin{center}
    \spacedlowsmallcaps{\myName} \\ \medskip

    \begingroup
        \color{CTtitle}\spacedallcaps{\myTitle}
    \endgroup
\end{center}
\clearpage{}
\clearpage{}\begin{titlepage}
\begin{addmargin}[-1cm]{-3cm}
    \begin{center}
        \large

        \hfill

        \vfill

        \begingroup
            \color{CTtitle}\spacedallcaps{\myTitle} \\ \bigskip
        \endgroup

        \spacedlowsmallcaps{\myName}

        \joel{
        \vfill

        \includegraphics[width=6cm]{gfx/TFZsuperellipse_bw} \\ \medskip
        }

\medskip
        A Dissertation Submitted for the Title of\\
        \myDegree \\
        \medskip
        \myDepartment \\
        \myFaculty \\
        \myUni \\ \bigskip

        \myTime 

        \vfill

    \end{center}
  \end{addmargin}
\end{titlepage}
\clearpage{}
\clearpage{}\thispagestyle{empty}

\hfill

\vfill

\noindent\myName: \textit{\myTitle,} \mySubtitle, \textcopyright\ \myTime

\bigskip

\noindent\spacedlowsmallcaps{Supervisors}: \\
\myProf \\
\myOtherProf \\
\medskip

\noindent\spacedlowsmallcaps{Location}: \\
\myLocation

\medskip

\noindent\spacedlowsmallcaps{Time Frame}: \\
\myTime
\clearpage{}
\cleardoublepage\clearpage{}\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}
\joel{https://plg.uwaterloo.ca/~migod/research/beckOOPSLA.html
problem
why it's a problem
startling sentence
implications
}

Programming is fraught with accidental complexity. Software, including
tools used for programming, is inflexible and hard to adapt to one's
specific problem context. Programming tools do not support
\emph{Notational Freedom,} so programmers must waste cognitive effort
expressing ideas in suboptimal notations. They must also work around
problems caused by a reliance on plain text representations instead of
\emph{Explicit Structure.}

The idea of a \emph{Self-Sustainable} programming system, open to
adaptation by its users, promises a way out of these accidental
complexities. However, the principles underlying such a property are
poorly documented, as are methods for practically achieving it in
harmony with Notational Freedom and Explicit Structure. We trace the
causes of this difficulty and use them to inform our construction of a
prototype self-sustainable system. By carefully reflecting on the steps
involved in our specific case, we provide insight into how
self-sustainability can be achieved in general, and thus how a motivated
programmer can escape the aforementioned sources of accidental
complexity.

\joel{One must translate ideas into suboptimal notations, work around problems created by plain text representations, and invest disproportionate effort to remove these accidental complexities on a case-by-case basis. }
 
\vfill

\endgroup

\vfill
\clearpage{}
\cleardoublepage\clearpage{}\pdfbookmark[1]{Publications}{publications}
\chapter*{Publications}\
Some ideas presented in this dissertation have appeared previously in the following publications:



\begin{refsection}[ownpubs]
    \small
    \nocite{*} \printbibliography[heading=none]
\end{refsection}

\joel{
\emph{Attention}: This requires a separate run of \texttt{bibtex} for your \texttt{refsection}, \eg, \texttt{ClassicThesis1-blx} for this file. You might also use \texttt{biber} as the backend for \texttt{biblatex}. See also \url{http://tex.stackexchange.com/questions/128196/problem-with-refsection}.
}
\clearpage{}
\cleardoublepage\clearpage{}\pdfbookmark[1]{Acknowledgments}{acknowledgments}

\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax
\chapter*{Acknowledgments}
I first wish to thank Tomas Petricek for enthusiastically supporting
this work and my research interests and giving detailed critical
feedback on publications. I'm particularly grateful for his continued
and undiminished supervision after his departure from my institution. I
also thank Stefan Marr for his supervision and for his feedback on
papers, talks, and this dissertation.

Jonathan Edwards' collaboration on the formidable \emph{Technical
Dimensions} paper was indispensable and his presence in regular video
calls has been welcome during many difficult periods of writing. I must
thank Richard Gabriel for shepherding its 2021 submission to
\href{https://www.hillside.net/plop/2021/index.php?nav=PLoP21}{Pattern
Languages of Programming} and thank the participants of the Writers'
Workshop for their feedback, as well as others who proofread or
otherwise gave input on the ideas at different stages. These include
Luke Church, Filipe Correia, Thomas Green, Brian Hempel, Clemens
Klokmose, Geoffery Litt, Mariana Mărășoiu, Michael Weiss, and Rebecca
and Allen Wirfs-Brock. I also thank the attendees of our Programming
2021
\href{https://2021.programming-conference.org/track/programming-2021-conversation-starters}{Conversation
Starters} and the 2022
\href{https://2022.programming-conference.org/home/mops-2022}{MOPS}
workshop.

I must express my gratitude to the
\href{https://futureofcoding.org/}{Future of Coding} Slack channel for
making me aware of Tomas' PhD opportunity in late 2018, and to Anil
Madhavapeddy and Antranig Basman for writing my reference letters. I
also thank Antranig for feedback on papers and countless stimulating
discussions on subjects related and unrelated to this work. I've
similarly enjoyed correspondence with Stephen Kell and Hamish Todd on
all sorts of interesting subjects that intersect with this one.

Thanks to all those who worked at \href{https://vpri.org/}{VPRI}; as an
undergraduate, the STEPS project reassured me that the unclear
frustrations about programming I was having were actually legitimate
after all. Particular thanks go to Ian Piumarta for the \acs{COLA} work
that inspired me so much; I hope this dissertation is a worthy step
towards its vision. I would be remiss not to mention Dan Cook, whose
shared interest in these themes through 2018 was a strong motivator for
my embarking on this journey. Whenever I began to doubt my goals, I'd
re-read his lucid explanations\footnote{\url{https://www.cemetech.net/forum/viewtopic.php?p=270092\#270092}}
and remember that they did make sense after all.

At this point, my mind is inexorably drawn to a crossed-out name in one
of the dissertations in the School's collection. I shall restore balance
to the cosmos by expressing my appreciation for Daria's love and support
during my research, and for our continued friendship since going our
separate ways. Let me also thank my family, office colleagues and anyone
who has slipped my mind for their company along this most challenging of
my accomplishments.
 
\endgroup
\clearpage{}
\cleardoublepage\clearpage{}\pagestyle{scrheadings}
\pdfbookmark[1]{\contentsname}{tableofcontents}
\setcounter{tocdepth}{2} \setcounter{secnumdepth}{3} \manualmark
\markboth{\spacedlowsmallcaps{\contentsname}}{\spacedlowsmallcaps{\contentsname}}
\tableofcontents
\automark[section]{chapter}
\renewcommand{\chaptermark}[1]{\markboth{\spacedlowsmallcaps{#1}}{\spacedlowsmallcaps{#1}}}
\renewcommand{\sectionmark}[1]{\markright{\textsc{\thesection}\enspace\spacedlowsmallcaps{#1}}}
\clearpage
\begingroup
    \let\clearpage\relax
    \let\cleardoublepage\relax
\pdfbookmark[1]{\listfigurename}{lof}
    \listoffigures

    \vspace{8ex}

\pdfbookmark[1]{\listtablename}{lot}
    \listoftables

    \vspace{8ex}
    \newpage





\pdfbookmark[1]{Acronyms}{acronyms}
    \markboth{\spacedlowsmallcaps{Acronyms}}{\spacedlowsmallcaps{Acronyms}}
    \chapter*{Acronyms}
    \begin{acronym}[UMLX]
        \acro{DOM}{Document Object Model}
        \acro{API}{Application Programming Interface}
        \acro{COLA}{Combined Object Lambda Architecture}
        \acro{JS}{JavaScript}
        \acro{DSL}{Domain-Specific Language}
        \acro{MSL}{Mood-Specific Language}
        \acro{UI}{User Interface}
        \acro{GUI}{Graphical User Interface}
        \acro{IDE}{Integrated Development Environment}
        \acro{OS}{Operating System}
        \acro{REPL}{Read-Eval-Print Loop}
        \acro{RISC}{Reduced Instruction Set Computing}
        \acro{CISC}{Complex Instruction Set Computing}
    \end{acronym}

\endgroup
\clearpage{}
\cleardoublepage
\pagestyle{scrheadings}
\pagenumbering{arabic}
\cleardoublepage
\clearpage{}\hypertarget{intro}{\chapter{Introduction}\label{intro}}

\note{in html/dom - you can open object browser and edit user interface, but this does not work for editing code in the same way - that is bulk JS with some substrings you would have to edit; what if everything was visible accessible (shareable) and editable, including structured code?

if I want to draw GUI, I can either write code or use GUI editor like VB or Hypercard - but the GUIs exist as separate to the programming system - could they be integrated like DSLs?

third - maybe COLA or Smalltalk - do self-sustainability but not quite.

Capabilities:
* Create (author) static content. static authoring. Hc, St
* Create (author) dynamic content. dynamic authoring. Hc, St
* Make a small change without having to restart the world. (self-sus) pokeability
* Change structural state without having to re-build the structure. (parsing bad) static pokeability. Hc St Web
* Change behavioural state without having to re-build the behaviour. dynamic pokeability Hc St
* Domain-specific notations. COLA

1. what is your quest - for a non-computer person
2. many pieces of the puzzle exist - web, hypercard, smalltalk
3. why hasn't anyone done this? PL paradigm is wrong - we need systems
4. systems allow better thinking! here is more specifically what I'm working on
}

When we have an idea for some computer software, and try to make this
idea a reality, we are forced to confront two types of complexity: the
\emph{essential} and the \emph{accidental}. We know there is ``no such
thing as a free lunch'', so we are able to accept the burden of whatever
complexity is actually intrinsic to our idea. If we have a simple idea,
we are prepared to do a little work; if it is more ambitious, we will
accept having to do more work. This \emph{essential} complexity is often
swamped by unwelcome incursions of tedious busy-work. Concepts that
appear simple must be spelled out in great detail for a computer. This
is the \emph{accidental complexity} that is widespread in programming
\parencite{MMM}.

This is particularly egregious when the ``idea'' is merely to change or
fix some small issue. Suppose we are using an app where the text is hard
to read owing to a similar background colour. The designers have not
included a feature for changing the colour of UI elements. A programmer
would know that there must be some API being called to render the
background. This API will receive the colour from a few numbers in the
app's memory. If only we could find these numbers and change them, we
would be able to read the text.

What, therefore, does it take to find and change a colour? The app
itself provides no way to proceed through its surface interface to its
internal mechanisms. Thus, the accidental complexity we must face
includes working with some external tool that can open it up. We could
attach an assembly-level debugger to the app process and stare at hex
dumps for a long time, eventually figuring out which address holds the
colour. Such an expert task would take an extremely long time even for
someone with the relevant experience. It would only let us make a change
to the \emph{running} app; we would have to repeat the procedure every
time we ran the app.

Alternatively, we could hope that the app is open-source, download the
code, setup the build system, locate the relevant code, re-build the
app, and re-install it. Each of these steps is also an expert task which
would be incredibly lengthy on a novel codebase, even for experienced
programmers. Furthermore, this approach entails destroying the running
instance of the app and re-initialising it, possibly losing unsaved
work.

In the worst case, both of these approaches could be blocked; run-time
tampering could be prevented by the security policies of mobile devices,
while re-building from source cannot work without access \emph{to} that
source. Suffice to say, none of this is suitable for an average user.
Even a seasoned programmer would consider it not worth the trouble. Our
task of changing a colour, while technically possible, has a severely
\emph{disproportionate} accidental complexity cost.

In specific situations, software authors do have good reasons to
restrict access to internals. In a game, it is important to enforce the
rules; access to internals would enable arbitrary cheating. However,
this is a \emph{special case} not representative of most types of
software. Despite this, we are unable to simply \emph{choose} to build
software that is ``open''. Even if \emph{we} wrote the app and desire to
support adaptation beyond what we anticipated, we face the fact that our
tools can only create software that is ``closed''. The task of
``supporting unanticipated modification'' is itself a \emph{feature}
that we must somehow figure out and implement on top, and it is unclear
how to achieve such a feature. Nevertheless, it is worth striving for a
world where this accidental complexity is as reduced as possible. We
might expect this to involve a mix of ``demolition'' work---that of
removing barriers that have been placed in the way---and
``construction'' work of building tools that help us work more
effectively.

\hypertarget{how-should-things-work}{\section{How Should Things Work?}\label{how-should-things-work}}

Imagine a world where the average computer user can patch or improve
their software the same way they might change a lightbulb or perform DIY
in their home. This clearly relies on the ability to make small
\emph{piecemeal} changes to their home, without having to demolish the
place and re-build it anew. We will call this \emph{naïve pokeability}:

\begin{defn}[Naïve pokeability]
\label{def:naive-pokeability}
A change has \emph{naïve pokeability} if it is possible to make the change while the software is \emph{running} without having to consider the implications of restarting it.
\end{defn}

Furthermore, the common-sense expectation is that the changes
\emph{persist} into the future:

\begin{defn}[Persistent]
\label{def:persistent}
The result of a change is \emph{persistent} if it remains until a future change overrides its effect.
\end{defn}

\begin{defn}[Transient]
\label{def:transient}
A change is \emph{transient} if, in the absence of special measures, it will be undone within a short timeframe and its effects will not last.
\end{defn}

Additionally, the tools for making changes are of an appropriate scale
and reside within the system. Changes are \emph{self-supplied} and, if
this covers all possible changes, we have a \emph{self-sustainable}
environment.

\begin{defn}[Self-supplied]
\label{def:self-supplied}
A change is \emph{self-supplied} by a piece of software if you can achieve the change by only using the software.
\end{defn}

\begin{defn}[Self-sustainable]
\label{def:self-sustainable}
A software system is \emph{self-sustainable} if arbitrary changes to it are self-supplied.
\end{defn}

The ideal system functions like a workshop where new tools can be
fashioned using existing tools as needed. They can be big or small, and
this ensures that we can use the ``right tool for the job'', no matter
the scale.

\begin{defn}[\RTFJ]
\label{def:right-tool}
This is a principle in programming which acknowledges that tools have differing strengths and weaknesses for different tasks. To ``\URTFJ'' is an ideal that relies on either an \emph{existing} range from which to select the best tool, or the capacity to design and build it on-demand.
\end{defn}

\begin{defn}[One-Size-Fits-All]
\label{def:osfa}
The opposite of ``\URTFJ''. This refers to using a single tool to do a wide range of tasks even though it may not be suited for some of them.
\end{defn}

\begin{defn}[Domain-Specific Adaptation]
\label{def:dsa}
This is a small or large part of a software system which provides its own custom interface for change.
\end{defn}

In standard practice, a program is generated from \emph{source code} and
put into a running state. To change the program, one must change the
source code, destroy the program and re-create it anew. These steps are
accomplished with separate tools, meaning that changes tend not to be
self-supplied (Definition~\ref{def:self-supplied}).

There is a limited notion of ``\URTFJ'' in that there are different
programming languages. However, languages tend to enforce their syntax
and semantics without permitting \emph{smaller-scale} adaptation, and
variation in these respects is normally restricted to textual notations.
Furthermore, some situations may call for more general \emph{notations}
or graphical interfaces that do not work like a language, but the fact
that programming is optimised for languages makes using such notations
more difficult.

Instead of the above, computer software should act as ``Personal Dynamic
Media'' \parencite{PersonalDynMedia}. In this vision, a software system
is \emph{designed} to be adapted and modified by its users. By
performing an explicit action (\eg{} switching to ``edit mode'') the
user can inspect the visible surface of the application to find the
causes of its appearance in the form of code and data. They can also
inspect a map of the non-visible implementation of the software's
functionality and navigate to the relevant parts. There may be a common
programming notation as a default, but where possible, parts of the
implementation are presented in local notations or interfaces that are
more easily understood. These interfaces can also be traced to
\emph{their} implementations and modified if desired. The user can then
change any aspect of the software while it is running, without having to
edit an external specification and destroy the running instance.

\hypertarget{a-fragmented-vision}{\section{A Fragmented Vision}\label{a-fragmented-vision}}

Several pieces of this vision do exist, but not in an integrated whole.
We can see some of the different characteristics we desire in software
by examining the Web browser, HyperCard, and Smalltalk.

\hypertarget{web-pages-web-apps-and-browsers}{\subsection{Web pages, web apps, and
browsers}\label{web-pages-web-apps-and-browsers}}

The \emph{web browser} has a powerful set of \emph{developer tools}
(Figure~\ref{fig:web-dev-tools}). This includes the ``inspector'' which
can be used to edit the page's underlying elements in the \ac{DOM}. For
example, an ad can be removed by locating and deleting its element. Some
of this underlying ``state'' may have no visual effects (\eg{} an
element's ID attribute) and is thus hidden from an ordinary user.
However, such state \emph{is} visible from the inspector in the
developer tools. This means that all of the ``structural'' state of a
page is \emph{potentially} visible, not to mention editable, in the web
browser.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{web-dev-tools.png}
\caption[Web Developer Tools]{The Developer Tools available for any Web page or app in a modern browser.}
\label{fig:web-dev-tools}
\end{figure}

The above is worth contrasting with the case of the ``behavioural'' side
of a web page oriented around the \ac{JS} programming language.
Alongside the ``structural'' state of the web page, there is also the
hidden state of \ac{JS} objects. The \ac{JS} console accepts commands
which may read or change this state, but there is nothing like the
element inspector for it.\footnote{This may be because the \ac{DOM} is a
  tree structure while the \ac{JS} state is a general graph, and it's
  harder to build an editor for the latter.} What \emph{is} visible in
the dev tools is the \emph{source code} of the scripts loaded by the
page.

Many changes to the ``behavioural'' state can be accomplished in the
console; for example, updating part of the state to a new object.
However, this cannot be relied upon in the same way as \ac{DOM} editing
because \ac{JS} language features prohibit many changes. For example, a
variable declared in the source as \texttt{const} will not be changeable
in the console. Moreover, fine-grained changes to code cannot be
performed there either. The main unit of code organisation, the
\texttt{function}, is an opaque object in the runtime environment; one
cannot simply replace a particular line or expression within it.
Instead, a complete new definition must be entered into the console to
replace it wholesale. Yet even this will fail if the source declares the
function \texttt{const}. In such cases, we lack \emph{naïve pokeability}
(Definition~\ref{def:naive-pokeability}) and we have no choice but to
edit the source files somehow. If the browser does not provide for local
edits to be made to these files, a separate text editor must be used.
The changes made in this way will only take effect once the scripts are
reloaded by refreshing the page and losing its \ac{JS} state.

Let us return to the ``structural'' state of the web page and note that
we are free to make arbitrarily fine-grained changes using the element
inspector. These changes take effect immediately without having to reset
anything. There are, in fact, HTML text files backing the page
structure, but they cannot restrict the inspector tool in the way
\ac{JS} files restrict the console. In short, the \emph{state} of a web
page has naïve pokeability while its dynamic \emph{behaviour} does not
reliably have this property.

There is one caveat: the HTML and \ac{JS} files are the ``ground
truth'', so any changes made via the inspector or the console will
disappear when the page is closed or refreshed. Changes made in the
browser are \emph{transient} (Definition~\ref{def:transient}); only
changes to the underlying files are \emph{persistent}
(Definition~\ref{def:persistent}), and websites typically do not allow
unknown individuals to change the files on their servers. All this is
sad news for our user deleting their ad, as they will have to repeat it
each time they access the page (or more realistically, use sophisticated
programmatic middleware like an ad-blocking extension to make this
automatic).

\hypertarget{hypercard}{\subsection{HyperCard}\label{hypercard}}

Before the Web, ``hypertext'' was regularly created and distributed by
people in the form of HyperCard stacks. Alan Kay criticised the web for
having a browser that doesn't include an \emph{authoring} tool,
instantly limiting the \emph{creation} of web pages to people who can
code in a text editor. In HyperCard, the viewer and editor exist
integrated together (Figure~\ref{fig:hypercard}). Furthermore, there is
an ``edit'' mode whereby a user can remix content from someone else,
even reprogramming the dynamic behaviour.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{hypercard.jpg}
\caption[HyperCard]{HyperCard, a pre-Web Hypertext system, included a direct authoring tool to complement the browser.}
\label{fig:hypercard}
\end{figure}

These aspects of HyperCard's design encouraged a community of
producer-consumers for hypertext content. The web's higher cost of
authoring led to a lower producer-to-consumer ratio, restricting the
kind of medium that it would become. Note that the naïve pokeability of
the element inspector does not amount to \emph{authoring} a web page;
such an interface is designed for fine-grained \emph{change} rather than
coarse-grained creation. It is also oriented towards programmers, being
part of the ``developer tools'', compared to HyperCard's presentation of
authoring as a primary use of the software.

\hypertarget{smalltalk-and}{\subsection{\texorpdfstring{Smalltalk and
\acs{COLA}}{Smalltalk and }}\label{smalltalk-and}}

Smalltalk provides for behaviour editing at a finer granularity than the
Web developer tools. Behaviour is separated first by class and then by
method; only then is a text editor presented for the code
(Figure~\ref{fig:pharo}). More importantly, changes to this code take
effect once committed, with no ``restarting'' of the system taking
place. The state of the system is persisted by default to an ``image''
file. In short, Smalltalk provides persistent naïve pokeability for both
code and data.

\begin{figure}
\centering
\includegraphics[width=\linewidth]{pharo.png}
\caption[Pharo class browser]{The class browser in the \emph{Pharo} distribution of Smalltalk.}
\label{fig:pharo}
\end{figure}

That being said, Smalltalk systems tend to run on VMs that are
implemented in a separate lower-level language like C++. Fundamental
infrastructure such as object layout and memory management is available
only as opaque primitives from the point of view of Smalltalk. Thus, to
change these aspects one must still switch to a different programming
system and re-compile.

Going further in the same direction as Smalltalk is the \acl{COLA} or
\acs{COLA} \acused{COLA} \parencite{COLAs}. \ac{COLA} makes said basic
infrastructure self-supplied (Definition~\ref{def:self-supplied}) so as
to approximate a truly self-sustainable system. It is also designed to
encourage domain-specific adaptations (Definition~\ref{def:dsa}) down to
a small scale of ``\acp{MSL}'' beyond the coarse-grained variation found
with ordinary programming languages. However, the architecture as
described does not have much to say about the user interface or
graphics, taking place instead in the world of batch-mode
transformations of streams.

\joel{
## The Missing Synthesis

We have given the above examples because they demonstrate some of our ideals from Section\ \ref{how-should-things-work}. Web browsers and Smalltalk exhibit GUIs with the potential for domain-specific graphical adaptation (Web, Smalltalk)
2. Reliable, persistent naïve pokeability of state and behaviour (Smalltalk, COLA)
3. Full self-sustainability with domain-specific languages (COLA)

Why has a synthesis of all three not been achieved? Part of the difficulty is that programming is framed in terms of *languages* with a focus on parsed syntax and batch-mode transformations. This makes it an uphill battle to achieve even one of these three properties. 
}

\hypertarget{accidental-complexity-beyond-languages}{\section{Accidental Complexity Beyond
Languages}\label{accidental-complexity-beyond-languages}}

In our experience, the three most important sources of accidental
complexity in programming are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In order to make even a small change to a program, we must go to the
  source code which may require an entirely different language and way
  of thinking. We lack \emph{Self-Sustainability.}
\item
  We must describe graphical constructs with language in order to fit
  them into program code. This represents a lack of what we will soon
  define as \emph{Notational Freedom.}
\item
  We have to avoid syntax errors, escape certain characters, and write
  code for parsing and serialising. This represents a lack of what we
  will soon define as \emph{Explicit Structure.}
\end{enumerate}

These are not quite observations about programming \emph{languages.}
Instead, they concern the wider environment of tools in which
programming is performed, such as the editor interface and facilities
for running the programs.

It is important not to conflate ``coding'' in a programming language
with programming itself. In this dissertation, we see \emph{programming}
as the general act of making a computer do things by itself. By this
definition, coding, visual programming, programming by example, and deep
learning are some specific \emph{means} by which to program. If we
ignore this subtlety, we risk unwittingly limiting the scope of
innovative ideas in the following ways:

\begin{figure}
\centering
\includegraphics[width=\linewidth]{spreadsheet.png}
\caption[Spreadsheet interface]{A spreadsheet contains text, but is not a \emph{syntax} or a \emph{language}; the grid lines are intrinsically graphical.}
\label{fig:spreadsheet}
\end{figure}

\begin{itemize}
\tightlist
\item
  Instead of seeking the right notation, interface or representation for
  the job, we might seek the right \emph{textual syntax} for the job. If
  we cannot find one, the real reason may simply be that text is not
  well-suited to the job (Figure~\ref{fig:spreadsheet}). Yet if text is
  all we know, we will be under the false impression that it is an
  \emph{intrinsically} hard job.
\item
  Instead of being able to make changes to a \emph{running} program, we
  are stuck changing its source code and re-creating the program. It is
  easy to make ``closed'' programs this way and hard to make programs
  open to ``re-programming'' while running.
\item
  Instead of seeking a software \emph{system} open to unanticipated
  changes as it runs, we might seek intricate \emph{language} features
  that give flexibility only for \emph{compiling} a program.
\end{itemize}

A key problem is that there is no established term for this scope of
programming research, and hence no body of work in which we may situate
it. This is the crux of the matter: we need a more general programming
\emph{systems} approach instead. We will discuss this further in
Chapter~\ref{analysis} and use it in Chapter~\ref{tech-dims} to propose
a systematic framework by which to analyse programming systems. This
framework will include three properties that are central to the
dissertation and develop them in detail. We will now familiarise the
reader with the basic outline of these three properties.

\hypertarget{the-three-properties}{\section{The Three Properties}\label{the-three-properties}}

The goal at the end of Section~\ref{how-should-things-work} is much too
ambitious a scope to achieve in this dissertation. However, from
Definitions~\ref{def:naive-pokeability}--\ref{def:dsa} and the above
discussion, we distill three properties that help address the issues we
identified. They are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Self-sustainability:} being able to evolve and re-program a
  system, using itself, while it is running. (This is a more intuitive
  definition that agrees with what we said earlier in
  Definition~\ref{def:self-sustainable}.)
\item
  \emph{Notational Freedom:} being free to use any notation as desired
  to create any part of a program, at no additional cost beyond that
  required to implement the notation itself.
\item
  \emph{Explicit Structure:} being able to work with data structures
  directly, unencumbered by the complexities of parsing and serialising
  strings.
\end{enumerate}

\hypertarget{importance-of-the-three-properties}{\subsection{Importance of the Three
Properties}\label{importance-of-the-three-properties}}

We are interested in exploring, developing, and achieving the Three
Properties in programming systems. We will refine and expand these
definitions in later chapters, but they are reasonable to start with.
Each one brings its own advantages to a programming system:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Self-sustainability reduces the accidental complexity of having to
  make changes using a separate, unfamiliar programming system. It also
  permits \emph{innovation feedback:} anything helpful created using the
  system can benefit not only other programs sitting atop the system,
  but also the system's own development.
\item
  Notational Freedom makes it easier to use the ``\RTFJ''
  (Definition~\ref{def:right-tool}). Once a programmer has decided what
  the right tool is in their specific context, Notational Freedom means
  they can use such a tool more easily as a Domain-Specifc Adaptation
  (Definition~\ref{def:dsa}). For example, if diagrams are desired,
  Notational Freedom removes the traditional limitation to use ASCII
  art. More generally, Notational Freedom removes the need to describe
  graphical constructs using language.
\item
  Explicit Structure avoids various pitfalls of strings, both in terms
  of correctness and convenience. Consumers of a structure benefit from
  an editor that can only save valid structures, and producers benefit
  by discovering errors early instead of later during consumption.
  Writing programs to use such structures is improved if one does not
  have to maintain code for parsing and serialising or think about
  escaping special characters.
\end{enumerate}

These properties are exhibited occasionally in different systems, as we
will mention in Chapters \ref{background} and~\ref{analysis}. However,
it is rare to see two or all three present in the same system. This
rarity suggests they are probably under-explored and under-developed, so
we could stand to learn a lot by studying them. We do not doubt that
these properties have drawbacks in addition to the above advantages, but
we stand to gain from these advantages taking us closer to the ideal at
the end of Section~\ref{how-should-things-work}.

\hypertarget{the-three-properties-in-combination}{\subsection{The Three Properties in
Combination}\label{the-three-properties-in-combination}}

It is worth exploring the Three Properties in \emph{combination} because
they complement each other in the following ways.

Suppose a system already has Notational Freedom. Self-Sustainability
makes it easier to add new notations to it. In the converse case of a
system lacking Notational Freedom, Self-Sustainability makes it easier
to add Notational Freedom \emph{itself} and lets the benefits flow into
all aspects of the system's development; this is what we called
\emph{innovation feedback}.

Notational Freedom is impossible to achieve without Explicit Structure.
In a world of parsed strings and text editors, we are limited to what we
will term \emph{syntactic} freedom in Section~\ref{notational-freedom}.
Thus, Notational Freedom needs Explicit Structure as a necessary
foundation.

Self-Sustainability also suffers without Explicit Structure.
Self-Sustain-ability is vaguely understood by analogy to self-hosting
compilers, as we will see in
Section~\ref{precursors-of-self-sustainability}. The \ac{COLA}
work~\parencite{COLAs} follows this approach, remaining unclear on how
such a property can be achieved in interactive, graphical systems.
Explicit Structure lets us study the other two Properties more purely,
without getting confused by the accidental complexities of parsing and
escaping (we will expand on this in
Section~\ref{we-study-the-spherical-cow}).

We can prioritise the Three Properties based on the above
inter-dependencies. Our primary goal is to explore Notational Freedom in
interactive, graphical programming systems. To support this, we should
achieve Self-Sustainability. To do both of these with minimal
distraction, we should make sure to build on a foundation of Explicit
Structure. We will not follow this order strictly, but it shows a logic
as to how each property fits into the bigger picture. We see that the
only way to discover how to achieve these goals is by \emph{doing,} so
we work to build a prototype programming system called
\emph{BootstrapLab} that makes progress on the Three Properties
simultaneously.

\hypertarget{thesis-statement-and-contributions}{\section{Thesis Statement and
Contributions}\label{thesis-statement-and-contributions}}

The statement of our thesis is as follows:

\begin{quote}
It is possible to add Notational Freedom to the web browser programming
system by embedding a Self-Sustainable system built on Explicit
Structure.
\end{quote}

Our main contribution is to prove this by construction in the form of a
prototype programming system called \emph{BootstrapLab}, which is the
topic of Chapter~\ref{bl}. This contribution involves not only
BootstrapLab itself, but also the necessary steps and principles that
its construction led us to \emph{discover.} We believe that it should be
possible to build these Three Properties atop a wide variety of
programming systems; our hope is that in Chapter~\ref{bl} we have
documented enough of a generalisable technique to make this feasible for
the average programmer. It is as if we have developed the study of
sorting by coming up with a prototype sorting algorithm---the new
clarity is the important part, while the concrete program was just the
vehicle that got us there.

Additionally, in order to assess how well BootstrapLab achieves the
Three Properties, we propose a \emph{technical dimensions} framework in
Chapter~\ref{tech-dims} for analysing programming systems, which is our
secondary contribution. BootstrapLab, being a programming system, is
then evaluated in terms of dimensions constituting the Three Properties.
We then review related work in Chapter~\ref{ch-related-work}. In
Chapter~\ref{future-work-and-conclusions} we acknowledge the limitations
revealed by our evaluation, suggest future work for both of our
contributions, and conclude with what we have learned and achieved.

\hypertarget{supporting-publications}{\section{Supporting Publications}\label{supporting-publications}}

The following essay was adapted into Chapter~\ref{bl}:

\begin{quote}
\fullcite{Onward22}
\end{quote}

The following paper won the journal's Editors' Choice Award and was
adapted into Chapter~\ref{tech-dims}:

\begin{quote}
\fullcite{TechDims}
\end{quote}

\joel{
# Imported from Convivial Salon '20
As someone who can code, I have already passed the first and most important hurdle for making full use of the potential of my computer. However, even in this supposedly empowered state, I am still far away from feeling the relationship between myself and software as between artisan and material, free to shape it into any form with effort proportional to complexity.

One would have thought that software-creation acts like hypothetical super-intelligent Artificial Intelligence (AI). That is: even though we start from a primitive base in the 50s (or even today), there would surely be a recursive process of self-improvement, building better software-creation tools with the existing ones, until an "expressivity singularity" where software becomes a workable material as described.

However, this didn't happen. Or at least, it is happening glacially slowly. The brute fact is that whenever you want to create software, you go to a text editor and figure out how to translate your design into that. The text editors, being software, were written with the help of previous text editors, and so on. It's undeniable that text editors have improved, even if you think it peaked with Emacs. We just don't seem able to go beyond them where it matters, such as visual domains ill-fitted to monospaced ASCII.

Amdahl's Law generalises the following idea: even when you spend hours of effort doubling the performance of a component used 1

\joel{My experience of coding, most of the projects requiring shapes (such as GUIs), leads me to conclude that no matter how much I improve my skill at a particular language, knowledge of libraries or even general coding ability, my predicament stays the same. Our basic method of creating software is optimised for an ever-diminishing proportion of the software we actually want to make; ill-optimised for the graphics, layout, interactivity and and basic physics---more on this later---that we usually require.}

As a programmer, I often feel stuck in a box I know I can never escape from: that box is the text editor, a fixed conduit through which all *fundamental* changes to my program must pass. It's not a part of the system I am building, so I can't even make use of features of the thing I'm developing, to make its own development easier.

Surely the trick is to *use* coding to build something *better than it*. And then use that, to build something even better. But there is an enormous breadth and depth of philosophies here, along with all sorts of concrete systems that failed to catch on. Even worse than this, is that in my very *language* here I am making the same mistake as the text editor---speaking in unqualified terms of "better" and "worse" as if there really is a \OSFA{} solution to software creation!

Of course what we *really* want is the ability for people to create *in the way that they think is best*^[To be clear: if someone *wants* to type out pictures in ASCII, let them---whether they do it for a challenge, or even if they find that more natural for themselves. But equally, if I want to do it another way, I should have that affordance.] in their particular context---to equip them to feasibly create the tools that suit them for the thing they want to make. And second-order tools that suit them for making the first-order tools, and so on. It would do no good to replace text-imperialism with anything-*else*-imperialism, which is one interpretation of calls for alternatives.

This dream goes beyond the familiar sense of what constitutes a "craft", as far as a strong melding of tool and material. Parallels can be drawn with industrialisation and a strong division of labour: the community as a whole produces its higher-order tools, but currently no single person can have the same autonomy. A (future) software craft could be expected to give this power to *individuals*, instead of the community alone. Whenever there are many small specialities (\eg{} languages, tools, or subject areas) each serving many clients, the \OSFA{} style is the best one can hope for. Adaptation to individual preferences and idiosyncrasies is only feasible when those individuals can do it themselves.

What we need is some system that not only lets us create software in a way that is "close to the problem domain" as decided by the user-developer, but also can augment or change itself to adapt to a different "way of creating". Existing systems seem to only have one of these properties without the other: Smalltalk and Lisp try to minimise arbitrary commitments of language *semantics* to this end, but their being textual languages is a fairly tough commitment to break out of. And it is not so hard to make a specific, *hard-baked* visual or alternative programming tool---but it is hard to make it re-programmable *without* having to go back to *its* textual source code.

# Imported from Onward '22

In the ordinary lifecycle of software, there is a hard separation between the _product_ and its _source_. The product may be any end-user application such as a game, and is created from the source by a _producer_, which is a compiler or other similar tool built for programmers. In this arrangement, the product's user has little ability to re-program it, beyond setting configuration parameters anticipated ahead of time. The user's only option is to modify the source (if it is available) and use the producer to create a new version of the product.

Curiously, this arrangement isn't limited to end-user products but also applies to most *programmer*-oriented products! In the ordinary programming experience, tools like the compiler or editor are themselves products with a separate source and producer. If the user of a language wants to re-program it beyond a customisation anticipated by its designer, they have to go and modify the compiler source code. If they are lucky, the compiler is also written in the same language. In this case, the user is already familiar with the language's notation and capabilities, making the task easier than learning an entirely new language. Even so, their changes still occur at a separate level from their ordinary use of the system.

In this context of programming, the separation between the product and the source is particularly lamentable, as it makes it very hard for programmers to improve their tools^[This is true in a global sense, but even more important in the sense of local adaptations for their own purposes.]. If the language ecosystem is not created using itself, a programmer's mastery of the language is worthless for adapting it. Even if they get lucky as described, the burden of getting the source code, recompiling and deploying it, and maintaining a fork would prevent many from succeeding.

An alternative to this arrangement is *self-sustainable* systems which dissolve the distinction between the product, source, and producer. A single environment provides not only for using and re-programming the *product*, but also for re-programming the *producer*, \ie{} the system itself that is used for the programming. These systems are carefully designed to avoid "baking in" any of their behaviour. Instead, they expose as much of their own implementation as possible for modification at the user level. The advantage of such an approach is that innovation and improvement in the system can feed back into its own development.

For example, consider mathematical notation. It involves many font styles and symbols as infix operators. Yet to express this in code we are limited to ASCII characters and, in many languages, prefix functional notation for custom operators. There are numerous domains where an improvement to this notation would make code easier to follow, such as rendering 3D graphics or computing text layout. If we implement a user interface for entering expressions in mathematical notation, not only would it help us program an end-user application such as a 3D game, but the same notation also becomes instantly available for our own use in-system. We could re-express parts of the code for the system's own user interface, such as its algorithms for text layout. In fact, we could even use our mathematical notation to re-implement the very user interface for the mathematical notation! This would not be the case if the end-user code existed in a different world than the programming system.

This "innovation feedback" encourages a virtuous cycle of improvement regarding notations and beyond. The same can happen when we develop better debugging and testing tools, user interface builders, provenance tracking or performance optimisations. In other words, the development of the system itself will benefit from any improvement made while using the system. This is the key advantage self-sustainable systems have over others.
}
\clearpage{}
\cleardoublepage
\clearpage{}\hypertarget{background}{\chapter{Background}\label{background}}

The relevant background we will need to acquaint ourselves with falls
into two halves: explaining the concept of a ``programming system'', and
explaining how the Three Properties tie together existing concepts in
programming. In Section~\ref{programming-systems-vs-languages}, we
define \emph{programming systems} in contrast to programming languages
and discuss why this is necessary. Then in
Section~\ref{examples-of-programming-systems}, we illustrate this with
landmark examples of programming systems from the past. Finally, in
Section~\ref{precursors-of-the-three-properties}, we survey the existing
patterns in programming that take us part of the way to the Three
Properties.

\hypertarget{programming-systems-vs-languages}{\section{Programming Systems vs
Languages}\label{programming-systems-vs-languages}}

Many forms of software have been developed to enable programming. The
classic form consists of a \emph{programming language}, a text editor to
enter source code, and a compiler to turn it into an executable program.
Instances of this form are differentiated by the syntax and semantics of
the language, along with the implementation techniques in the compiler
or runtime environment. Since the advent of \acp{GUI}, programming
languages can be found embedded within graphical environments that
increasingly define how programmers work with the language---for
instance, by directly supporting debugging or refactoring. Beyond this,
the rise of \acp{GUI} also permits diverse visual forms of programming,
including visual languages and \ac{GUI}-based end-user programming tools
(we will survey these
in~Section~\ref{novel-notations-versus-notational-freedom}).

The classic essay by \textcite{PLrev} distinguishes the \emph{languages}
and \emph{systems} paradigms in programming research. \emph{Languages}
are formal mathematical models of syntax and semantics; researchers
might ask what an expression \emph{means} and include code samples in
papers. \emph{Systems,} in contrast, are running pieces of software
whose current state changes according to the effects of program code.
Researchers studying systems are likely to be more concerned with what
code \emph{does} to a running system in a specific state instead of the
more abstract language properties.

The topic of this thesis, and many of the examples we will use to
illustrate concepts, rely on understanding this distinction and only
make sense within the systems paradigm. Therefore we shift our attention
from \emph{programming languages} to the more general notion of
``software that enables programming''---in other words,
\emph{programming systems}.

\begin{defn}[Programming System]
\label{def:programming-system}
A \emph{programming system} is an integrated and complete set of tools sufficient for creating, modifying, and executing programs. These will include notations for structuring programs and data, facilities for running and debugging programs, and interfaces for performing all of these tasks. Facilities for testing, analysis, packaging, or version control may also be present. Notations include programming languages and interfaces include text editors, but are not limited to these.
\end{defn}

A word about terminology: if we view languages in the sense of Gabriel's
``languages paradigm'', then it is a ``type error'' to include languages
in the above definition. Abstract mathematical models of syntax and
semantics are not the same as software. However, language
\emph{implementations} are software. We will use the term ``language''
to abbreviate ``language implementation'' since we do not use the other
meaning in this dissertation.

With that said, our above notion of programming system covers classic
programming languages together with their editors, debuggers, compilers,
and other tools. Yet it is intentionally broad enough to \emph{also}
accommodate image-based programming environments like Smalltalk,
operating systems like Unix, and hypermedia authoring systems like
Hypercard, in addition to various other examples we will mention next.

\hypertarget{examples-of-programming-systems}{\section{Examples of Programming
Systems}\label{examples-of-programming-systems}}

We illustrate the notion of a programming system through a number of
example systems. We are not trying to exhaustively cover all possible
systems, but simply give an impression based on major examples. We draw
them from three broad reference classes:

\begin{itemize}
\tightlist
\item
  Software ecosystems built around a text-based programming
  \emph{language}. They consist of a set of tools such as compilers,
  debuggers, and profilers. These tools may exist as separate
  command-line programs, or within an \ac{IDE}.
\item
  Those that resemble an \ac{OS} in that they structure the execution
  environment and encompass the resources of an entire machine (physical
  or virtual). They provide a common interface for communication, both
  between the user and the computer, and between programs themselves.
\item
  Programmable \emph{applications}, typically optimised for a specific
  domain, offering a limited degree of programmability which may be
  increased with newer versions.
\end{itemize}

\joel{
We will proceed to detail some systems under this grouping. This will provide an intuition for the notion of a programming system and establish a collection of go-to examples for the rest of the paper.}

\hypertarget{systems-based-around-languages}{\subsection{Systems Based Around
Languages}\label{systems-based-around-languages}}

Text-based programming languages sit within programming systems whose
boundaries are not explicitly defined. To speak of a programming system
we must include a language with, at minimum, an editor and a compiler or
interpreter.

There is wiggle room in how we choose to circumscribe these elements. Do
we mean a specific compiler version? Do we include common plugins or
extensions? Still, we would expect these choices to have enough of a
common overlap that we can proceed in analysis without worrying too much
about the variations. We will revisit this point in
Section~\ref{the-circumscription-problem-of-systems}.

\paragraph{Java with the Eclipse ecosystem.}

The Java language~\parencite{Java} alone does not form a programming
system, but it does if we consider it as embedded in an ecosystem of
tools. A minimalistic delineation would consist of a text editor to
write Java code and a command line compiler. A more realistic one is
Java as embedded in the Eclipse \ac{IDE}~\parencite{Eclipse}. The
programming systems view permits us to see whatever there may be beyond
the textual code. In the case of Eclipse, this includes the debugger,
refactoring tools, testing and modelling tools, \ac{GUI} designers, and
so on.

\paragraph{Haskell tools ecosystem.}

Haskell is another language-focused programming system. It is used
through the command-line \emph{GHC} compiler~\parencite{GHC} and
\emph{GHCi} REPL, alongside a text editor that provides features like
syntax highlighting and auto-completion. Any editor that supports the
Language Server Protocol~\parencite{LSP} will suffice to complete the
programming system.

Haskell is mathematically rooted and relies on mathematical intuition
for understanding many of its concepts. This background is also
reflected in the notations it uses. In addition to the concrete language
syntax for writing code, the ecosystem also uses an informal
mathematical notation for writing about Haskell (\eg{} in academic
papers or on the whiteboard). This provides an additional tool for
manipulating Haskell programs. Experiments on paper can provide a kind
of rapid feedback that other systems may provide through live
programming.

\paragraph{From REPLs to Computational Notebooks.}

A different kind of developer ecosystem that evolved around a
programming language is the Jupyter notebook
platform~\parencite{Jupyter}. In Jupyter, data scientists write scripts
divided into notebook cells, execute them interactively and see the
resulting data and visualisations directly in the notebook itself. This
brings together the \ac{REPL}, which dates back to conversational
implementations of Lisp in the 1960s, with literate
programming~\parencite{LiterateProg} used in the late 1980s in
Mathematica 1.0~\parencite{Mathematica}.

As a programming system representative of Computational
Notebooks~\parencite{CompNotebooks}, Jupyter has several interesting
characteristics. The primary outcome of programming is the notebook
itself, rather than a separate application to be compiled and run. The
code lives in a document format, interleaved with other notations. Code
is written in small parts that are executed quickly, offering the user
more rapid feedback than in conventional programming. A notebook can be
seen as a trace of how the result has been obtained, yet one often
problematic feature of notebooks is that some allow the user to run code
blocks out-of-order. The code manipulates mutable state that exists in a
``kernel'' running in the background. Thus, retracing one's steps in a
notebook is more subtle than in, say, Common
Lisp~\parencite{CommonLisp}, where the \texttt{dribble} function would
directly record the user's session to a file.

\hypertarget{os-like-programming-systems}{\subsection{OS-Like Programming
Systems}\label{os-like-programming-systems}}

``\ac{OS}-likes'' date from the 1960s when it became possible to
interact one-on-one with a computer. At first, time-sharing systems
enabled interactive shared use of a computer via a teletype; smaller
computers such as the PDP-1 and PDP-8 provided similar direct
interaction, while 1970s workstations such as the Alto and Lisp Machines
added graphical displays and mouse input. These \emph{\ac{OS}-like}
systems stand out as having the totalising scope of \emph{operating
systems}, whether or not they are ordinarily seen as taking this role.

\paragraph{MacLisp and Interlisp.}

LISP 1.5~\parencite{LISP15} arrived before the rise of interactive
computers, but the existence of an interpreter and the absence of
declarations made it natural to use Lisp interactively, with the first
such implementations appearing in the early 1960s. Two branches of the
Lisp family~\parencite{LispEvolve}, MacLisp and the later Interlisp,
embraced the interactive ``conversational'' way of working, first
through a teletype and later using the screen and keyboard.

Both MacLisp and Interlisp adopted the idea of \emph{persistent address
space}. Both program code and program state were preserved when powering
off the system, and could be accessed and modified interactively as well
as programmatically using the \emph{same means}. Lisp Machines embraced
the idea that the machine runs continually and saves the state to disk
when needed. Today, this \emph{persistence}
(Definition~\ref{def:persistent}) is widely seen in cloud-based services
like Google Docs and online \acp{IDE}. Another idea pioneered in MacLisp
and Interlisp was the use of \emph{structure editors}. These let
programmers work with Lisp data structures not as sequences of
characters, but as nested lists. In Interlisp, the programmer would use
commands such as \texttt{*P} to print the current expression, or
\texttt{*(2\ (X\ Y))} to replace its second element with the argument
\texttt{(X\ Y)}. The PILOT system~\parencite{Pilot} offered even more
sophisticated conversational features. For typographical errors and
other slips, it would offer an automatic fix for the user to
interactively accept, modifying the program in memory and resuming
execution. This is something that is only possible with Lisp's
\emph{naïve pokeability} (Definition~\ref{def:naive-pokeability}).

\paragraph{Smalltalk.}

Smalltalk appeared in the 1970s with a distinct ambition of providing
``dynamic media which can be used by human beings of all
ages''~\parencite{PersonalDynMedia}. The authors saw computers as
\emph{meta-media} that could become a range of other media for
education, discourse, creative arts, simulation and other applications
not yet invented. Smalltalk was designed for single-user workstations
with a graphical display, and pioneered this display not just for
applications but also for programming itself. In Smalltalk 72, one wrote
code in the bottom half of the screen using a structure editor
controlled by a mouse, and menus to edit definitions. In Smalltalk-76
and later, this had switched to text editing embedded in a \emph{class
browser} for navigating through classes and their methods.

Similarly to Lisp systems, Smalltalk adopts the persistent address space
model of programming where data remains in memory, but based on
\emph{objects} and \emph{message passing} instead of \emph{lists}. Any
changes made to the system state by programming or execution are
preserved when the computer is turned off (this is \emph{persistence}
again, Definition~\ref{def:persistent}). Lastly, the fact that much of
the Smalltalk environment is implemented in itself makes it possible to
extensively modify the system from within: Smalltalk exhibits
Self-Sustainability.

We include Lisp and Smalltalk in the OS-likes because they function as
operating systems in many ways. On specialised machines, like the Xerox
Alto and Lisp machines, the user started their machine directly in the
Lisp or Smalltalk environment and was able to do everything they needed
from \emph{within} the system. Nowadays, however, this experience is
associated with Unix and its descendants on a vast range of commodity
machines.

\paragraph{Unix.}

Unix fits our Definition~\ref{def:programming-system} for programming
systems and illustrates the ways that a system is shaped for its
intended target audience. Built for computer
hackers~\parencite{Hackers}, its abstractions and interface are close to
the machine. Although historically linked to the C language, Unix
developed a language-agnostic set of abstractions that make it possible
to use multiple programming languages in a single system. While
everything is an object in Smalltalk, the ontology of Unix consists of
files, memory, executable programs, and running processes. Note the
explicit ``stage'' distinction here: Unix distinguishes between volatile
\emph{memory} structures, which are lost when the system is shut down,
and non-volatile \emph{disk} structures that are preserved. This
distinction between types of memory is considered, by Lisp and
Smalltalk, to be an implementation detail to be abstracted over by their
persistent address space. Still, this did not prevent the Unix ontology
from supporting a pluralistic ecosystem of different languages and
tools. Thus Unix is distinguished as a \emph{meta-}programming system,
supporting the creation and interaction of different programming systems
within it. We will go into more detail on these points in
Section~\ref{the-unix-paradigm}.

\paragraph{Early and modern Web.}

The Web evolved~\parencite{DotCom} from a system for sharing and
organising information to a \emph{programming system}. Today, it
consists of a wide range of server-side programming tools, \ac{JS} and
languages that compile to it, notations like HTML and CSS, and the
sophisticated developer tools included in browsers. As a programming
system, the ``modern 2020s web'' is reasonably distinct from the ``early
1990s web''. In the early web, \ac{JS} code was distributed in a form
that made it easy to copy and re-use existing scripts, which led to
enthusiastic adoption by non-experts---recalling the birth of
microcomputers like Commodore 64 with BASIC a decade earlier.

In the ``modern web'', multiple programming languages treat \ac{JS} as a
compilation target. \ac{JS} is also used as a language on the server
side. This web is no longer simple enough to encourage copy-and-paste
remixing of code from different sites. However, as we observed in
Section~\ref{web-pages-web-apps-and-browsers} it does come with advanced
developer tools providing functionality resembling that of Lisp and
Smalltalk. The \ac{DOM} almost resembles the tree/graph model of
Smalltalk and Lisp images, lacking the key \emph{persistence} property.
Such a limitation is being addressed by efforts like
Webstrates~\parencite{Webstrates}, which synchronise the \ac{DOM}
between the server and clients. Thus if a client changes an element,
this can be mirrored on the server side and saved as the ground truth of
the web page.

\paragraph{COLAs.}

The one system that directly influenced our work is the \Acl{COLA}, or
\ac{COLA}~\parencite{COLAs}: a small, expressive starting system
designed for open evolution by its user. It is described as a mutually
self-implementing pair of abstractions: a structural object model (the
``Object'' in the name) and a behavioural Lisp-like language (the
``Lambda''). \ac{COLA} aims for maximal openness to modification, down
to the basic semantics of object messaging and Lisp expressions.

The two remarkable features we see in the \ac{COLA} idea are
\emph{self-sustain-ability} and a hint at \emph{notational freedom},
which we will say more about in
Section~\ref{precursors-of-the-three-properties}. \ac{COLA} inherits
self-sustainability from the Smalltalk tradition and attempts to amplify
it. This provides for what the authors refer to as \emph{internal
evolution} as a means for implementing \emph{\acp{MSL}:}

\begin{quote}
Applying {[}internal evolution{]} locally provides scoped,
domain-specific languages in which to express arbitrarily small parts of
an application (these might be better called \emph{mood-specific}
languages). Implementing new syntax and semantics should be (and is) as
simple as defining a new function or macro in a traditional language.
\end{quote}

An example of a \ac{MSL} is the one reported
in~\parencite[p.\ 4]{Steps08} for concisely specifying how TCP packets
should be processed. The report also notes:

\begin{quote}
The header formats are parsed from the diagrams in the original
specification documents, converting ``ascii art'' into code to
manipulate the packet headers.
\end{quote}

This machine interpretation of ASCII art diagrams is another example of
a \ac{MSL}, and we see this as the extreme end of what they are capable
of. The ability for a programmer to express arbitrarily small parts of
an application in a form they deem suitable is, in its fully
\emph{general} form, what we call Notational Freedom. With such a
capability, code could be synthesised from \emph{real} tabular diagrams
of packet headers, not just those rendered with ASCII characters.

\hypertarget{application-focused-systems}{\subsection{Application-Focused
Systems}\label{application-focused-systems}}

The previously discussed programming systems were either universal, not
focusing on any particular kind of application, or targeted at broad
fields, such as Artificial Intelligence and symbolic data manipulation
in Lisp's case. In contrast, the following examples focus on narrower
application domains. Many support programming based on rich interactions
with specialised visual and textual notations.

\paragraph{Spreadsheets.}

The first spreadsheets became available in 1979 in
VisiCalc~\parencite{VisiCalc, VisiCalc2} and helped analysts perform
budget calculations. As programming systems, spreadsheets are notable
for their two-dimensional grid substrate and their model of automatic
re-evaluation. The programmability of spreadsheets developed over time,
acquiring features that made them into powerful programming systems in a
way VisiCalc was not. A major step was the 1993 inclusion of
\emph{macros} in Excel, later further extended with \emph{Visual Basic
for Applications} and more recently with \emph{lambda functions.}

\paragraph{HyperCard.}

While spreadsheets were designed to solve problems in a specific
application area, HyperCard~\parencite{HyperCard} was designed around a
particular application format. Programs are ``stacks of cards''
containing multimedia components and controls such as buttons. These
controls can be programmed with pre-defined operations like ``navigate
to another card'', or via the HyperTalk scripting language for anything
more sophisticated.

As a programming system, HyperCard is interesting for a couple of
reasons. It effectively combines visual and textual notation. Programs
appear the same way during editing as they do during execution. Most
notably, HyperCard supports gradual progression from the ``user'' role
to ``developer'': a user may first use stacks, then go on to edit the
visual aspects or choose pre-defined logic until, eventually, they learn
to program in HyperTalk.

\paragraph{Graphical languages.}

Efforts to support programming without relying on textual code are
``languages'' in a more metaphorical sense. In the ``boxes-and-wires''
style of LabView~\parencite{LabView} programs are made out of graphical
structures. There is also the Programming-By-Example~\parencite{YWIMC}
subset in which a general program is automatically generated by the user
supplying sample behaviours and hints.

\hypertarget{precursors-of-the-three-properties}{\section{Precursors of the Three
Properties}\label{precursors-of-the-three-properties}}

In the next chapter, we will go on to develop the Three Properties in
detail. However, they do not leap out of a vacuum, but are rather
developments of concepts that already exist in programming. For each of
the Three Properties, we will give a ``glossary'' of these existing
concepts and finish with a ``Conclusion'' entry. In short:

\begin{itemize}
\tightlist
\item
  Self-Sustainability is foreshadowed by self-hosting compilers and
  reflection.
\item
  Notational Freedom generalises \acp{DSL} and polyglot programming.
\item
  Explicit Structure already exists widely in the form of data
  structures and various editors; programming is the exception.
\end{itemize}

\hypertarget{precursors-of-self-sustainability}{\subsection{Precursors of
Self-Sustainability}\label{precursors-of-self-sustainability}}

\hypertarget{self-hosting}{\subsubsection{Self-Hosting}\label{self-hosting}}

This describes a compiler that can compile its own source code into a
functionally identical compiler program. We can then change the language
understood by the compiler by changing the source code, compiling it
with the current version, and discarding this version in favour of the
new one. We can then rewrite the compiler's source code to make use of
the new language feature. In this way, a programming language can be
evolved using itself. We can call the language ``self-hosting'' as a
proxy for its compiler.

\hypertarget{bootstrapping}{\subsubsection{Bootstrapping}\label{bootstrapping}}

This is the process of getting a language into a self-hosting
state~\parencite{Bootfrom0}. Suppose we design a novel language
\emph{NovLang} and we are happy to use C++ to build its compiler.
Bootstrapping it consists of the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We write a NovLang compiler in NovLang, but we cannot run it yet.
\item
  We translate this by hand to C++ and build a temporary NovLang
  compiler.
\item
  We run this to compile the NovLang source code from step 1.
\item
  We obtain a runnable compiler for NovLang, which was written in
  NovLang and is now self-hosting.
\item
  We can now discard the C++ code.
\end{enumerate}

\hypertarget{meta-circular}{\subsubsection{Meta-Circular}\label{meta-circular}}

This describes an interpreter that is written in its own
language~\parencite{Metac}. This was first introduced in Lisp, in which
one can write Lisp code to walk nodes in a data structure and treat them
as Lisp expressions. If such code is compiled, it results in an ordinary
Lisp interpreter. Alternatively, if we feed such code into an existing
Lisp interpreter, this new inner interpreter is now meta-circular. We
could change the code to add a new language feature, in which case the
inner interpreter would understand this slightly improved language.
However, this approach does not scale, as each improvement would nest a
further interpreter within the previous ones, multiplying the overhead
to impractical levels.

\hypertarget{reflection}{\subsubsection{Reflection}\label{reflection}}

This is the capacity for a system to display, explain or affect its own
computational behaviour during run time~\parencite{CompRefl}. It is
sometimes explained with the word ``aboutness'': an ordinary program is
``about'' its domain (say, calculations), while a reflective program is
also ``about'' its own computation. One test of this is the ability to
make the tacit explicit~\parencite{ProcRefl}: entities that are normally
implicit and unaddressable (such as the stack frame or variable binding
environment) can be made so by an explicit command to reflect. An
ordinary meta-circular interpreter cannot name its outer interpreter's
data structures, but a reflective one can (and may be able to change how
its outer interpreter works, and thus how it itself works). This is
developed exhaustively for Lisp-like languages in~\parencite{ProcRefl}.
While reflection originates as a property of languages, the Self
environment~\parencite{Self} provides an example in an interactive
context. Any object on screen can call up an ``outliner'' object with a
description of its prototype, private state and methods. This outliner
is an object and can have the same operation applied to it.

\hypertarget{conclusion}{\subsubsection{Conclusion}\label{conclusion}}

These concepts (self-hosting, bootstrapping, meta-circularity, and
reflection) seem related but it is not obvious how. We interpret all of
these as different manifestations of self-sustainability in special
contexts, such as compilers or interpreters. In Chapter~\ref{analysis}
we will make this more precise by delving into the differences between
compilers, interpreters, and interactive programming systems.

\hypertarget{precursors-of-notational-freedom}{\subsection{Precursors of Notational
Freedom}\label{precursors-of-notational-freedom}}

\hypertarget{section}{\subsubsection{\texorpdfstring{\URTFJ}{}}\label{section}}

This is a widespread maxim in programming~\parencite{RightTool} that we
encountered in Definition~\ref{def:right-tool}. The ideal conditions
capturing the spirit of this idea are as follows.

\begin{itemize}
\tightlist
\item
  \emph{Subjective Preference:} What is ``right'' is subjectively
  determined by the programmer, even on a whim. Ordinarily, when
  proposing a change to a language (\eg{} Python), every user of the
  language is forced to confront the change, which invites debate about
  what is ``right'' for everyone. This could be sidestepped if each
  programmer could use what is right, for their own context, without
  this being forced on others. This is meant even in a collaborative
  context: ideally, each collaborator may use their chosen tool while a
  common infrastructure or format allows their efforts to cohere.
\item
  \emph{Metaphorical Tool:} The ``tool'' might be an entire programming
  system or language, a design approach, or simply a notation in which
  to express a component.
\item
  \emph{Range of Scopes:} The ``job'' can be large (an entire project),
  small (a single expression) or anything in-between.
\end{itemize}

Even though these are ideal conditions that we do not inhabit, being
aware of them lets us get a sense of how applicable this principle is
and opens us to any low-hanging fruit in this area. We will now review
the limited extent to which we can apply the principle in our actual
environment of programming.

\hypertarget{polyglot-programming}{\subsubsection{Polyglot Programming}\label{polyglot-programming}}

This is the practice of using multiple languages in a single
project~\parencite{Polyglot}. Modules implemented in different languages
need to share data and invoke each other's functions, for which there
are several approaches:

\begin{itemize}
\tightlist
\item
  If the modules are separate programs, standard inter-process
  communication mechanisms like interchange file formats (JSON, XML),
  socket protocols, and Remote Procedure Calls are available.
\item
  Polyglot programming \emph{within} a shared process address space is
  trickier; the classic approach is to have different languages (\eg{}
  C, Pascal) compile to a common \emph{object file} format understood by
  the linker. This method is restricted to compile time; for run-time
  sharing, languages use Foreign Function Interfaces (FFIs). This
  practice has been critiqued by~\textcite{KellMMM} who advocates the
  use of ``integration domains'' instead.
\item
  Polyglot programming within a single \emph{file} is rare and
  restricted to fixed combinations. Perl and \ac{JS} support regexes
  written with a local syntax. HTML files include not only HTML but also
  \ac{JS} and CSS. C\# supports Language INtegrated Queries (LINQ) which
  are a C\# syntax adaptation of SQL queries. Unlike the freedom to
  choose \emph{any} combination of existing languages for an entire
  project, these instances only permit use of a \emph{pre-approved} set
  decided by the language designers.
\end{itemize}

\hypertarget{section-1}{\subsubsection{\texorpdfstring{\Aclp{DSL}}{}}\label{section-1}}

These go beyond Polyglot Programming by encouraging \emph{custom}
languages designed by the programmer for their problem domain. Where
Polyglot Programming is about making the best use of \emph{existing}
languages designed by someone else, \acp{DSL} come closer to a
\emph{freedom} to use what one subjectively determines to be the best
tool for one's job. JetBrains' MPS~\parencite{MPS} is an interactive
programming system that encourages \acp{DSL}. ``Reader Macros'' in Lisp
allow a programmer to use custom syntax for parts of the code. The
\ac{COLA} design~\parencite{COLAs} supports ``\aclp{MSL}'' intended to
span a range of scopes down to individual expressions, and the related
OMeta~\parencite{OMeta} project is a platform for custom \acp{DSL}. The
Eco editor~\parencite{Eco} also supports \acp{MSL} and even more general
notations.

\hypertarget{conclusion-1}{\subsubsection{Conclusion}\label{conclusion-1}}

``\URTFJ'' is the basic intuition behind Notational Freedom. In
practice, we see a restricted version: use the right \emph{pre-existing}
tool for the job, as long as the job is no smaller than a single file.
Occasionally, a pre-approved set of different languages are available
within a single file. In the rare cases that support the use of custom
``tools'' within a file, we risk being restricted to \emph{languages}
rather than general \emph{notations.} Only MPS and Eco, as far as we are
aware, go further. We will continue this discussion in more detail in
Section~\ref{notational-freedom}.

\hypertarget{precursors-of-explicit-structure}{\subsection{Precursors of Explicit
Structure}\label{precursors-of-explicit-structure}}

\hypertarget{structure}{\subsubsection{Structure}\label{structure}}

This is the relation of parts to wholes. An entire data structure is
made up of smaller parts which reference each other. From one
perspective, a data structure is a graph of memory blocks connected by
numerical pointers. At a more human-friendly level, it is a graph of
dictionaries with named entries, some of which point at other
dictionaries. Both of these models can be visualised as boxes with
arrows.

\hypertarget{binary-files}{\subsubsection{Binary files}\label{binary-files}}

This is a very general term referring to any file that cannot be treated
as plain text. We see binary files as \emph{compacted} data structures.
Unlike data structures in memory, which can be sparsely spread across
large regions and intermingled with each other, a binary file will often
contain the parts densely packed together without any unrelated data. If
not, the binary file serves as an uncompacted ``image'' of a region or
regions of memory.

\hypertarget{syntax}{\subsubsection{Syntax}\label{syntax}}

In programming, this refers to the ``look and feel'' of a language's
textual source code. Formally, syntax is the set of rules defining legal
and illegal symbol sequences. This idea can be metaphorically extended
to non-sequential structures. For example, we can think of C
\texttt{struct} definitions as setting out the valid ``shape'' of the
parts of a data structure. The same applies to binary file formats.

\hypertarget{quantitative-syntax}{\subsubsection{Quantitative Syntax}\label{quantitative-syntax}}

This is a term introduced by~\parencite[p.\ 13]{Infra} for the pattern
of prefixing a block with its length and using numerical pointers to
link structures. A simple example is the Pascal String which begins with
a length byte and continues for that many characters. Binary files rely
primarily on quantitative syntax.

\hypertarget{qualitative-syntax}{\subsubsection{Qualitative Syntax}\label{qualitative-syntax}}

This, in contrast to Quantitative Syntax, relies on special delimiters.
For example, the C String begins right away with its characters, relying
on a null byte to show up at some point and signal the end.

\hypertarget{text-files-strings}{\subsubsection{\texorpdfstring{Text files, \ie{}
Strings}{Text files,  Strings}}\label{text-files-strings}}

These are lists of plain text characters. In programming, they are often
containers for machine-readable structures as an alternative to binary
files. Like the latter, they compact the structure, but in a way subject
to the constraints of plain text and qualitative syntax. In practice,
the structure in question is a tree, in which case the string is built
as an \emph{in-order} traversal. This means that special qualitative
syntax (usually the matched bracket characters \texttt{(}, \texttt{{[}},
\texttt{\{}, or \texttt{\textless{}}) is employed \emph{around}
substrings to encode the structure.

\hypertarget{parsing-and-serialising}{\subsubsection{Parsing and serialising}\label{parsing-and-serialising}}

These convert between strings and structures. Parsing \emph{recovers}
structure implicit in a string, while serialising spins out the
structure into a string.

\hypertarget{format-error}{\subsubsection{Format error}\label{format-error}}

This is a part of a data structure that violates a decidable expectation
of its consumer. For example, a syntactically valid file containing
program source code might violate static typing rules or use a name that
was not declared. Undecidable ``semantic'' rules like prohibiting
division by zero are excluded from this term (see
Figure~\ref{fig:format-errors}).

\begin{figure}
\centering
\scalebox{0.85}{
  
\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]


\draw   (210,85) .. controls (210,49.1) and (288.35,20) .. (385,20) .. controls (481.65,20) and (560,49.1) .. (560,85) .. controls (560,120.9) and (481.65,150) .. (385,150) .. controls (288.35,150) and (210,120.9) .. (210,85) -- cycle ;
\draw   (30,85) .. controls (30,49.1) and (106.11,20) .. (200,20) .. controls (293.89,20) and (370,49.1) .. (370,85) .. controls (370,120.9) and (293.89,150) .. (200,150) .. controls (106.11,150) and (30,120.9) .. (30,85) -- cycle ;

\draw (98,61) node [anchor=north west][inner sep=0.75pt]   [align=left] {Syntax errors};
\draw (351,162) node [anchor=north west][inner sep=0.75pt]   [align=left] {\begin{minipage}[lt]{120pt}\setlength\topsep{0pt}
\begin{center}
“Semantic" errors\\(some undecideable*)
\end{center}

\end{minipage}};
\draw (125,162) node [anchor=north west][inner sep=0.75pt]   [align=left] {\begin{minipage}[lt]{80pt}\setlength\topsep{0pt}
\begin{center}
“Format" errors\\(all decideable)
\end{center}

\end{minipage}};
\draw (101,92) node [anchor=north west][inner sep=0.75pt]   [align=left] {Type errors};
\draw (231,68) node [anchor=north west][inner sep=0.75pt]   [align=left] {\begin{minipage}[lt]{90pt}\setlength\topsep{0pt}
\begin{center}
Use of undeclared\\variable
\end{center}

\end{minipage}};
\draw (385,61) node [anchor=north west][inner sep=0.75pt]   [align=left] {Division by zero*};
\draw (394,92) node [anchor=north west][inner sep=0.75pt]   [align=left] {Infinite loop*};


\end{tikzpicture}
 }
\caption[Format errors, syntax errors, and type errors]{Format errors include syntax errors, type errors and some ``semantic'' errors as long as they are decideable.}
\label{fig:format-errors}
\end{figure}

\hypertarget{syntax-error}{\subsubsection{Syntax error}\label{syntax-error}}

This is a specific type of format error where part of a text string
violates a grammatical expectation of its consumer.

\hypertarget{editors}{\subsubsection{Editors}\label{editors}}

These are programs for creating various data structures in the form of
files. Editors for 3D models, vector graphics, raster images, audio, and
video understand the file formats and strive to save only valid files.
It is usually not possible to even \emph{express} a structure in the
editor that contains a format error. Such cases are exceptional: for
example, a 3D scene might open without errors in another 3D editor, but
cause errors in a game engine according to the latter's additional
requirements---perhaps it expects specific objects in the scene named
\texttt{Player}, \texttt{Exit}, and so on. Nevertheless, for most
editors and most use cases, the consumer-side validity rules are in
harmony with the producer-side rules.

\hypertarget{text-editors}{\subsubsection{Text Editors}\label{text-editors}}

These are a type of editor for plain text files. However, they are
widely used to write code in programming languages, which have extra
syntax rules beyond the plain text format. Unlike most editors, text
editors \emph{can} save files that are invalid from the perspective of
their consumers under realistic use-cases. These syntax errors are then
discovered at the point of consumption.

\hypertarget{conclusion-2}{\subsubsection{Conclusion}\label{conclusion-2}}

The basic intuition behind Explicit Structure is the \emph{directness}
experienced in creation and programming. Almost every data structure in
computing has an editor with which one can manipulate the structure
directly, and when programming we can act as if data structures have
named parts that we can simply reference. This directness is interrupted
by the standalone exception of text editors (on the creation side) and
strings with machine-readable\footnote{We are unconcerned with strings
  that contain natural language simply to be echoed out to the user
  (\eg{} error messages). However, our ideas about Explicit Structure
  could be applicable to cases where software must parse and interpret
  natural language too.} implicit content (on the programming side).
\clearpage{}
\cleardoublepage
\clearpage{}\joel{ Stories (reminder)
1. Bootstrapping self-sustaining systems from a starting point
2. Fixing/freeing the COLA work by lifting the text restriction
3. Re-building the software stack with the benefit of hindsight and better tech.
}

\hypertarget{analysis}{\chapter{Analysis}\label{analysis}}

\joel{
To begin we must explain sys vs languages.
Now we can cover the COLA programming system design including the Id object model.
This introduces self-sustainability, bootstrapping, and notational freedom.
On the latter: here's why COLA's text reliance is a liability.
But why is all this so hard? / big picture: Against Conv Wisdom.
}
\joel{
Having introduced the relevant background knowledge for the dissertation, we will define concepts that we will repeatedly use and the ideas on which they depend. Some of these concepts will already exist, in which case we may use established terms or define new ones as necessary. Others will be novel concepts or interpretations of existing ideas.
}

This dissertation is about building programming systems. In
Section~\ref{programming-systems-vs-languages} we defined this concept
and explained how it is related to that of a programming language. Here,
we will distinguish the general concepts of \emph{state} and
\emph{change} in programming systems. We will illustrate this by
distinguishing the \emph{low-level binary} and \emph{minimally
human-friendly} levels of abstraction. We will then offer our
interpretation of three major sets of conventions in which programming
systems have existed, which we call \emph{paradigms.} With these in mind
we will go on to define our Three Properties in more detail. We will
conclude by reviewing the limitations of existing work in achieving the
Three Properties in the way we desire.

\hypertarget{two-fundamentals-state-and-change}{\section{Two Fundamentals: State and
Change}\label{two-fundamentals-state-and-change}}

For the present work, our most general model of a programming system is
like a physical system in the sense of analytical
mechanics~\parencite{SICM}. There is always a current \emph{state} of
the system, and this will necessarily \emph{change over time}. We stress
that this is the case regardless of whether the underlying programming
metaphor is imperative, purely functional, logic-based, or otherwise
eschews a notion of ``state'' in its conceptual model.

To see how this is inevitable, consider the following. In working with a
declarative or functional programming system, the expression you are
currently editing or the output you are seeing at a given moment is, by
definition, a single state. This state changes whether you interact or
simply wait for progress. In other words, anything to which this view is
not applicable will not be interactive or interesting.

In such a model, we include both the visible interface and the
``hidden'' internal state of the system (\eg{} heap data structures) as
part of ``state''. Such an all-encompassing ``state'', of course, is not
comprehensible atomically but is always broken down into substructures:
on the interface side, this is usually various types of rectangles,
while internally we see byte lists, object graphs, trees and so on.
Likewise, the actual \emph{change} from one state to another usually
does not involve all of the state but only a small part of it. In the
limit, there is usually some smallest unit of state (a byte, dictionary
entry, tree node) and this gives rise naturally to primitive
\emph{instructions} describing a change to such a small unit. Different
choices for how to represent the instructions have implications for
where it is possible to take the evolution of a system. We will see in
Chapter~\ref{bl} that some choices are more appropriate than others for
ensuring a system can be made self-sustainable.

\hypertarget{the-low-level-binary-world}{\subsection{The Low-Level Binary
World}\label{the-low-level-binary-world}}

While human beings think in terms of names, computer hardware works on
numerical bit patterns. This shows through to the lowest level of the
software stack, which we call the \emph{low-level}, \emph{machine-level}
or \emph{binary world.} Here, state consists of one long line of bytes
while change is achieved via machine instructions interpreted by the
hardware. There are three noteworthy features of state here for a
programmer's mental model:

\begin{itemize}
\tightlist
\item
  \emph{Flatness:} if there is not enough space to insert something, we
  have to physically move things to make room. For example, if a list of
  integers is represented by a contiguous array, inserting at the
  beginning requires moving every later entry one place forward. If
  there is not enough spare capacity in the array, it needs copying
  somewhere else with more space.
\item
  \emph{Absoluteness:} while various instruction sets support relative
  addresses, data structures are typically established through absolute
  pointers. Thus when a data structure is moved, any internal pointers
  need relocating based on the new start address.
\item
  \emph{Numerical meaninglessness:} addresses are numerical, but no
  number has an inherent meaning. This interchangeability means it is
  unlikely that two parties will happen to coordinate on the same number
  for the same purpose. Instead, they must communicate beforehand and
  agree on which numerical addresses hold which things or correspond to
  which names.
\end{itemize}

\hypertarget{the-minimally-human-friendly-world}{\subsection{The Minimally Human-Friendly
World}\label{the-minimally-human-friendly-world}}

\joel{https://gutenberg.org/files/12/12-h/12-h.htm What's the use of having names?}

Key technologies were developed to allow humans to create software using
\emph{names} instead of numbers: symbolic assemblers, high-level
languages, and so on. These free us from the cognitive difficulties
associated with numerical labels in the binary world. For example,
programs in the C programming language use names for variables,
functions, and the parts of data structures. However, C's nature as
``portable assembly''~\parencite{Cprog} means that the flatness and
absoluteness of memory must remain in our awareness when using the
language. Even though data structures can be designed to grow by
containing slots for pointers to newly allocated blocks, competence at C
still requires an understanding of the real nature of low-level memory.

A language like \ac{JS}, in contrast, does away with this: state in
\ac{JS} is a graph of dictionaries with named entries. One does not
allocate so many bytes of memory and receive an absolute pointer, but
instead creates an empty dictionary and receives the dictionary
itself.\footnote{Of course, this is a description of the human
  experience; all the layers of representation including bytes and
  physical hardware are present, but do not demand the programmer's
  attention.} We assert that this is at least the \emph{minimally}
human-friendly model of state that is possible, even though improvements
could easily be suggested. To be explicit, the aforementioned three
low-level aspects get negated as follows:

\begin{itemize}
\tightlist
\item
  \emph{Dynamic and nestable} instead of \emph{flat:} one can simply add
  new entries, insert items in collections and create new objects.
\item
  \emph{References} instead of \emph{absolute pointers:} there is no
  distinction between pointers and values. References are implicit and
  automatic. One only needs to be aware how side effects work for
  mutable objects versus immutable values like strings. The underlying
  system can lay out these data structures in memory however it wishes
  and even move them without the programmer needing to update the
  references.
\item
  \emph{Names} instead of \emph{numbers:} objects can be identified by a
  root-level name or by a multi-name path. This provides for logical
  nesting relationships and makes it easier for parties to coordinate
  (agreeing on an already-used name is easier than finding an available
  number and agreeing on it).
\end{itemize}

\hypertarget{let-us-avoid-the-low-level-binary-world}{\subsection{Let Us Avoid The Low-Level Binary
World}\label{let-us-avoid-the-low-level-binary-world}}

In the comparison of programming abstractions, there are what we could
call \emph{industrial} virtues: precise control, efficiency,
performance, and so on. There are also \emph{leisurely} virtues:
simplicity, convenience, and lack of responsibilities. The industrial
and leisurely virtues are somewhat in opposition and correlate with a
model's perception as ``low-level'' or ``high-level''. Lower-level
abstractions are said to embody more of the ``industrial'' virtues at
the expense of the ``leisurely'', and vice versa for high-level
abstractions.

We say all this to note that we agree with the general pattern, but with
one important exception: we do not think it is worth working
\emph{directly} in the low-level binary world outside of narrow special
cases. It was historically necessary to begin there, and it still
underlies all of the software in which we do our work, but we do not see
any benefits to working within that model for building programming
systems.

To be clear, we are only explicitly stating a preference that is
implicit but widely agreed upon: namely, that there is not usually a
good reason to program in machine code when assembler or higher is
available, or to use numeric literals when named constants are
available. Anything involving relocating pointers, resizing structures
or mapping names to numbers should be handled automatically and not
occupy any of our cognitive resources as programmers. There may be
exceptions, but our point is precisely that they are not the common
case.

We will see in Chapter~\ref{bl} that building a self-sustainable system
follows a path similar to the historical development of programming: we
begin at a low level and build up more advanced features and
conveniences. However, we do not think it is necessary to begin at quite
the same low level as the historical case: in all our work, we will take
the minimally human-friendly level as our pre-existing starting point
without concern as to how it is implemented.

\hypertarget{paradigms-of-programs-and-programming}{\section{Paradigms of Programs and
Programming}\label{paradigms-of-programs-and-programming}}

The concept of a scientific ``paradigm'' was popularised by
Kuhn~\parencite{Kuhn}. It refers to the set of norms and conventions in
which scientific questions are pursued and results are interpreted. In
computing, a ``programming paradigm'' is a set of norms around the
concepts and style in which programs are built.

In this section, we wish to broaden the scope and consider the
foundational assumptions of programming itself, and the effects this has
on how it is performed. A paradigm here is a set of norms and
conventions centred around an idea of what a ``program'' is, what
programs are \emph{for}, and what is technologically feasible in the
current environment.

We observe that certain periods of computing history and influential
programming systems embody distinct paradigms in this way. We propose
three: Batch Mode, Unix, and Interactive. Each one accommodates our
Three Properties differently.

It is important to understand the Interactive Paradigm, whose
assumptions pose the least resistance to achieving the Three Properties.
Equally important is to be clear on the Unix Paradigm we currently
inhabit, because we can only realistically achieve our goals from within
it. However, the Unix Paradigm is best understood as inheriting from its
predecessor, Batch-Mode, which we will introduce first.

Our goal in this section is to contrast the basic paradigmatic
assumptions, and their consequences, between our current paradigm (Unix)
and the one we would prefer for the work of this dissertation
(Interactive). Because we see the Unix Paradigm as inheriting its key
assumptions and consequences from its Batch-Mode predecessor, we will
find it easier to introduce them in the latter's context. Thus we will
explicitly describe the assumptions and consequences of Batch-Mode,
continue with a discussion of how Unix augments Batch-Mode while
retaining the same assumptions and consequences, and finally describe
the assumptions and consequences of the Interactive Paradigm by
comparison to those of Batch-Mode.

\joel{
- run time: the time at which a program runs
- runtime: the software that supports the execution of a program
- run-time: the adjective describing when something happens
}

\hypertarget{the-batch-mode-paradigm}{\subsection{The Batch-Mode Paradigm}\label{the-batch-mode-paradigm}}

Computer programs originated as ``batch-mode'' processes. This is the
manner in which a calculation proceeds and delivers a result at the end,
or a compiler passes over source code and outputs a machine-level
program.

In this paradigm, a program starts, runs, and then stops. The effect or
``behaviour'' of a program is its \emph{output;} to change its
behaviour, we need to change the executable program. But we cannot
change the program binary directly; most nontrivial changes would
invalidate various binary offsets, which would then have to be
discovered and adjusted. Instead, we change its \emph{source code}, and
then \emph{re-generate} the program as another batch-mode operation.

This poses no problem because any important effects of the program are
outside it, whether on a paper printout or saved to magnetic tape. Any
data structures the program creates occur within its ``working memory'',
a temporary scratchpad internal to the program and discarded when it's
done its job. This reflects the technological fact that storage comes in
two varieties: one is fast but volatile (it loses its contents without a
steady power supply), while the other is non-volatile but slow. Both are
expensive, as is processing power.

\hypertarget{assumptions-and-consequences-in-batch-mode}{\subsubsection{Assumptions and Consequences in
Batch-Mode}\label{assumptions-and-consequences-in-batch-mode}}

The above points can be distilled into the following assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Program Outputs Result.} The point of a program is to output a
  result, such as a numerical calculation or data retrieved from
  records.
\item
  \emph{Resource Scarcity.} Processing speed and storage (fast and slow)
  are scarce resources that we can only afford for essential tasks.
\item
  \emph{Delete By Default.} There are only one or two data items we care
  about long-term (\eg{} the result). Any intermediate steps taken to
  create the result are unimportant or uninteresting, so their working
  data structures should be discarded to free resources.
\end{enumerate}

The three key consequences of these assumptions are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Run Time Is Volatile.} We implicitly design programs to run in
  the fast/volatile storage. This ensures performance and that the
  uninteresting intermediate state is not wastefully persisted.
\item
  \emph{Few Things To Save.} For the one or two exceptional data items
  that we do care about (such as the output), we have to remember to
  write code to move these out of volatile memory and into non-volatile
  storage. This is not tricky, because there are only a few items we
  care about!
\item
  \emph{Run Time As Obstacle.} The time during which the program is
  running is an \emph{obstacle} to us getting the result; a better
  program is one that terminates sooner.
\end{enumerate}

\hypertarget{compilers-and-change-by-re-creation}{\subsubsection{Compilers and Change By
Re-Creation}\label{compilers-and-change-by-re-creation}}

In Batch Mode, the programmer writes code in a high-level language and
passes this through a \emph{compiler} which outputs an executable
program. The programmer can then make changes to the source code and
compile a new executable. Strictly speaking, the old program executable
is \emph{replaced} with the newly generated one. Still, the continuity
between the versions means ``the program'' as envisioned by the
programmer is changing. In other words, Batch Mode facilitates
\emph{change by re-creation:} in order to change something, we trace its
history to the process that generated it, change the source input, and
then re-generate everything from that point onwards
(Figure~\ref{fig:change-by-re-creation}). This applies even if the
change is small; consider how a single-character typo in one's
\LaTeX-typeset thesis is fixed by re-running \LaTeX~and re-typesetting
the entire document.

\begin{figure}
\centering

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]


\draw    (70,50) -- (175.5,50) ;
\draw [shift={(177.5,50)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (60,60) -- (60,98) ;
\draw [shift={(60,100)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (190,60) -- (190,98) ;
\draw [shift={(190,100)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (200,50) -- (302.5,50) ;
\draw [shift={(304.5,50)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (320,60) -- (320,98) ;
\draw [shift={(320,100)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (60,120) -- (60,158) ;
\draw [shift={(60,160)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (190,120) -- (190,158) ;
\draw [shift={(190,160)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (320,120) -- (320,158) ;
\draw [shift={(320,160)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (370.5,129) -- (110,130) -- (71.79,110.89) ;
\draw [shift={(70,110)}, rotate = 26.57] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (247,129.5) -- (211.77,110.93) ;
\draw [shift={(210,110)}, rotate = 27.79] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (377,129.5) -- (341.77,110.93) ;
\draw [shift={(340,110)}, rotate = 27.79] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;

\draw (54,102) node [anchor=north west][inner sep=0.75pt]   [align=left] {$P$};
\draw (53,40) node [anchor=north west][inner sep=0.75pt]   [align=left] {$S$};
\draw (184,102) node [anchor=north west][inner sep=0.75pt]   [align=left] {$P'$};
\draw (183,40) node [anchor=north west][inner sep=0.75pt]   [align=left] {$S'$};
\draw (311,102) node [anchor=north west][inner sep=0.75pt]   [align=left] {$P''$};
\draw (311,40) node [anchor=north west][inner sep=0.75pt]   [align=left] {$S''$};
\draw (71,71) node [anchor=north west][inner sep=0.75pt]   [align=left] {compile};
\draw (103,22) node [anchor=north west][inner sep=0.75pt]   [align=left] {edit};
\draw (243,22) node [anchor=north west][inner sep=0.75pt]   [align=left] {edit};
\draw (71,132) node [anchor=north west][inner sep=0.75pt]   [align=left] {run};
\draw (54,162) node [anchor=north west][inner sep=0.75pt]   [align=left] {$R$};
\draw (183,163) node [anchor=north west][inner sep=0.75pt]   [align=left] {$R'$};
\draw (312,163) node [anchor=north west][inner sep=0.75pt]   [align=left] {$R''$};
\draw (362,136) node [anchor=north west][inner sep=0.75pt]   [align=left] {inputs};


\end{tikzpicture}
 \caption[Change By Re-Creation]{Change By Re-Creation: source code $S$ is compiled into a program $P$ which is run on some inputs to produce a result $R$ signifying the observable ``behaviour'' of a program in the Batch-Mode paradigm. To change this behaviour under the same inputs, we must trace up the arrows to the source code and edit it into $S'$. From this, a new program $P'$ is compiled, which is run to produce a new result $R'$, and so on.}
\label{fig:change-by-re-creation}
\end{figure}

\hypertarget{static-commitment-in-batch-mode}{\subsubsection{Static Commitment in
Batch-Mode}\label{static-commitment-in-batch-mode}}

The stages of \emph{compile time} and \emph{run time} are of comparable
importance in this paradigm. Properties that are \emph{static}, or
\emph{early-bound}, are invariant over the entire run time of a program
and are ``baked in'' at compile time. Those that are \emph{dynamic} or
\emph{late-bound} may vary over the run time. Since a program has a
specific answer to work out (Program Outputs Result), then the only
properties that \emph{need} to be dynamic are those that directly
pertain to such a process. All other properties are candidates for
\emph{static commitment:} the compiler (suitably informed, \eg{} by type
annotations) can assume they will never change, and hence can avoid
generating code to deal with the consequences of such changes.

Beyond optimising the program's performance, this also gives programmers
an opportunity to make mathematical guarantees about certain properties.
This all follows from ``Run Time As Obstacle'': a program's destiny is
to terminate with an answer, and a better program terminates sooner.
Requirements may change so that some formerly static property now needs
to be dynamic; for example, a behaviour that was previously the same for
all objects might now need to be dispatched on the type of the object.
In such a situation, the program is re-written and re-compiled, ready to
run under the new conditions. In the event that the old version of the
program happens to be running, it can be deleted once it terminates.

\hypertarget{key-legacies-of-batch-mode}{\subsubsection{Key Legacies of
Batch-Mode}\label{key-legacies-of-batch-mode}}

The batch-mode paradigm can be considered an appropriate adaptation to
the early conditions of computing: specialised, industrial-scale use
cases and extreme scarcity in storage and processing speed. Its legacy
survives today in the following forms:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The \emph{volatility split:} at all times, a programmer must remain
  aware of, and specify, whether their data is to be stored in volatile
  or non-volatile storage. An example is the question ``Does this belong
  in a class, or in the database?''.\footnote{There do exist
    technologies like Object-Relational Mappers (ORM) which bridge the
    split, but this is optional infrastructure with its own costs. Its
    existence serves to highlight the significance of the Volatility
    Split.} Variables and classes are easy to express in code, but are
  presumed to be transient; file and database access grants persistence,
  but is more complex to express.
\item
  The \emph{change by re-creation} model: in order to change something,
  trace its history to the process that generated it, change the source
  input, and then re-generate everything from that point onwards.
\item
  Encouragement of \emph{static commitment:} many innovations in
  programming take the form of improved ways to enforce static
  properties over a program's run time, such as type system features.
\end{enumerate}

\hypertarget{the-unix-paradigm}{\subsection{The Unix Paradigm}\label{the-unix-paradigm}}

Unix is a family of Operating Systems dating from the 1970s. For this
dissertation, we are not interested in the differences between Unix
versions or descendants. Instead, we refer to the common set of concepts
and conventions that form ordinary programming practice today, most
importantly \emph{files} and \emph{processes.}

Here we have a \emph{continuously} running master-program (the
\emph{kernel}) which allocates computation and storage to batch-mode
programs under its supervision. Unix calls these \emph{processes;} each
one a sort of virtual processor plus working memory, which it calls
``core''. As in Batch-Mode, core is just a means for the process to do
its job quickly, and is discarded upon termination. The other world, of
``things that matter'', is a hierarchical tree of \emph{files} shared
between processes and persisted as they come and go. Files and ``pipes''
serve as important inter-process communication mechanisms, and this
\emph{composability} of processes is an important part of the Unix
philosophy.

Unix was created before the rise of \acp{GUI} and naturally preserved
the batch-mode norm from its surroundings. Still, it contains early
signs of what we will call the ``interactive'' paradigm in
Section~\ref{the-interactive-paradigm}. Users can access the current
state of processes and files via the command line \emph{terminal} or
\emph{shell}. This runs as a process but is, like the kernel,
continuously running, passing input and output between the user and the
kernel.

There is one further small innovation worth noting. As an Operating
System, Unix goes some of the way towards hiding the Volatility Split by
\emph{paging} core to disk, prioritising fast storage for processes that
need it (the others are paused waiting for some event). However, Unix
still sees processes as temporary scaffolding to be discarded when
complete (Delete By Default). What this means is that even though Unix
is clearly capable of persisting a process' data while it is still
active, it will still be discarded when the process completes.

We see that the Volatility Split, Change By Re-creation, and Static
Commitment were preserved from the Batch-Mode era in the processes and
files within Unix. Let us summarise all this as the \emph{Unix
Paradigm:} a compromise between the batch-mode and interactive paradigms
(described soon in Section~\ref{the-interactive-paradigm}) where limited
interaction is used to organise batch-mode computation. For this reason,
we consider the assumptions, consequences, and legacies of Batch-Mode
(Sections~\ref{assumptions-and-consequences-in-batch-mode}
and~\ref{key-legacies-of-batch-mode}) to be inherited by Unix as its
assumptions, consequences and legacies.

\hypertarget{unix-as-a-programming-system}{\subsubsection{Unix as a Programming
System}\label{unix-as-a-programming-system}}

We already gave a cursory analysis of Unix as a programming system in
Section~\ref{os-like-programming-systems}, on which we will now go into
further detail. We note that Unix is an overarching system managing many
smaller processes. To the extent that \emph{other} programming systems
are implemented as Unix processes, Unix functions as a meta-system
supporting subordinate programming systems. Thus there are always
\emph{two} levels to programming in the Unix Paradigm: the ``large''
\emph{inter-process} scope comprising processes and their communication,
and the ``small'' \emph{intra-process} scope within each process. In
both of these, \emph{state} consists of both core and files thanks to
the Volatility Split. However, the two levels emphasise these to
different degrees.

At the inter-process scope, it seems appropriate to describe the
filesystem as the primary ``state''
(Section~\ref{two-fundamentals-state-and-change}) of the Unix system.
There is, of course, nontrivial state in core such as the currently
running processes and bookkeeping information for them, which will be
lost if the system is restarted. Nevertheless, from its own perspective,
the ``important data'' for users all lives in the filesystem; what
happens to be running at any given time in core is merely a means to an
end.\footnote{``Few Things To Save'' reminds us: if a data structure was
  important, the programmer would have written code to save it to a
  file!} The agent of \emph{change} at the inter-process scope is the
kernel, and the primitive ``instructions'' are the system calls used to
write to files and change the file tree.

Meanwhile, at the small scope of a \emph{process} embodying a
programming system nested within Unix, the manifestation of state and
change will depend on the particular system itself. Yet because we know
it is running as a Unix process, we can at least be certain that the
lowest level of ``state'' will be split between core and files, and
``change'' will occur through the execution of machine instructions.

\hypertarget{the-interactive-paradigm}{\subsection{The Interactive Paradigm}\label{the-interactive-paradigm}}

We define the \emph{interactive paradigm} as the programming model that
emerges from conditions of speed and storage abundance. Such abundance
frees us from having to start with the question ``what purposes can
computers currently cope with?'' and instead ask ``what are computers
for?'' with the answer being roughly equivalent to ``anything''. This
generality means that we should be careful to avoid embedding limiting
assumptions in the infrastructure that supports programs and
programming.

\hypertarget{assumptions-and-consequences-of-the-interactive-paradigm}{\subsubsection{Assumptions and Consequences of the Interactive
Paradigm}\label{assumptions-and-consequences-of-the-interactive-paradigm}}

The Interactive paradigm relaxes or rejects the basic axioms of
batch-mode programming:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ``Program Outputs Result'' is rejected. The point of a program is to
  simulate a piece of the world somehow useful to a human, but in a
  manner that is free of the constraints of physical media substances
  like paper. Producing an output is only one of many such effects
  useful to humans.
\item
  ``Resource Scarcity'' is rejected. Processing and storage are (or will
  be\footnote{This was the attitude at Xerox PARC summed up in the
    principle ``design for the hardware of tomorrow''.}) sufficiently
  abundant that we can use them generously in service of higher goals.
\item
  ``Few Items To Save'' is rejected. We do not know \emph{a priori} and
  in full generality which data items we care about long-term, because
  the space of human purposes is large. For some tasks, the journey is
  more important than the destination.\footnote{An example of this is
    the Event Sourcing pattern~\parencite{EvSourcing}, where the history
    of state changes is recorded and accessible as a sequence.}
\end{enumerate}

And the consequences:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Instead of ``Delete By Default'', we have ``Persist Intermediate
  Data''. We cannot \emph{commit} on principle to saving some data and
  discarding or hiding other data. We persist everything by default and
  provide means to free up resources explicitly. We reluctantly abstain
  from this only where necessary for performance, treating this as a
  temporary optimisation to relax in future. But we cannot decide for
  the user what they will be interested in.
\item
  The Volatility Split is replaced with Volatility Obliviousness: code
  can simply create and manipulate data structures without the
  programmer needing to keep in mind what type of storage they live in.
\item
  Instead of Change By Re-creation, we have ``Change by Changing''. It
  ought to be possible to change the state or behaviour of the system
  directly, as opposed to changing some upstream specification and
  re-creating the system from that. This is important both for
  performance and for avoiding premature deletion of data.
\item
  Instead of ``Run Time As Obstacle'', we have ``Run Time Is Valuable''.
  It is no longer the case that a good program terminates quickly. There
  may not even be any reason for it to terminate at all. Where
  previously the run time was an inconvenient delay to getting the
  result, now the run time may be the \emph{raison d'être} of the
  software, such as is the case with any interactive graphical
  application.
\end{enumerate}

This paradigm is embodied in Lisp and Smalltalk, both for different
reasons. Lisp originated before Unix as a language for mathematical and
logical symbol manipulation in AI research; it makes sense that such a
tool had little need to import batch-mode, industrial-scale computation
as its primary concept. Smalltalk, on the other hand, deliberately
rejected this convention to serve its goal of shifting computing out of
the industrial mode and into the personal. In neither do we find a
mandatory separation between volatile and non-volatile storage, nor
between ``large objects'' (files and processes) and ``small objects''
(variables and code). Instead we find a graph of data structures, called
``expressions'' in Lisp and ``objects'' in Smalltalk.

\hypertarget{batch-mode-anachronisms}{\subsection{Batch-Mode Anachronisms}\label{batch-mode-anachronisms}}

The relaxed assumptions make sense in today's computing environment with
plentiful processing and storage. However, the Unix Paradigm preserves
the assumptions and consequences of Batch Mode. From this perspective,
the three Batch Mode legacies feel obsolete.

\hypertarget{volatility-split}{\subsubsection{Volatility Split}\label{volatility-split}}

The Volatility Split treats what ought to be an \emph{implementation
detail} as a major design concern. The question of whether the variable
\texttt{x} should live in the physical form of RAM cells or as magnetic
domains may not even be knowable by the programmer. It resembles the
question of at which precise address a new string buffer should live in
memory; a function like \texttt{malloc()} removes the need for the
programmer to ``manually'' decide such an implementation detail, and
this is a good thing.\footnote{Even though this is known as ``manual''
  memory management, the ``manual'' refers to the management of
  allocation \emph{lifetime}, in contrast to \emph{garbage collection}
  which automatically decides when to free memory. The actual allocation
  of memory via a call to \texttt{malloc()} is automatic by the very
  fact that it is a subroutine being run on a computer.} Similarly, the
storage medium of a variable should surely be deferred to some automatic
mechanism.

\hypertarget{change-by-re-creation}{\subsubsection{Change By Re-creation}\label{change-by-re-creation}}

Re-creation seems like an unnecessarily convoluted path to achieve a
simple change. Suppose we want the field \texttt{foo} of object
\texttt{greeter} to change to \texttt{"Hello"}. The system knows the
object referred to by the name \texttt{greeter} and knows how the field
\texttt{foo} is stored. It seems odd to have to dig through code and
re-generate the object along with everything it touched, a practice Bret
Victor dubbed ``destroy-the-world programming''~\parencite{BretVictor};
surely we ought be able to just type \texttt{greeter.foo\ =\ "Hello"}
and have the property update accordingly in the running system. Change
By Re-creation may be compatible with this as an \emph{implementation}
strategy hidden from the user's concern, so long as the data loss from
terminating the current process is mitigated. An example of this is the
method proposed by~\textcite{Externalize} under the name ``Queen of
Sheba Adaptation''.

\hypertarget{static-commitment}{\subsubsection{Static Commitment}\label{static-commitment}}

Static commitment mechanisms, such as type systems, now play a much less
helpful role or even an obstructive one. If a program's value derives
from its behaviour as an interactive system, it may well be running for
a long time or even (ideally) forever. This intensifies any
disadvantages of static commitment mechanisms like type systems.

The immediate problem is that if requirements change and a commitment
must be relaxed to vary at run time, we are forced to terminate the
running system and re-generate it. Unlike the Batch-Mode case
(Section~\ref{static-commitment-in-batch-mode}), we cannot simply wait
for the program to run its course and terminate, and when we do force it
to terminate we risk losing important transient state.

The more fundamental problem is that a mandatory commitment might be
clearly \emph{premature} from the perspective of the user. A type
commitment like ``Type X shall always be a subtype of Y'' may be too
restrictive, too soon. Consider a game in which the class
\texttt{Goblin} is a subclass of \texttt{Enemy}. In a language like C++,
class relationships are statically enforced. This prevents the player
from befriending Goblins later in the game, as we cannot write code to
change a \texttt{Goblin} instance to inherit from \texttt{Friend} at an
appropriate point during run time. This means that the natural means of
expressing relationships in the language must be abandoned in favour of
an ad-hoc replacement with dynamic capabilities and no syntactic sugar.
We will discuss this further in Section~\ref{video-games}.

It must be stressed that there is still a role for commitments and
optimisations, but it is \emph{piecemeal} at smaller scales
\emph{during} run time. As the duration of the program's run time
increases, the set of properties one might wish to statically commit to
shrinks correspondingly, for the simple reason that the likelihood of a
change in requirements increases.

For an analogy, consider a single program with a specific purpose in a
Unix environment. If its requirements change, the program is re-compiled
while the rest of the system does not need to be affected. This is
because any ``static'' commitments with which it was compiled apply to
the run time of the individual Unix \emph{process.} Suppose that
instead, the entire Unix environment was assembled incorporating static
commitments about this program, where these commitments were scoped to
the lifetime of the \emph{entire environment.} Then, when requirements
for the program change, the whole environment must be re-compiled and
\emph{re-installed;} it will not do to merely replace the program,
because the rest of the environment was compiled and optimised with the
now-invalidated commitments in mind.

This is an extreme hypothetical, but it is analogous to what can happen
when ordinary process-level static commitment is employed for a
long-running, interactive or open-ended process such as a game. Anything
whose change during run time cannot be \emph{ruled out} cannot be
enforced as a process-level static commitment. Technologies like
hot-swapping or Dynamic Code Evolution~\parencite{DynCodeEvol} bring the
benefits of commitment and optimisation to such systems at a scale that
is more appropriate for them.

\hypertarget{conclusion}{\subsection{Conclusion}\label{conclusion}}

As examined by~\textcite{WIB} and~\textcite{Kell-OS}, Unix ``won'' in a
way that Lisp and Smalltalk did not, firmly establishing the Unix
Paradigm as ubiquitous. Where Lisp and Smalltalk exist, they are
processes sitting within Unix and saving to ``image'' files. For
implementors of novel programming systems, the tenacious Volatility
Split, Change By Re-creation model and Static Commitments clash with the
Interactive Paradigm natural to the enterprise. The takeaway for this
dissertation is that if we wish to build our system in the Unix
paradigm, we must be mindful of its shortcomings relative to the ideal
Interactive paradigm and expect part of our work to involve mitigating
them.

\hypertarget{the-three-properties-in-more-detail}{\section{The Three Properties in More
Detail}\label{the-three-properties-in-more-detail}}

In Section~\ref{the-three-properties} we gave introductory definitions
for Self-Sustainability, Notational Freedom, and Explicit Structure. Now
it is time to go into more detail and examine them in light of the
paradigms we identified.

\hypertarget{self-sustainability}{\subsection{Self-Sustainability}\label{self-sustainability}}

Self-sustainability involves being able to evolve and re-program a
system, using itself, while it is running. At the upper limit of this
would reside ``stem cell''-like systems: those which can be
progressively evolved to arbitrary behaviour without having to step
outside of the system to a lower implementation level. Any difference
between these systems would be merely a difference in current state,
since any could be turned into any other.

The lower limit, of minimal self-sustainability, looks something like
the following: beyond the transient run-time state changes that make up
the user level of any piece of software, the user cannot change anything
without dropping down to the implementation level. This would resemble a
traditional end-user ``application'' focused on a narrow domain with no
means to do anything else.

At a sufficiently large scope, self-sustainability is inevitable. By
analogy, while any nation's economy might be dependent on other nations,
the world economy is a closed system that provides its own inputs.
Similarly, the ecosystem of software as a whole is necessarily
self-sustainable. Even an \emph{individual} Unix system is largely
self-sustainable at its inter-process scope, but it is notable that we
lose self-sustainability on the way down to the intra-process scope. We
will discuss these two scopes as they relate to self-sustainability,
after which we will distinguish the \emph{user level} and
\emph{implementation level} of programming systems. Then we will
conclude with a definition of \emph{innovation feedback,} the key
advantage a self-sustainable system has over others. For further
information and motivation on Self-Sustainability beyond our own
analysis here, we recommend the introductory sections
of~\parencite{COLAs} and~\parencite{OROM} and the vision presented
in~\parencite{CookClay}.

\hypertarget{self-sustainability-at-the-inter-process-scope}{\subsubsection{Self-Sustainability at the Inter-Process
Scope}\label{self-sustainability-at-the-inter-process-scope}}

At the inter-process scope of Unix, we have individual processes---text
editors, compilers, interpreters, debuggers---which change the
large-scale system state (files), such as by creating new programs. Some
of these processes run \emph{shell scripts} to coordinate this activity,
this being the de-facto programming language\footnote{Technically, the
  various shell \emph{dialects} (bash, csh, etc.) form multiple de-facto
  \emph{languages}, but this is not important for the point.} at the
inter-process scope. In this way, a Unix system is evolved and
re-programmed using itself, while it is running. Hence, Unix (\ie{}
programming-in-the-large) is self-sustainable, which is congruent with
the origins of Unix as a system for programmers.

The matter is complicated by the fact that a small minority of special
changes require restarting the system to take effect. However, the
spirit of the ``while it is running'' condition is that the system does
not need to be \emph{destroyed and rebuilt from scratch}. Because the
``state'' of the inter-process scope is mainly files, the destructive
operation here is not so much ``restart'' as perhaps ``reset'' or
``reinstall''.

In contrast, for a programming system that exists as a process
\emph{within} Unix, its data structures in volatile memory will be
permanently lost if it is restarted, and these data structures may well
be an important part of its state as a continuously running interactive
programming system. Indeed, when we turn our attention to the
intra-process scope of the Unix Paradigm, we mostly do not see
self-sustainability.

\hypertarget{self-sustainability-at-the-intra-process-scope}{\subsubsection{Self-Sustainability at the Intra-Process
Scope}\label{self-sustainability-at-the-intra-process-scope}}

Compiled programming languages like C++ or Java are used via several
different Unix processes. These include interactive ones like text
editors, and batch-mode ones like the compiler. Self-sustainability
ought to be the analogue of the properties in
\ref{precursors-of-self-sustainability} for interactive programming
systems. To recap, these were self-hosting compilers, the bootstrapping
thereof, meta-circular interpreters, and reflection.

The self-hosting compiler is how self-sustainability manifests in the
batch-mode world, where the memory used by the process is disposable and
unimportant, hence Change by Re-creation does not cause too many
problems. For interactive programming systems, this is often
inappropriate or at least highly inconvenient, so it is hard to base
full self-sustainability on self-hosting.

In this respect, interactive systems more closely resemble
\emph{interpreters} than compilers. The job of a compiler is to generate
a new program, which could (in principle) be a \emph{replacement} for
the old compiler. Moreover, both the new program and its source code
live in the filesystem, \ie{} non-volatile storage. The job of an
interpreter is simply to \emph{execute} a program, and by default any
changes we make to its state as a result of the code we feed it will not
survive process termination. Unlike interpreters, interactive processes
like \acp{REPL} or programming systems are meant to run as long as the
user wishes and contain a lot of important state in memory.

Traditionally, the Volatility Split was just forwarded into the user's
mental model, making no guarantees about whether work would be saved in
the event of a crash and recommending the user to save regularly.
End-user applications did eventually implement ``auto-save'', but this
is a feature programmed in to preserve specific user data. For
programmers, ``auto-save'' of run time state involves infrastructure
that takes considerable work to implement, owing to ``Delete By
Default''. Therefore, re-creating the system risks important data loss.
Even if such infrastructure is present, restarting the system to make a
change may interrupt the user experience with an inconvenient delay.

Perhaps instead of the above compiler-related precursors, we can adapt
the interpreter-related precursors, meta-circularity and reflection.
Meta-circularity will only aid us if the inner interpreter is causally
connected to the outer one via reflection. Therefore reflection is the
most suitable precursor to develop into self-sustainability,
particularly as it manifests in Self~\parencite{Self} rather than, say,
Java. This could be achieved if reflection is scaled up to encompass as
much of the system as possible and if reflected data can be changed
rather than simply observed. It would also be necessary to protect any
changes achieved through reflection from being lost upon process
termination. In short, self-sustainability takes much from reflection in
interpreters but combines this with the persistent evolution of the
self-hosting compiler.

\hypertarget{user-vs.-implementation-levels}{\subsubsection{User vs.~Implementation
Levels}\label{user-vs.-implementation-levels}}

For any piece of software, there are two levels:

\begin{itemize}
\tightlist
\item
  The \emph{user level} is where software is used for its intended
  purpose by its target audience. For example, the user level of Firefox
  involves browsing websites.
\item
  The \emph{implementation level} is where the software is created and
  changed in ways unavailable at the user level. As a trivial example,
  by taking all of the source code of Firefox and replacing it with the
  code for Hello World, a programmer can change Firefox into a Hello
  World program.
\end{itemize}

If the software is a programming system, then this can get confusing:
both levels involve programming! Consider this example situation:
someone is using Python to write a Hello World program, and the
programming system (Python interpreter plus editor) is written in C. We
can view this situation in three ways depending on the ``user''
(Figure~\ref{fig:user-impl-examples}):

\begin{figure}
\centering
\scalebox{0.85}{
  \begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]


\draw   (36.7,70) -- (200,70) -- (200,230) -- (36.7,230) -- cycle ;
\draw    (36.7,110) -- (200,110) ;
\draw    (36,150) -- (200,150) ;
\draw    (36,190) -- (200,190) ;
\draw   (220,70) -- (320,70) -- (320,150) -- (220,150) -- cycle ;
\draw    (230,110) -- (310,110) ;
\draw   (340,70) -- (440,70) -- (440,190) -- (340,190) -- cycle ;
\draw    (350,150) -- (430,150) ;
\draw   (460,110) -- (560,110) -- (560,230) -- (460,230) -- cycle ;
\draw    (470,190) -- (550,190) ;

\draw (116,162) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {C};
\draw (100,122) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {Python};
\draw (60,82) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] { “Hello World” app};
\draw (114,202) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {...};
\draw (236,80) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {User level};
\draw (235,121) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {Impl. level};
\draw (236,32) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {End-user};
\draw (354,20) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {\begin{minipage}[lt]{60pt}\setlength\topsep{0pt}
\begin{center}
Application\\Developer
\end{center}

\end{minipage}};
\draw (475,20) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {\begin{minipage}[lt]{51pt}\setlength\topsep{0pt}
\begin{center}
Python\\Developer
\end{center}

\end{minipage}};
\draw (355,101) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {User level};
\draw (354,161) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {Impl. level};
\draw (475,141) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {User level};
\draw (474,201) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {Impl. level};


\end{tikzpicture}
 }
\caption[Relativity of user vs. implementation levels]{Relativity of user versus implementation level depending on one's role.}
\label{fig:user-impl-examples}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We can focus on the user of the Hello World program. The user level is
  Hello World, while the implementation level involves Python.
\item
  We can focus on the programmer as the user of Python. The user level
  involves Python \emph{and} the Hello World program (for testing,
  debugging, and so on) while the implementation level involves C.
\item
  We can focus on a different programmer who works on the Python
  implementation. The user level involves C \emph{and} Python (for
  testing, debugging, and so on). Even though there are further
  implementation levels below, we short-cut the analysis here and leave
  them unspecified.
\end{enumerate}

In this dissertation, we are interested in \emph{building} programming
systems with the Three Properties: Self-Sustainability, Notational
Freedom and Explicit Structure. This means we occupy the third
viewpoint, where we are detached from any particular end-user program
that might get created. We see our situation as follows:

\begin{itemize}
\tightlist
\item
  We are using some already-existing programming system (\eg{} C). We
  did not create it and we do not expect to be able to change it. We
  call this the \emph{platform}.
\item
  The programming system we create using the platform is called the
  \emph{product system} or simply ``the system'' (\eg{} Python).
\end{itemize}

\hypertarget{platforms-and-substrates}{\subsubsection{Platforms and
Substrates}\label{platforms-and-substrates}}

Because we seek to build a product system that is Self-Sustainable, the
picture becomes more complicated. The point of Self-Sustainability is to
blur the distinction between the implementation and user levels. Not
only can the system be used to create ordinary programs, but it can also
be used to change itself. We use the term \emph{in-system} to refer to
changes made within the product system, by using it as a programming
system at its user level.

In the Platonic ideal self-sustainable system, there is no distinction
between the two levels at all. In practice, the best we can do is
attempt to \emph{minimise} the implementation level to a tiny
core:\footnote{In the limit, we will leave the world of software only to
  hit the non-malleable world of physical hardware. Still, search
  ``FPGA'' in~\parencite{COLAs} for its speculations on pushing this as
  far as it can go (see the captions for Figure~3 and Figure~14 and
  page~23.)} everything else can be changed in-system. In this case, we
call this tiny core the \emph{substrate}. Our task as implementors is to
use an established platform to write a minimal substrate that can then
support a self-sustainable system. Almost all aspects of the system can
then be changed in-system, and the rest must be changed in the substrate
using the platform.

To summarise the picture in the self-sustainable case
(Figure~\ref{fig:plaf-substr-prod}):

\begin{itemize}
\tightlist
\item
  The \emph{platform} is the already-existing programming system that we
  accept as-is and do not expect to have much control over: for example,
  the C programming language.
\item
  The \emph{substrate} consists of the code we write for the platform.
  We exercise control over it, but we do not expect it to be accessible
  in-system, which is why we seek to minimise it. An example would be a
  C Virtual Machine for Smalltalk.
\item
  The \emph{product system} is the programming system supported by the
  substrate, such as Smalltalk. Ideally, a tiny part of it is
  implemented in the substrate while most of it is implemented in
  itself. In other words, most changes to the system can be made using
  the running system (they are \emph{self-supplied},
  Definition~\ref{def:self-supplied}) while only a few may require
  modifying the substrate and restarting or re-compiling the running
  system.
\end{itemize}

\begin{figure}
\centering

\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]


\draw   (30,20) -- (220,20) -- (220,210) -- (30,210) -- cycle ;
\draw    (30,130) -- (220,130) ;
\draw    (30,170) -- (220,170) ;
\draw   (229.5,208.5) .. controls (234.17,208.5) and (236.5,206.17) .. (236.5,201.5) -- (236.5,122.21) .. controls (236.5,115.54) and (238.83,112.21) .. (243.5,112.21) .. controls (238.83,112.21) and (236.5,108.88) .. (236.5,102.21)(236.5,105.21) -- (236.5,29.5) .. controls (236.5,24.83) and (234.17,22.5) .. (229.5,22.5) ;
\draw   (251.5,130.5) .. controls (256.17,130.5) and (258.5,128.17) .. (258.5,123.5) -- (258.5,85.94) .. controls (258.5,79.27) and (260.83,75.94) .. (265.5,75.94) .. controls (260.83,75.94) and (258.5,72.61) .. (258.5,65.94)(258.5,68.94) -- (258.5,31.5) .. controls (258.5,26.83) and (256.17,24.5) .. (251.5,24.5) ;

\draw (71,181) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {\textit{Platform:} C itself};
\draw (61,141) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {\textit{Substrate:} VM in C};
\draw (66,71) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {\textit{Product: }Smalltalk};
\draw (275,52) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {User\\level};
\draw (254,152) node [anchor=north west][inner sep=0.75pt]  [font=\normalsize] [align=left] {\begin{minipage}[lt]{24.83pt}\setlength\topsep{0pt}
Impl.
\begin{center}
level
\end{center}

\end{minipage}};


\end{tikzpicture}
 \caption[Smalltalk analysed as platform/substrate/product]{Example platform (C) supporting a substrate (Smalltalk VM) for a self-sustainable product system (Smalltalk). Because the product is self-sustainable, the user and implementation levels are no longer disjoint, so the platform/substrate/product distinction is a more helpful alternative.}
\label{fig:plaf-substr-prod}
\end{figure}

For ordinary software, there is no reason to distinguish the platform
and the substrate; the two of them together constitute the
implementation level. For a self-sustainable system this distinction is
necessary, because the ``implementation level'' extends into the product
system itself (ideally being concentrated there).

\hypertarget{the-key-benefit-innovation-feedback}{\subsubsection{The Key Benefit: Innovation
Feedback}\label{the-key-benefit-innovation-feedback}}

A system that is self-sustainable has an advantage over those that are
not: we call this \emph{innovation feedback}. Innovations programmed
using the system---useful functions, notations, or tools---can benefit
their \emph{own} development as well as the rest of the system. In
contrast, for a system whose internals cannot be affected by any program
within it, innovations can only be exploited for the system's
development by \emph{duplicating} the work at the system's
implementation level.

For example, at the inter-process scope of Unix, a text editor may be
used to improve its own source code, which can then be compiled into an
even better text editor. This improved editor can then edit its own
source code and begin a new cycle of self-improvement. The shell
interface, graphical interfaces and all tools are just \emph{programs}
which can be replaced with newly compiled improvements, all using other
Unix programs. Therefore, a Unix system is not limited to improving
detached \emph{separate} distributions of programs destined for a
different user, but naturally improves itself as well.

\begin{figure}
\centering
\scalebox{0.88}{
  
\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]


\draw    (72.5,67) -- (72.98,107) ;
\draw [shift={(73,109)}, rotate = 269.32] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (143,69) -- (143.48,109) ;
\draw [shift={(143.5,111)}, rotate = 269.32] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (81,109) -- (128.44,71.25) ;
\draw [shift={(130,70)}, rotate = 141.48] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw    (155,123) -- (193,123) ;
\draw [shift={(195,123)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (153,69) -- (201.44,107.75) ;
\draw [shift={(203,109)}, rotate = 218.66] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (213,69) -- (213,107) ;
\draw [shift={(213,109)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw   (50,30) -- (240,30) -- (240,220) -- (50,220) -- cycle ;
\draw    (50,150) -- (240,150) ;
\draw    (50,184) -- (240,184) ;
\draw   (318.75,30) -- (508.75,30) -- (508.75,220) -- (318.75,220) -- cycle ;
\draw    (318.75,150) -- (508.75,150) ;
\draw    (318.75,184) -- (508.75,184) ;
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (478.75,90) -- (538.75,90) -- (538.75,120) ;
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (538.75,150) -- (538.75,200) -- (480.75,200) ;
\draw [shift={(478.75,200)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw [line width=2.25]    (526.5,124) -- (550,148) ;
\draw [line width=2.25]    (549.25,124) -- (527.25,148) ;

\draw  [dash pattern={on 4.5pt off 4.5pt}]  (230,90) -- (270,90) -- (270,120) ;
\draw  [dash pattern={on 4.5pt off 4.5pt}]  (270,150) -- (270,200) -- (212,200) ;
\draw [shift={(210,200)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
\draw [line width=2.25]    (260,120) -- (283.5,144) ;
\draw [line width=2.25]    (282.75,120) -- (260.75,144) ;


\draw (61,42) node [anchor=north west][inner sep=0.75pt]   [align=left] {$S_{TE}$};
\draw (62,114) node [anchor=north west][inner sep=0.75pt]   [align=left] {$TE$};
\draw (130,42) node [anchor=north west][inner sep=0.75pt]   [align=left] {$S_{TE'}$};
\draw (136,115) node [anchor=north west][inner sep=0.75pt]   [align=left] {$C$};
\draw (207,43) node [anchor=north west][inner sep=0.75pt]   [align=left] {$S$};
\draw (201,112) node [anchor=north west][inner sep=0.75pt]   [align=left] {$TE'$};
\draw (131,158) node [anchor=north west][inner sep=0.75pt]   [align=left] {Unix};
\draw (114,193) node [anchor=north west][inner sep=0.75pt]   [align=left] {Hardware};
\draw (392.75,157) node [anchor=north west][inner sep=0.75pt]   [align=left] {Python};
\draw (411.75,193) node [anchor=north west][inner sep=0.75pt]   [align=left] {C};
\draw (358.75,61) node [anchor=north west][inner sep=0.75pt]   [align=left] {optimise\_code()};
\draw (379.75,101) node [anchor=north west][inner sep=0.75pt]   [align=left] {AST\_utils};


\end{tikzpicture}
 }
\caption[Innovation feedback at the inter-process vs. intra-process scope]{Software innovations within a Unix system (left) cannot feed back into its hardware platform. However, the software innovations can feed into each other: a text editor $TE$ edits its source code $S_{TE}$. This new source $S_{TE'}$ is put through the compiler $C$ to create an improved text editor $TE'$, which can edit not only the source code $S$ of other programs but also its own. In a Python system (right), Python innovations can assist in the Python world but cannot feed back to assist with the C implementation of Python.}
\label{fig:innovation-feedback}
\end{figure}

When put this way, it sounds obvious; of course computer software is
used to improve computer software. Yet how different it is at the
intra-process scope: the very same text editor \emph{on its own} cannot
compile its improved replacement. A Python interpreter written in C may
empower us to create useful Python functions, but to improve the
interpreter itself we need to inhabit the world of C, in which our
Python functions are unavailable. Figure~\ref{fig:innovation-feedback}
contrasts this situation with innovation feedback in Unix.

From our presentation, it may appear that self-sustainability is a
peculiar special case that is naturally hard to achieve. Yet the world
of software as a whole is self-sustainable, as is an individual Unix
system. We conjecture that self-sustainability is a natural default that
was \emph{prevented} by the historical contingency of Unix enforcing
Batch-Mode assumptions on intra-process programming. Nevertheless, we
accept the Unix Paradigm as a given, and accomplish the tasks of this
dissertation on that basis.

\hypertarget{notational-freedom}{\subsection{Notational Freedom}\label{notational-freedom}}

In Section~\ref{precursors-of-notational-freedom} we mentioned the maxim
``Use The Right Tool For The Job''. This is a noble aspiration, but one
that is not currently fulfilled. At the ``large scope'' of the Unix
paradigm, there is a vast array of programming languages specialised for
different jobs. Yet we saw some barriers to Polyglot Programming, such
as the need for inter-process communication. As we scale down to
\emph{within} a single process and forego inter-process communication,
data sharing between languages gets thornier
(Section~\ref{polyglot-programming}).

The ideal is where a component at any scale can be expressed in a
\emph{notation} that is particularly suited to it. Here, we will define
the lesser stages of \emph{syntactic} and \emph{linguistic} freedom
before arriving at full notational freedom.

\hypertarget{caveat-on-subjective-value-judgements}{\subsubsection{Caveat on Subjective Value
Judgements}\label{caveat-on-subjective-value-judgements}}

Before proceeding, it is important to stress the fact that Notational
Freedom is about supporting \emph{subjectively} appropriate notations.
To explain the concept, we will give some examples of notations and
judge them as better, worse, convenient, unwieldy, and so on. When we
make these judgements, we are not claiming them as objective facts; nor
are we even claiming them subjectively across all possible use cases. We
are simply giving concrete examples of \emph{possible} preferences and
using these to illustrate our points. That being said, we have not
chosen these examples at random: they are in line with our preferences
and plausibly shared by others. If the reader does not share the
preferences in these examples, a hypothetical reading may be useful
(``\emph{supposing that} a programmer had such a preference\ldots'').
With this in mind, we will turn to the first step of \emph{syntactic
freedom.}

\hypertarget{syntactic-freedom}{\subsubsection{Syntactic Freedom}\label{syntactic-freedom}}

We noted in Section~\ref{precursors-of-notational-freedom} that, within
a single file, combinations of different languages are occasionally
possible. Yet these are fixed sets, pre-approved by language designers
and set in stone for all contexts and users. We could call this property
\emph{syntactic\footnote{Programming languages differ by semantics as
  well, but for Notational Freedom we are only interested in the surface
  notational aspects. Infrastructure for supporting this would already
  be close to supporting freedom of semantics, as shown by \ac{COLA}'s
  mood-specific languages.} diversity}, where a language named A
additionally permits syntaxes B, C, and D in certain situations. This
goes a small way towards ``\URTFJ'', but what is conspicuously missing
is the ability for the \emph{programmer} to decide which syntaxes to
use, and where, based on their local context.

This would be syntactic \emph{freedom} beyond pre-approved diversity. It
is not unreasonable to expect that a single function, or perhaps even a
single line of code, might be best expressed in a different language to
the rest of the code, in a way that the language designer cannot
anticipate.

We will use a running example as we build up through the stages to full
Notational Freedom. A common occurrence in scientific or graphics
programming is a few lines of mathematical operations. It would be
convenient to bring these closer to familiar mathematical notation
instead of an unwieldy ASCII approximation. Suppose we start with the
following notation for a formula:

\begin{verbatim}
vec_a.mul(cos(ang_b/2))
     .add(vec_b.mul(cos(ang_a/2)))
     .add(vec_a.cross(vec_b))
\end{verbatim}

Syntactic freedom would mean being able to see this situation and
specify a local syntax that lets us rewrite it as:

\begin{verbatim}
cos(ang_b/2) vec_a + cos(ang_a/2) vec_b + vec_a × vec_b
\end{verbatim}

\joel{
It could be objected that using `+` instead of `.add()` is already supported in some languages, such as C++ with its operator overloading. We would then point to the `×` Unicode character and ask for a language that permits this infix operator. We might be met with Haskell, famous for its arbitrary user-defined infix operators that may include Unicode symbols. In this case we would point at the juxtaposition of the two parts of the first term to denote multiplication. Are there any languages that permit overloading of whitespace as an infix operator? Supposing there were, there would be other cases for other problem domains where piecemeal allowances in what can be overloaded is not enough. Custom glyphs or even the symbols available in \LaTeX{} but not in Unicode could suffice as an example, but we will not belabour this further.}

Languages provide specific, limited freedoms in this regard; consider
C++'s operator overloading or Haskell's arbitrary infix operators.
However, these specific facilities do not amount to full syntactic
freedom.

We are aware of true syntactic freedom in two places: \ac{COLA}'s
\acfp{MSL} and Lisp's Reader Macros. This is a significant step in the
right direction, but the syntax of strings as defined by formal grammars
has limitations. It can only see two directions (left and right) and has
no notion of display variations like typefaces, weights, sizes, colours
and so on. This encourages us to edit expressions as lists of characters
without support for nested boxes or other interfaces that can be useful.
In other words, it keeps us in the text editor interface with its
Implicit Structure and associated problems (see
Section~\ref{explicit-structure} below). If we go on to lift these
restrictions, we arrive at \emph{linguistic} freedom.

\hypertarget{linguistic-freedom}{\subsubsection{Linguistic Freedom}\label{linguistic-freedom}}

By this, we mean freedom to represent expressions as arbitrary written
\emph{language} rather than restricted \emph{syntax.} In the physical
world, written language takes many forms which are hard to digitise in
their full detail---we don't expect our personal handwriting to be
adopted as an internationally-recognised font. Yet even in computing,
written language takes a variety of forms and supports a variety of
display characteristics. In programming, these are stripped away and we
generally only have formatless \emph{syntax} to work with.\footnote{Technically,
  syntax highlighters make keywords bold and add various colours, but
  these are fixed rules applying to display only. The point is that it
  is not possible to create a ``bold variable'' or a ``red function''.}

In our running mathematical example, there is a very good illustration
of the step up to linguistic freedom in the form of publishing-standard
mathematical notation (and conveniently for this document, a core
capability of \LaTeX):

\[\cos\left(\frac{b}{2}\right)\mathbf{a} + \cos\left(\frac{a}{2}\right)\mathbf{b} + \mathbf{a} \times \mathbf{b}\]

This exhibits the following improvements (from the perspective of
established norms in mathematical notation) that do not fit into the
``syntax'' technologies:

\begin{itemize}
\tightlist
\item
  Vertical layout of fractions
\item
  Replacing the \texttt{vec\_a} and \texttt{ang\_a} with \(\mathbf{a}\)
  and \(a\), distinguished by weight
\item
  No restriction to fixed-width characters or spaces
\end{itemize}

Beyond these display characteristics, it also leaves open the
possibility of an editing interface not restricted to
character-by-character string operations. For \LaTeX{} mathematics, we
must often write verbose textual source in the manner of
Section~\ref{syntactic-freedom}`s example and render it into the better
notation. Yet there do exist interfaces for editing mathematics more
directly, such as those in MS Word, Mathcha\footnote{\url{https://www.mathcha.io/}},
Desmos\footnote{\url{https://www.desmos.com/}}, and Wolfram
Alpha\footnote{\url{https://www.wolframalpha.com/}}. Linguistic freedom
permits such ``structured'' or ``projectional'' editing as an option.
This brings to mind JetBrains' MPS~\parencite{MPS} and
Eco~\parencite{Eco} as the only systems of which we are aware that offer
Linguistic Freedom.

For our running example, we have plausibly reached the Right Tool For
The Job at this point. In general, however, we still regard ``language''
as too narrow of a constraint. By this, we simply mean notations that
consist of repeated glyph shapes laid out in a (mostly) linear manner.
This is different to other uses of the term: ``visual language'' may not
include text at all, but uses the ``language'' term for the arbitrary
arrangement of elements. Under this latter meaning, the ``mood-specific
language'' idea has all the generality it deserves. Nevertheless, in
programming, we think the term ``language'' runs the risk of mentally
excluding graphical or interactive possibilities. To ensure they remain,
our use of the word ``language'' will stick to denoting mostly-linear
renderings of glyphs and we shall use words like ``notation'' or
``interface'' for the fully general extension.

\hypertarget{full-notational-freedom}{\subsubsection{Full Notational Freedom}\label{full-notational-freedom}}

Here, we wish to have unrestricted support for graphics and interaction.
In our mathematical example, full notational freedom would support an
interactive 3D visualisation of the vectors involved if that was what
the programmer desired. Language isn't everything---diagrams and
pictures are sometimes the form in which a problem or solution is
delivered, and programmers ought not to be forced to describe pictures
using words. We are only aware of one programming system that embodies
full Notational Freedom, the Eco multi-language editor~\parencite{Eco}.

We should emphasise that we are using the terms ``notation'' and
``interface'' interchangeably; we are not just talking about static
pictures but dynamic entities on a screen. The ``text editor'' interface
is one such example. One could use a text editor to work on the hex code
\texttt{0xff00ff} representing the colour magenta. Alternatively, one
could use a colour picker interface.

The key thing is that this property is called Notational \emph{Freedom},
rather than something like ``Optimal Notation''. We recognise that
different notations suit different purposes and respect the art of
developing them as a separate area of expertise, which we do not claim
for ourselves. The idea is to support the \emph{subjective} productivity
of the programmer, who we assume is best equipped to judge the
appropriateness of notations for herself. This property is about
\emph{supporting} the usage of different notations for different
contexts.

\hypertarget{what-it-means-to-support-local-notations}{\subsubsection{What It Means to ``Support'' Local
Notations}\label{what-it-means-to-support-local-notations}}

It is true that there is no such thing as a free lunch; we do not go so
far as to suggest that the system should turn a natural language
description into a working interface (recent advances in AI
notwithstanding). So long as the programmer is willing to do the
necessary work to program a new notation---such as writing a grammar,
specifying the layout of symbols, or implementing the rendering and
input handling for an interface---this should suffice to use it in
harmony with all the other available notations.

However, the Unix Paradigm and text editors impose an \emph{additional}
``tax'' in terms of effort beyond this reasonable standard. In the best
case, there may be some plugin architecture, while at worst it may
require forking the editor's source code. The actual work involved in
creating the notation might be very small, but it will be dwarfed by the
task of getting the editor to accept it. Notational Freedom does not
come by default, and most editors and programming systems are not
designed with it in mind.

A system with Notational Freedom is designed \emph{without} the
assumption that there will only be one notation and lacks these taxes to
the extent possible. In short, by ``support'' we mainly mean the removal
of artificial \emph{barriers} that have been put in the way of
mood-specific notations.

\hypertarget{explicit-structure}{\subsection{Explicit Structure}\label{explicit-structure}}

As we remarked in Section~\ref{precursors-of-explicit-structure},
Explicit Structure refers to the sense of working with data
\emph{directly} rather than through some other medium. To go into more
detail, it will be useful to split the life-cycle of a data structure
into two halves:

\begin{itemize}
\tightlist
\item
  On the \emph{producer side}, the data structure is created or edited
  using some interface.
\item
  On the \emph{consumer side}, a programmer is writing code that uses
  the data structure.
\end{itemize}

Explicit Structure is hard to define positively because it is the
default state of affairs across much of computing, with programming
being the notable exception. On the producer side, explicit structure is
exhibited by a vector graphics editor like Inkscape: one simply draws a
diagram with shapes and saves it as a file. On the consumer side,
Explicit Structure looks like a programmer navigating through named
parts of the diagram structure:

\begin{verbatim}
svg.root_nodes[1].children[2].fill_color = '#ff00ff';
\end{verbatim}

Explicit Structure is perhaps easier to define negatively, as a
\emph{lack} of Implicit Structure. Implicit Structure is present when we
use \emph{plain text} (or Qualitative Syntax more generally, as in
null-terminated C strings) as a communication or storage medium: the
structure can only be navigated after parsing the string. The problem
with plain text is that it fuses together two independent concepts: what
we could call \emph{presentation} (how one reads and modifies the data)
and \emph{representation} (how the data is stored in memory or on disk).
For example, the AST of a program \emph{could} be stored in its tree
form and \emph{presented} as indented text. But what we do instead is
serialise the text, store that, and parse it back before we are able to
work with it.

In our work, we approach the default Implicit Structure of programming
with skepticism. We direct the reader to the fuller arguments from the
authors of Subtext~\parencite{Subtext} and Infra~\parencite{Infra}, but
we will summarise the most important points here and offer some of our
own.

\hypertarget{language-can-be-stored-differently-to-a-character-list}{\subsubsection{Language Can Be Stored Differently to a Character
List}\label{language-can-be-stored-differently-to-a-character-list}}

Language always contains \emph{structure}: English paragraphs contain
sentences, containing clauses, containing words. Natural language, like
English, is typically entered into a digital medium only to be poured
out again at some other end, like photo uploads; normally, the computer
does not need to dive into the structure at all. On the other hand, for
programming languages, the Abstract Syntax Tree structure is the entire
point.

Despite this, programming language source code is universally stored as
a sequence of characters, rather than as the tree or graph that it
represents. This has the downside that every program that consumes or
transforms the code must recover (parse) this structure out, discovering
any mistakes only at this point of consumption (since these were just
recorded with the other characters). This is comparable to storing
vector graphics diagrams as arrays of pixels and using Computer Vision
to haphazardly recognise shapes and lines: unnecessary work to recover
information that was thrown away at creation time.

More unfortunate work results from having to ``escape'' characters that
have been reserved to denote structure instead of their literal selves.
In the worst case, the storage of language as character lists is largely
responsible for the class of attacks known as SQL injection. This would
not be possible with SQL commands represented as trees containing holes
to be filled with user-submitted strings.

Consider the common practice of embedding SQL commands in the source
code of various languages. In C\#, these are forced into the syntax of
the host language as ``embedded queries'', yet a programmer may prefer
to use SQL syntax directly as part of the source. The traditional
path-of-least-resistance to achieving the latter was to have SQL code
inside program strings, which created significant security risks. This
is by no means intrinsic to having SQL source be what the programmer
\emph{types} or \emph{sees;} it is entirely possible to combine a text
editing user experience with an explicitly structured in-memory or disk
representation.

\hypertarget{digital-plain-text-is-not-inherently-human-readable}{\subsubsection{Digital ``plain text'' is not inherently
human-readable}\label{digital-plain-text-is-not-inherently-human-readable}}

This argument is made best in \cite[p.\ 14]{Infra} which deserves
quoting here:

\begin{quote}
The critical observation is that software infrastructure is heavily
involved in supporting the human-readability of text. It is not the case
that the bit sequences of UTF8 or any other text encodings are somehow
intrinsically understandable to a human. An application interprets the
bytes as character codes as per a known standard, which are mapped to
glyphs in a font, and rendered to a grid of pixels. This chain of
interpretation and transformation starts with clusters of electrons and
ends with clusters of photons before the human nervous system takes
over. The point being that there is still a necessary software layer
performing a transformation in the middle.
\end{quote}

\begin{quote}
electrons \(\rightarrow\) bits \(\rightarrow\) charactercodes
\(\rightarrow\) glyphs \(\rightarrow\) pixels \(\rightarrow\) photons
\end{quote}

\begin{quote}
``Human readability'' just colloquially implies that it is a standard
encoding understood by most text editors. The sense of inherent
readability merely comes from the ready availability of tools that
render ASCII and Unicode. One can assume that a text editor or some text
rendering infrastructure exists in the target system. Therefore, any
encoding could technically achieve the same `human readable' status as
ASCII if it and its editors were general-purpose enough to warrant an
equally ubiquitous install base. Thus, there is an opportunity to expand
or upgrade the realm of what can be considered human readable.
\end{quote}

It can be tempting to defend text files as human-readable in contrast to
binary files which are not. However, as Hall's argument shows, this is
mere \emph{status quo} bias: all of the ``human-readability'' of a text
file is due to the wide availability of text editors. Few can read text
through a binary or hexadecimal rendering of character codes, which is
the basis on which a fair comparison with ``binary files'' must be made.
By the same criteria, binary PDF files are human-readable owing to the
ubiquity of PDF readers. In other words, the difference between plain
text and ``binary'' data is not so much an essential difference of two
kinds but simply a difference in tool availability.

\hypertarget{we-study-the-spherical-cow}{\subsubsection{We Study the Spherical
Cow}\label{we-study-the-spherical-cow}}

Text usually functions as a \emph{medium} or rendering of something that
is not inherently text. In the first place, text was invented to record
speech made by human beings. In programming, text is used as a
\emph{proxy} for a nested tree-like structure, but is \emph{not the
structure itself.}

To study a programming idea like self-sustainability, it is unfortunate
to have the accidental complexities of text representation ``getting in
the way'' of studying the idea itself. Even though a real-world
programming system may use text, we wish to avoid this obscuring layer
for much the same reason as a physicist studies a frictionless sphere in
a vacuum instead of a cow in a field. We want to not be distracted with
air resistance and complex shapes, so as to focus on the property we are
interested in; future work can then add the practical complexities back
in again for a more realistic model. In short, we study
Self-Sustainability and Notational Freedom \emph{directly} as properties
of interactive graphical systems, and Explicit Structure is necessary
for this.

\hypertarget{conclusions}{\section{Conclusions}\label{conclusions}}

There are systems that exhibit one or two of our Three Properties, but
each has shortcomings. Infra~\parencite{Infra} and
Subtext~\parencite{Subtext} thoroughly exploit Explicit Structure; the
former develops the other two properties to a small extent, while the
latter leaves them out of scope. Eco~\parencite{Eco} supports Notational
Freedom, but as an editor, does not form a complete programming system
and lacks self-sustainability. JetBrains' MPS~\parencite{MPS} possibly
goes the furthest in promising Linguistic Freedom atop a base of
Explicit Structure, and is even partly developed using itself as
evidenced by its GitHub language metrics. However, MPS has the
considerable resources of a software company behind it and is designed
to be industrially viable. We think our Three Properties are, in
essence, small enough to be realisable by an individual for personal
use. In addition, we pursue a general technique for adding these
properties to a programming system that lacks them (Chapter~\ref{bl}).
Such a contribution could suit a wider range of contexts than a
requirement to use a specific existing system like MPS.

\ac{COLA}, by far the most important influence on the work in this
thesis, promises Self-Sustainability and restricted Notational Freedom
in the form of \acp{MSL}. However, \ac{MSL} support is presented in the
paper \parencite{COLAs} as a pipeline of traditional \emph{batch-mode
transformations} such as parsing, analysis, and code generation.
Similarly, it presents its bootstrapping process in terms of batch-mode
transformations of various source code files. This entrenches it in the
Implicit Structure of the Unix Paradigm
(Section~\ref{the-unix-paradigm}) which obscures the essential ideas
relevant to our purposes (recall
Section~\ref{we-study-the-spherical-cow}).

We would rather have the ability to gradually \emph{sculpt} a system
into a self-sustainable state, interactively, through a combination of
manual actions and automatic code. This requires that the system should
be conceived primarily through a graphical interface, yet the \ac{COLA}
design does not provide guidance in this respect. It is possible to see
how a \ac{COLA}'s various languages and components work together as a
sort of self-sustainable command-line \ac{REPL}, but less easy to see
how its text-centric approach may apply to arbitrary graphical
interfaces.

\ac{COLA} sketches a way to escape the intra-process scope of the Unix
Paradigm in a vehicle comprehensible to a single individual. Yet it only
does so in the framing of batch-mode stream transformations, which
limits its potential. We will refer to \ac{COLA} repeatedly for
inspiration and comparison and we will offer some analysis in terms of
our own concepts. However, we must adapt its approach to a basis of
Explicit Structure while retaining the essential ideas. This is the
topic of the next chapter.
\clearpage{}
\cleardoublepage
\clearpage{}\hypertarget{bl}{\chapter{BootstrapLab: The Three Properties in the Web Browser}\label{bl}}

\newtheorem{force}{Force}
\newtheorem{requirement}{Requirement}

\joel{
Having tried the "notation-first" approach with diminishing returns in Chapter\ \ref{year1}, we now turn our efforts towards prioritising self-sustainability. Recall that we took the "\OROM{}" half of the COLA design as our starting point and made things happen with plain JavaScript. This left us at the mercy of text strings as a starting point for building the "code" half.}

We now arrive at the main contribution of this work: the construction of
a programming system with our Three Properties, which we call
\emph{BootstrapLab.}\footnote{\url{https://github.com/jdjakub/BootstrapLab/tree/master/orom/computation}}
On its own, the existence of such a system acts as a constructive proof
of our Thesis Statement
(Section~\ref{thesis-statement-and-contributions}). However, we are less
interested in the fact that such a thing \emph{is} possible than we are
in \emph{how} it was done and what we can learn from the process. We
have discussed our Three Properties in previous chapters as best we
could while remaining in the theoretical realm, but since they are meant
to be properties of programming systems, it is essential that we give
practical experience an opportunity to teach us something about them
that we could not learn otherwise. We would expect not only to learn how
to \emph{achieve} such properties, but also to gain clarity on their
nature.

Thus, in this chapter\footnote{This chapter was adapted from our 2022
  \emph{Onward!} Essay entitled ``Ascending the Ladder to
  Self-Sustainability''~\parencite{Onward22}} we take the
self-sustainable \ac{COLA} as our inspiration and seek to build up to
its Lisp-like ``behavioural'' half by means of code with Explicit
Structure. We critically analyse its development process and identify
ideas that may apply more generally. This will lay the foundations for
creating new self-sustainable programming systems. We will have to wait
until Chapter~\ref{tech-dims} to evaluate BootstrapLab in terms of our
Three Properties, but we will summarise it in terms of Olsen's criteria
for user interface systems~\parencite{EvUISR} at the end of this
chapter.

What is presented here is not necessarily a chronologically accurate
account, but a \emph{rational reconstruction} of the steps involved. For
each step, we describe the general task at hand, illustrate this with
concrete decisions made in the implementation of BootstrapLab and, where
appropriate, sketch possible alternative decisions and their likely
consequences. In other words, it is a depth-first exploration of the
process with some alternative branches suggested along the way. It can
be understood on two levels:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  It tells the development story of a concrete system. BootstrapLab is a
  novel self-sustainable system, based on explicit structure, built on
  top of the web platform.
\item
  It presents a rational reconstruction of the logical steps needed to
  bootstrap a \emph{general} self-sustainable programming system (by
  taking BootstrapLab to be representative of the important parts of
  such a task). It highlights design \emph{forces} and \emph{heuristics}
  for resolving them which can be used by designers of future
  self-sustainable systems.
\end{enumerate}

\hypertarget{methodology}{\section{Methodology}\label{methodology}}

We follow in the spirit of \ac{COLA}, but we aim to bootstrap a
graphical and interactive self-sustainable system instead of a textual
one based on batch-mode transformations. The system should not have
barriers in the way of using custom notations. We also want to work with
an \emph{interactive} system, meaning that the user should be able to
modify the state of the running system through manual gestures and not
just programmatically.

This approach can better exploit the graphical and interactive
capabilities of modern computing, but it also sidesteps the tedious
accidental complexities of parsing and serialising text. Similarly,
making the system interactive will allow the user to better understand
the consequences of individual small changes and will, in turn, support
a virtuous cycle of self-improvement.

Our desire is to make an interactive, structured ``port'' of the
\ac{COLA} approach. This is unexplored territory. It must be emphasised
that finding the right ``final design'' upfront should not be necessary
and would defeat the spirit of the enterprise. The point is to build an
initial kernel which is then sufficient for evolving and improving
itself.

Unlike \ac{COLA}, we do not write an initial object system in a language
like C++. In order to support interactivity, structure, and graphics, we
begin with a platform that already conveniently supports those features.
This forms a suitable ``blank slate'' from which to gradually develop
the system into a self-sustainable state. At each stage, we take stock
of which changes can feasibly be achieved at the user level within the
system, versus those that can only be achieved at the implementation
level (recall Section~\ref{user-vs.-implementation-levels}). We then ask
ourselves: how can we imbue the user level with control over some of
these aspects?

The following sections propose key steps for evolving
self-sustain-ability in this way, informed by our actual experience
applying them in BootstrapLab. We will point out the \emph{forces} that
shape the design and the \emph{heuristics} by which we resolve competing
forces. As we proceed through the development journey, we will reflect
on the heuristics in light of actual practice and compare our choices
for BootstrapLab with the corresponding stages of two other systems:
\ac{COLA} and the Altair 8800 of the 1970s.

\hypertarget{concepts-and-terminology}{\section{Concepts and Terminology}\label{concepts-and-terminology}}

\tomas{It would be nice to include the diagram I sketched here (if we think it can be useful for explaining things...)}

Following the terminology in Section~\ref{platforms-and-substrates}, we
use the term \emph{product system} (or simply ``the system'') to refer
to the programming system that we evolve towards self-sustainability. We
use the \emph{producer system} (or simply ``producer'') to bootstrap the
product system. The producer is divided into two layers: the
\emph{platform} consists of all the pre-existing capabilities of the
producer, while the \emph{substrate} is the basis for the product system
that we have to build. We use the term \emph{in-system} to refer to
changes made within the product system, by using it as a programming
system at its user level. We also model the product system as having a
\emph{state} that \emph{changes over time} as we introduced in
Section~\ref{two-fundamentals-state-and-change}.

\joel{
This is necessarily the case for any interesting interactive programming system, regardless of its programming paradigm. Even in functional, declarative, reactive or logic paradigms, the evaluation or re-computation in response to interaction with a user produces a new (changed) state.

When discussing state, we refer to both the visible interface and the hidden internal state of the programming system. The state always consists of substructures such as byte arrays, object graphs or trees. Correspondingly, a change to the state can be decomposed into sub-changes that affect small parts of the state.^[It may be argued that a very high-level programming paradigm would make it impossible to affect only small parts of the state. This may, however, not be a suitable starting point for a self-sustainable system.] This gives rise to primitive *instructions* that describe state change at the finest level of granularity.
}

Recall the definition of \emph{bootstrapping} we gave in
Section~\ref{precursors-of-self-sustainability}. Our task is to explore
the question: how do we bootstrap \emph{interactive graphical}
self-sustainable systems? Note that by definition, what we do with a
self-sustainable system is open-ended. This chapter is solely concerned
with \emph{getting there} from the ordinary world, which is why we will
spend so much discussion on the design of the substrate. This determines
how the product system can evolve, how soon can it become
self-sustainable and to what extent.

\hypertarget{journey-itinerary}{\section{Journey Itinerary}\label{journey-itinerary}}

The rest of the chapter documents the steps involved in designing a
self-sustainable system. Be advised that the sequence is a
\emph{rational reconstruction.} The implementation of BootstrapLab
followed a more meandering path, but the following steps gesture at the
Platonically optimal pathway for bootstrapping a self-sustainable
programming system:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Choose a starting platform.} The platform is a
  \emph{pre-existing} programming system that we use to create and run
  the product system. The platform cannot be re-programmed, let alone to
  become self-sustainable, but it allows us to build a self-sustainable
  product system. To choose a platform, we consider its distance from
  desired substrate features and personal preference.
\item
  \emph{Design a substrate.} The substrate defines the basic
  infrastructure supporting the product system: how the state is
  \emph{represented} and \emph{changed}. The design of a substrate
  re-uses parts of the platform where possible and extends it where
  necessary. We must decide which platform capabilities to use to
  represent the state and how to expose graphics and interaction. We
  design a minimal \emph{instruction set} describing changes to the
  state, which can be represented using the state. We then use the
  platform to implement an engine that executes these instructions.
\item
  \emph{Implement temporary infrastructure.} Use the platform to
  implement tools for working within the substrate, most importantly a
  \emph{state viewer} or editor. These tools constitute a ``ladder''
  that we will pull up behind us once we have ascended to in-system
  implementations of these tools.
\item
  \emph{Implement a high-level language.} The substrate's instruction
  set (ASM) is cumbersome, so ensure programs can be expressed in-system
  via high-level constructs. Decide how to represent expressions as
  structured state and whether to \emph{interpret} or \emph{compile}
  them into ASM. Ideally, develop such an engine in ASM gradually and
  interactively. Alternatively, implement it at the platform level and
  later \emph{port} it to ASM or the high-level language itself.
\item
  \emph{Pay off outstanding substrate debt.} Port all remaining
  temporary infrastructure into the system, taking advantage of the
  infrastructure itself and the high-level language. The result is a
  \emph{self-sustainable} programming system.
\item
  \emph{Provide for domain-specific notations.} Use the self-sustaining
  state editor to construct a more convenient interface for editing
  high-level expressions. Add \emph{novel notations and interfaces} as
  needed. Use these not just for programming new end-user applications,
  but also to improve the product system itself.
\end{enumerate}

What we have here looks like a Waterfall development plan, each step
strictly following from the completion of the previous. This
presentation is convenient as a summary, but in practice, the sequencing
here need not be so rigid. Adjacent steps may overlap, or we may need to
prototype and revise a previous step in light of the result.

The general outline also resembles the discredited ``recapitulation
theory'' in biology, where in order for an embryo to develop into a full
organism, it passes through the evolutionary history of its ancestors.
In other words, for a \emph{particular} cell to develop into an animal,
it needs to fast-track its ancestors' evolution from a cell in the
distant past. While this has since been rejected in biology, it is a
good summary of what is going on in our project here.

For us, the bootstrapping of a \emph{particular} self-sustainable system
fast-tracks the historical development of computing's abstractions. It
begins at the low level and ascends through to higher-level languages,
each time building the next stage in the current one. This journey could
be seen as an attempt to \emph{reconstruct} programming on top of a more
structured, graphical substrate than the byte arrays we all had to use
the first time around. With that in mind, let us now proceed to the
first stage.

\hypertarget{choose-a-starting-platform}{\section{Choose a Starting Platform}\label{choose-a-starting-platform}}

\begin{quote}
The platform is a \emph{pre-existing} programming system that we use to
create and run the product system. The platform cannot be re-programmed,
let alone to become self-sustainable, but it allows us to bootstrap a
self-sustainable product system. To choose a platform, we consider its
distance from desired substrate features and personal preference.
\end{quote}

\tomas{I removed the "blank slate" phrase here, because the platform is not a blank slate at all (maybe - it is the "slate" itself? which is of course not blank because it is granite!)}

The first step is to choose the platform that we will use as the basis
for the product system. This could be any existing high-level or
low-level programming system. An important factor is simply personal
familiarity or preference for a particular platform. This plays a role
during bootstrapping, but is destined to become irrelevant once
self-sustainability is achieved.

The other major consideration is the primitives provided by the
platform. They influence how we can design the substrate on top of it in
the next step. If we begin with a high-level platform with many
convenient features (\eg{} graphics and audio capabilities), then we
will have to regard them as black boxes. We may expose them as
primitives in the product system, but we will not be able to
\emph{re-program} them in-system since we cannot re-program the
platform.

Alternatively, such imported convenient high-level features could later
be \emph{re-implemented} in the product using more basic primitives.
However, this would delay the point from which we can work fully
in-system. This foreshadows a coming design tension in the substrate
(Section~\ref{the-major-design-conflict}).

In the Altair 8800, the \emph{platform} comprised linear memory (state)
and native CPU instructions (state change). The platform did not provide
other tooling aside from switches to manually set memory values
(Figure~\ref{fig:altair}).

\begin{figure}
\centering
\includegraphics[width=8cm]{Altair-8800.jpg}
\caption[The Altair 8800 microcomputer]{The Altair 8800 microcomputer and its front panel of switches. \emph{Image credit: \parencite{Altair}.}}
\label{fig:altair}
\end{figure}

In \ac{COLA}, the platform is C~\parencite{OROM} or
C++~\parencite{COLAs} and the Unix command-line environment; in other
words, it is the Unix programming system
(Section~\ref{the-unix-paradigm}).

In BootstrapLab, we chose \ac{JS} and the Web platform. This provides us
with built-in Web technologies and libraries (including graphics) and
the browser developer tools. This platform provides a range of
convenient tools to assist bootstrapping. Because of its large scope, we
have to carefully choose primitives to expose to the product system.

\emph{What can be changed at the user level?} At this point, there is no
product system to speak of yet. This means that nothing can be changed
in-system. The platform can, in principle, be modified, but by
assumption this is so unfamiliar or uneconomical that the reader has
opted to make a self-sustainable system instead.

\hypertarget{design-a-substrate}{\section{Design a Substrate}\label{design-a-substrate}}

\begin{quote}
The substrate defines the basic infrastructure supporting the product
system: how the state is \emph{represented} and \emph{changed}. The
design of a substrate re-uses parts of the platform where possible and
extends it where necessary. We must decide which platform capabilities
to use to represent the state and how to expose graphics and
interaction. We design a minimal \emph{instruction set} describing
changes to the state, which can be represented using the state. We then
use the platform to implement an engine that executes these
instructions.
\end{quote}

With the \emph{platform} defined as the already-existing programming
system that we start from, we define the \emph{substrate} as the basic
infrastructure, implemented via the platform, necessary for the product
system. This substrate is the part of the system which we have control
over (being programmed \emph{by us}, unlike the platform itself) yet
which we do not expect to expose from within the system. In other words,
the substrate is the small non-self-sustainable core that supports the
self-sustainable product on top of it.

In short, our division is as follows:

\joel{
* *Platform*: not created by us, not self-sustainable.
* *Substrate*: created by us atop the platform, not self-sustainable.
* *Product*: created by us atop the substrate, self-sustainable.
}

\vspace{1em}
\begin{tabular}{ccc}
\toprule
 & Created by us? & Self-sustainable? \\
\midrule
Platform & No & No \\
Substrate & Yes, atop Platform & No \\
Product & Yes, atop Substrate & Yes \\
\bottomrule
\end{tabular}
\vspace{1em}

The design of the substrate can be considered along two axes
(Table~\ref{substr-tab}). The first dimension follows the distinction
between data and code, or \emph{state} and state \emph{change}
(Section~\ref{two-fundamentals-state-and-change}). We must first decide
how the \emph{state} of the system will be represented. Often, this is a
matter of choosing an appropriate subset of what the platform already
provides. Then, we decide how primitive \emph{changes} to that state can
be described and define the instruction set.

The second dimension follows the division between the \emph{computer}
and \emph{human} actors. The full state of the system will be an
internal data structure, but a \emph{part} of the state---comprising the
state of the user interface---can be directly seen by the user.
Similarly, \emph{change} can be performed automatically or manually.
There must be a way to run instructions automatically at a high speed,
but the user interface must also provide controls for a human to make
changes at their own pace.

\joel{
| Domain \\ Agent | Human (Manual) | Computer (Automatic) |
|:--------------:|:--------------:|:--------------------:|
|      State     | User Interface |    Data structures   |
|     Change     |   UI Controls  |     Instructions     |
}

\begin{table}
\centering\small
\caption{The conceptual divisions of the substrate.}
\begin{tabular}{c|cc}
\toprule
Domain \textbackslash{} Agent & Human (Manual) & Computer (Automatic) \\
\midrule
State & User Interface & Data structures \\
Change & UI Controls & Instructions \\
\bottomrule
\end{tabular}
\label{substr-tab}
\end{table}

While the foregoing model applies to programming systems generally, a
special condition is required for those that are self-sustainable. We
must represent instructions as pieces of state, as opposed to having
``two types of things''---ordinary data, and code---which must be viewed
and edited using completely different tools. This property,
conventionally known as \emph{homoiconicity}, means instructions can be
generated and manipulated just like ordinary state, whether
programmatically or manually. Only if this is possible can higher-level
abstractions be built up, in-system, from the low level.

\joel{Isn't homoiconicity basically just von Neumann instead of Harvard architecture? any difference?}
\begin{requirement}[Homoiconicity]
Instructions must be readable and writeable as ordinary state.
\end{requirement}

\hypertarget{s-low-level-byte-arrays}{\subsection{\texorpdfstring{\acs{COLA}'s Low-Level Byte
Arrays}{'s Low-Level Byte Arrays}}\label{s-low-level-byte-arrays}}

In \ac{COLA}, the substrate is quite minimal and the majority is
inherited ``for free'' from the low-level runtime environment provided
by Unix (Section~\ref{the-low-level-binary-world}).

At the lowest level, state in \ac{COLA} consists of an array of bytes,
addressed numerically. Some structure is imposed on this via C's
standard memory allocation routines, refining the model of state to a
graph of fixed-size memory blocks and the stack. Changes to this state
are represented as machine instructions encoded as bytes. This is the
basic state model of a C program; the sample code for \ac{COLA}
embellishes this with little more than a way to associate objects to
their vtables\footnote{A \emph{vtable} specifies object behaviour by
  supplying runnable code for a requested method name. It is separate
  from the object ``instance'' so that multiple objects can share the
  same behaviour.} and a cache for method lookups.

This bare-bones, low-level substrate does not require much development
on top of the platform and so it is quicker to complete. The ontology of
state is copied from the platform, and in this case the machine
instructions can be inherited too.\footnote{In general, the internal
  representation of code in the platform will be unavailable to us when
  programming with it, so we expect not to be able to inherit it. This
  low-level platform is a special case, where we do have access to code
  if we are willing to write instructions using their numerical codes.}
Completing the substrate more quickly means we can start working
in-system sooner, but there is a downside: it may be cumbersome to work
with such minimal functionality. The unfortunate effect would be that we
speed through a primitive substrate, only to suffer slow progress at the
beginning of in-system development.

Building back up from machine-code level may be an impressive hacker
achievement or useful for pedagogy~\parencite{Mu}. But it is clearly not
optimal, speed-wise, when we already have a higher-level platform to
program with.

In the other direction, there is no limit to how fancy we could make the
substrate in terms of high-level abstractions and convenient features.
However, these would take much longer to implement and delay in-system
development. Moreover, this risks doing a lot of work that can never
benefit from in-system innovation feedback (recall
Section~\ref{the-key-benefit-innovation-feedback}); the substrate's
implementation will not be modifiable from within the system it
supports.

\hypertarget{the-major-design-conflict}{\subsection{The Major Design Conflict}\label{the-major-design-conflict}}

We clearly have two opposing tendencies here, which we will formalise as
follows:

\begin{force}[Avoid Boilerplate]
\label{avoid-bp}
Push complex features into the substrate to avoid wasting in-system development time on them.
\end{force}

\begin{force}[Escape The Platform]
\label{escape-plaf}
Push complex features in-system to avoid delaying in-system development and to have them benefit from innovation feedback.
\end{force}

We will refer to these throughout the journey. They conflict over where
the implementation of convenient functionality should reside. In any
specific design, they will resolve in some compromise. It is helpful to
consider the extreme points of this.

Force~\ref{escape-plaf} wants to get the substrate over with as quickly
as possible, eager to escape the (real) limitations of the platform and
get working in a system that \emph{can} be arbitrarily changed.
Force~\ref{escape-plaf}, left unchecked, will guide us to adopt a
substrate resembling a Turing machine: have a tape for the state;
instructions for manually shifting left and right, reacting to the
current symbol, and writing a new one; have a user interface in which to
do these things manually. Such a substrate is so simple it could be
coded in an hour or two. Yet our first duties in-system will be to
implement extremely basic features, like data addressing and arithmetic,
in an extremely tedious way. The endpoint of Force~\ref{escape-plaf} is
the Turing Tarpit.

On the other hand, if we follow Force~\ref{avoid-bp} unchecked, we spend
much time and effort working with the platform to produce, in effect, a
\emph{complete} novel programming system. Any feature we would find
useful in-system, we would have already implemented outside it. Yet this
means that all the important functionality could not be changed except
by going back to the source code in the platform; we'd have created a
boring old \emph{non-}self-sustainable programming system. The endpoint
of Force~\ref{avoid-bp} is programming-as-usual.

A symptom of the latter failure mode would be that we never felt
comfortable leaving the platform behind and continuing development from
within the system. Self-sustaining systems are meant to be \emph{grown}
from a small enough starting point; we shouldn't need to come up with a
flawless design ahead of time. This will only be possible if we artfully
balance Forces~\ref{avoid-bp} and~\ref{escape-plaf} so that the
in-system programming experience becomes tolerable in a reasonable
timeframe.

\paragraph{Reflections on the Machine-Level Approach.}

We experienced something like the Force~\ref{escape-plaf} absurdity for
\ac{COLA} when following the sample C implementation of its object
system. The code was easy enough to comprehend and compile, but what we
were left with was a system living entirely in memory lacking even a
command-line interface. In order to develop the system, it seemed
necessary to run it in a machine-level debugger.

\tomas{I wonder though if this is partly over-simplicity on the platform level, not substrate?}

Even if we had stayed with it, we would still be stuck in the low-level
binary world which is unfriendly for humans to work with, as we
explained in Section~\ref{the-low-level-binary-world}. Instead of names,
we only have numbers for addressing things. The state is flat and we
cannot insert or grow something without physically moving other content
to make space. Any structure, such as trees or graphs, has to be
\emph{faked} as memory blocks pointing to each other.

This type of substrate is still better than a Turing machine, and was a
historical necessity in the early days of computing. But nowadays, we
have the opportunity to leave this behind, and instead build new systems
on top of a ``low level'' that is nevertheless \emph{minimally}
human-friendly (Section~\ref{the-minimally-human-friendly-world}).

\begin{heuristic}[Minimally human-friendly low-level]
\label{min-friendly-ll}
Ensure the substrate natively supports \emph{string names} and \emph{substructures.} This is a minimal response to Force\ \ref{avoid-bp} that still keeps the substrate simple enough and thus does not strongly conflict with Force\ \ref{escape-plaf}.
\end{heuristic}

\hypertarget{bootstraplabs-simple-structured-state-model}{\subsection{BootstrapLab's Simple, Structured State
Model}\label{bootstraplabs-simple-structured-state-model}}

For the design of BootstrapLab, we chose the Web platform and \ac{JS}
for personal preference reasons. This imposed a number of design
decisions on the substrate, due to a tendency for earlier choices to
determine which later ones will feel ``natural'' or ``fitting''.

In our high-level platform language \ac{JS}, state is a graph of plain
\ac{JS} objects acting as property dictionaries. Suppose we \emph{still}
chose a low-level binary substrate like that of \ac{COLA}. This would no
doubt be possible: declare one giant \ac{JS} array called
\texttt{state}, design numerical instruction encodings which overwrite
numbers at certain indexes, etc. Yet this would feel like a perverse
\emph{waste} of something the platform was giving us for free.

\ac{JS} already provides the basic human affordances of naming and
substructure, so why would we throw them away and force ourselves to
implement them in-system? The low-level \ac{COLA} substrate does
plausibly follow from its base C platform; our choice of \ac{JS} as the
platform encourages us to preserve \emph{its} own state model in the
substrate we design.

Similarly, it would make no sense to represent instructions as numbers
or strings. While in the binary world, machine instructions are byte
sequences with bitfields for opcodes and operands, in a dictionary
substrate inherited from \ac{JS}, it makes sense to have explicit fields
for this data:

\begin{verbatim}
{
  operation: 'copy',
  from: [ alice, 'age' ],
  to: [ bob, 'age' ]
}
\end{verbatim}

As this example shows, addresses in a dictionary-based state model
consist of an object reference and a key name.

This ``preservation'' incentive pervades the journey from platform to
product system. The substrate should leverage representations made
possible by the platform, while the instruction representation should
leverage the structuring of state provided by the substrate. This will
also apply to further subdomains expressed in the state model, such as
graphics and high-level programming expressions. We formalise this as
the following:

\begin{force}[Alignment]
\label{alignment}
Everything should \emph{fit}: instructions, high-level expressions, and graphics expressions should all fit the substrate, and the substrate should fit the platform.
\joel{Violation \eg{} flat array as state via JS, fails to preserve a feature. Ideally, this force propagates all features from A to B.}
\joel{Call this "preservation"?}
\end{force}

In the end, our substrate largely inherits the state model, only making
simplifications. For example, \ac{JS} objects have prototypal
inheritance, meaning that a simple ``read'' operation of a property
requires potentially traversing a chain of objects. Our substrate here
omits this, so reads are quite simple. Additionally, \ac{JS} includes a
special \texttt{Array} object type. We omitted this, opting to represent
lists as maps\footnote{We refer to our substrate's basic dictionary
  structure as the \emph{map} for brevity.} with numerical keys. This
unification means that the state model only has one type of composite
entity, a fact we will exploit later for the high-level language.

We also noticed that we would not get very far if all our progress
in-system could be wiped clean by losing our browser tab. Our platform,
sitting within the Unix paradigm (Section~\ref{the-unix-paradigm}), does
not provide \emph{persistence} out of the box, so we had to implement a
mechanism in the substrate. We walk the state graph from the root node
and discover a spanning tree, specially marking cyclic or double-parent
references. We then serialise this into a JSON file which we can load by
undoing the process. This is reminiscent of the image-based persistence
in Smalltalk, though it is frustratingly manual. Nevertheless, it was
critical to patch this unfortunate aspect of the platform and this was
enough to do so.

Even though \ac{JS} is a high-level language, we consider this substrate
low-level \emph{relative} to the platform below it. Force~\ref{avoid-bp}
gave us several ideas for convenient features of a smarter state model,
but Force~\ref{escape-plaf} urged us to press ahead without them and see
if we needed them later. Appendix~\ref{bl-trivia} contains these
details.

\hypertarget{designing-the-instruction-set}{\subsubsection{Designing the Instruction
Set}\label{designing-the-instruction-set}}

While the ``data'' half of the substrate may be easy to inherit from the
platform, the ``code'' half is typically not. Simply including an
interpreter for source code in \ac{JS} is not an option; this would
embed a reliance on a strings and parsing in the core of the system,
against our desire for Explicit Structure.

Slightly better would be an interpreter for the \ac{JS} abstract syntax
tree. However, Force~\ref{escape-plaf} still pushes against this. A
high-level language interpreter is nontrivial even without parsing and
would delay our ability to work in-system. Also, an interpreter is a
computer program; this program, or parts of it, might be best expressed
or debugged via particular notations; by having it in the substrate,
we'd restrict ourselves to the interface of \ac{JS} in our text editor.

Instead, consider what it takes to implement the interpreter for
Assembler, a.k.a. the Fetch-Decode-Execute cycle. We fetch the next
small change to make to the state (an instruction). We do a simple
case-split on the opcode field; we carry out some small change to the
state; rinse and repeat. With this, we can surely mirror the real-world
development of higher-level languages from lower ones.

\begin{heuristic}[Use Imperative Assembler]
\label{use-asm}
Begin from imperative assembler, as this allows us to make arbitrary changes to the state using a minimal interpreter that is quick to implement. Force\ \ref{escape-plaf} outweighs Force\ \ref{avoid-bp} here.
\end{heuristic}

It is important to stress that this ``assembler'' is relative to the
form of the substrate. If the substrate is binary memory, ``assembler''
will refer to machine instructions. But in our case of a minimally
human-friendly low level (Heuristic~\ref{min-friendly-ll}), there is
nothing binary about them. The instructions express operations on
structured objects with names and are, themselves, represented as
structured objects with names. Similarly, ``imperative'' just refers to
the fact that the instructions are arranged in a sequence from the point
of view of the interpreter, because it is easier to implement a
fetch-execute cycle than, say, a resolver for a dependency graph. The
above considerations lead us to Heuristic~\ref{simple-asm}.

\begin{heuristic}[Simple Assembler]
\label{simple-asm}
Prefer fewer instruction types (RISC) over more (CISC). This reduces the size of the interpreter and will be quickest to implement. It will make programs longer, but this can be mitigated by a high-level programming language. Force\ \ref{escape-plaf} outweighs Force\ \ref{avoid-bp} here too.
\end{heuristic}

Right away, we know there will have to be a special piece of state for
the \emph{instruction pointer}. This could indicate the \emph{current}
instruction or the \emph{next}; we chose the latter for BootstrapLab and
called it \texttt{next\_instruction}.

The value of this ``register'' is determined by how exactly we fetch the
next instruction. Perhaps each one has a \texttt{next} field which we
can simply follow. In this case, the \texttt{next\_instruction} will
simply be the instruction itself. This also gives us convenient
conditionals (\eg{} fields called \texttt{if\_true} and
\texttt{if\_false}) but means that instruction \emph{sequences} will
have a nesting structure. This latter consequence may be inconvenient
for presentation in a tree view. For BootstrapLab, we chose the
alternative of numerically indexed lists of instructions which easily
display in a column. This choice determined \texttt{next\_instruction}
to instead hold an \emph{address} made of container map and key name:

\begin{verbatim}
next_instruction: {
  map: <instruction list>,
  key: 1 // i.e. first instruction in the list
}
\end{verbatim}

Here, the ``fetch'' step involves dereferencing the address and then
incrementing the key name.

Next, we turn to what types of instructions we need. Alignment
(Force~\ref{alignment}) means that, given a state model, obtaining an
instruction set should be more of a ``derivation'' than a hard design
problem. This is because some choices are obviously inappropriate and
others clearly fitting to the state model. For example, in a
tree-structured state model, it would be foolish to have instructions
that can only see the root level:

\begin{verbatim}
{op: 'copy', from: 'source_key', to: 'dest_key'}
\end{verbatim}

Without the ability to read or write keys \emph{within} an arbitrary
tree node, as far as programmatic change is concerned, the state becomes
a \emph{de facto} flat list instead of a tree. Therefore, it is critical
that anywhere in the state can be accessed or modified by an appropriate
instruction sequence.

The checklist of basic functions for an instruction set to be
Turing-complete is as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Copy from one location to another (a ``literal'' is just copied from
  the instruction itself)
\item
  Treat a value as an address and follow the reference
\item
  Unconditional jump (copy a value to the instruction pointer)
\item
  Conditional jump (take a path based on a runtime condition)
\end{enumerate}

Force~\ref{avoid-bp} may push us to include basic boilerplate like
arithmetic or an operand stack. Furthermore, it is advisable to have an
``escape hatch'' into the platform if possible. In BootstrapLab, our
platform language \ac{JS} provides the \texttt{eval()} function to
execute a string of \ac{JS} code. We exposed this as a \texttt{js}
instruction. This allows us to use and store \ac{JS} code in the
\emph{running} system instead of having to edit the source file.

The resulting instruction set for BootstrapLab was derived from these
considerations, as well as extreme application of
Heuristic~\ref{simple-asm}. It uses the top-level map as a set of
``registers'' whose contents are \emph{immediately} accessible. State
that is ``further away'' is accessed by following key paths from there,
or from existing map references. There are several special registers
used by instructions, but other names in the top level are available as
local variables in user code. The instructions are as follows:

\begin{itemize}
\tightlist
\item
  \texttt{load} fills the \texttt{focus} register with a literal value.
  \joel{For example, `load reg1` causes the `focus` register to contain the string `reg1`.}
\item
  \texttt{deref} treats the value in \texttt{focus} as naming a register
  and copies the register's value into \texttt{focus}.
  \joel{For example, if `reg1` contained the value `42`, `deref` would store `42` in `focus`.}
\item
  \texttt{index} expects a map in the \texttt{map} register and a key
  name in \texttt{focus}. It looks up this key in \texttt{map} and
  replaces \texttt{map} with the value.
  \joel{For example, if the value in `map` contains a key `foo` with value `42` and `focus` contains `foo`, `index` will store `42` in `focus`.}
\item
  \texttt{store} copies the value in \texttt{focus} to a named register.
  Alternatively, if no register is present, it copies the value in the
  \texttt{source} register to the destination identified by \texttt{map}
  and \texttt{focus}, as with the \texttt{index} instruction.
\end{itemize}

An instruction is represented as a map with an \texttt{op} field for its
name and other fields for parameters. For example:

\begin{verbatim}
{ op: 'store', register: 'source' }
\end{verbatim}

It is remarkable that these few operations really are sufficient even
for conditional and unconditional jumps. A jump is achieved by
overwriting \texttt{next\_instruction}, and this can be conditionalised
by \texttt{index}ing a map of code paths based on a selector. We made
the decision that \texttt{index}, if accessing a key not present in the
map, will try and retrieve the special key \texttt{\_} instead. This
supports a generic ``else'' or ``otherwise'' clause for conditionals.

The minimal, microcode-like instruction set here was an experiment in
extreme parsimony; see
Appendix~section~\ref{the-minimal-random-access-instruction-set-and-its-perils}
for the gory details. Although it was interesting, certain basic
operations (such as jumps) are extremely verbose, taking many
instructions. Although it was quick to implement these instructions in
\ac{JS}, it was too tedious to work with them in-system. In retrospect,
it looks like we went too far with Force~\ref{escape-plaf} here and fell
into its associated Turing Tarpit trap. We thus consider an
\emph{extreme} interpretation of Heuristic~\ref{simple-asm} refuted for
the purposes of working in-system sooner. We recommend achieving a
better balance by including direct path arguments in instructions (\eg{}
``copy \texttt{a.b.c} to \texttt{x.y.z}'' as a single instruction), as
well as separate (un)conditional jump instructions.

\hypertarget{graphics-and-interaction}{\subsubsection{Graphics and
Interaction}\label{graphics-and-interaction}}

Now that we have covered the computer-oriented part of the substrate, we
turn to the human-oriented user interface state and change aspects. One
way we wish to distinguish BootstrapLab from \ac{COLA} is that graphical
interfaces are present from the beginning and not just an afterthought.
There are two factors here: how graphics are represented in the
substrate, and how they are actually displayed.

It may be useful to see this as a microcosm of the entire journey. First
we must select a graphics library available for our platform (\ie{} the
\emph{graphics platform}). Then we must decide how graphics are
represented in our substrate (a graphics \emph{sub-}substrate) and how
these graphics actually end up on our screen.

In BootstrapLab, we chose to build off the THREE.js 3D graphics library
as our platform. As for the substrate, we face an immediate choice
between so-called ``immediate mode'' and ``retained mode'' conventions.
In immediate mode, we draw and change graphics by issuing commands; a
``code-like'' approach. In retained mode, the state of the scene is
represented as some structured arrangement of state. When we want to
change something, we simply change the relevant part of the state and
the display should automatically update.

Immediate-mode in this case could be realised by, say, exposing all the
relevant THREE.js functions as special instruction types. In actuality,
however, this sounded far too tedious to work with; Force~\ref{avoid-bp}
won out and we opted for retained mode instead. The rest of the design
then fell out via Alignment (Force~\ref{alignment}).

Consider the low-level binary substrate in which microcomputer games
were programmed. In this world there is a special region of memory, the
\emph{framebuffer}, which is treated as the ground truth of pixels
displaying on the screen. To draw, programs rasterise shapes into pixels
and write to the framebuffer.\footnote{In Commodore 64 BASIC, this would
  be accomplished with commands like \texttt{POKE\ 1024,1}.} The
framebuffer has a flat structure---two-dimensional, yet not by any means
nested---aligning with the substrate it sits within. This suggests that
a natural choice for retained-mode graphics representation can be found
by inspecting the substrate. In BootstrapLab's case, the natural choice
is not a flat ``framebuffer'' but a tree structure of data describing
shapes and text---vector graphics.\footnote{Further rationale for this
  approach can be seen in~\parencite{Dadgum66}.}

\begin{heuristic}[In-state graphics]
\label{in-state-graphics}
Make graphical interfaces expressible as ordinary state in a special location. Having graphics built into the substrate responds to Force\ \ref{avoid-bp} while Force\ \ref{alignment} directs us to use a representation that fits the state model.
\end{heuristic}

In BootstrapLab, this is a sub\emph{tree} of the state under the
top-level name \texttt{scene} (Figure~\ref{fig:scene-tree}). There are
several special keys (\eg{} \texttt{text}, \texttt{position},
\texttt{color}, \texttt{children}) which have graphical consequences.
Other keys may be used as ordinary state.

\begin{figure}
\centering
\includegraphics[width=8cm]{scene-tree-example.png}
\caption[BootstrapLab scene tree]{Example of how nested tree fields are represented (right) vs. the rendered output (left). The right-hand half is the temporary state view discussed in Section\ \ref{implement-temporary-infrastructure}.}
\label{fig:scene-tree}
\end{figure}

For interaction, we need to expose the platform's ability to listen for
user input. In BootstrapLab, we execute a named code sequence in the
substrate from JavaScript event handlers, which now function as ``device
drivers'' (Figure~\ref{lst:devdrv}).

\begin{figure}
\begin{lstlisting}[language=JavaScript]
window.onkeydown = e => {
  state.set('input', 'type', 'keydown');
  state.set('input', 'key', e.key);
  let input_handler_code = state.get('input', 'handler');
  save_context();
  state.set('next_instruction', new state.Map({
    map: input_handler_code, key: 1
  }));
  asm.execute_till_completion();
  restore_context();
};
\end{lstlisting}
\caption[BootstrapLab ``device driver'' for \acs{DOM} events]{``Device driver'' triggering a generic event handler sequence in-system.}
\label{lst:devdrv}
\end{figure}

This is a basic sketch with some issues elided that a complete account
would cover. For example, what happens when an input event occurs during
the handling of a previous event? Possibilities include ignoring the
extra event or providing some sort of stack analogue\footnote{Of course,
  in a structured substrate, there is room for improvement on the linear
  form of the low-level machine stack; see
  Section~\ref{implementing-masp-for-bootstraplab} for how we did this
  for the high-level language.} for nested handlers. Such a data
structure may also be necessary for saving and restoring the instruction
pointer along with other context. These concerns have analogues in
interrupt handling for operating system design, which could be consulted
for further guidance.

\hypertarget{bootstraplab-substrate-summary}{\subsubsection{BootstrapLab Substrate
Summary}\label{bootstraplab-substrate-summary}}

Computer state is a graph of maps; lists are just maps with numerical
keys. Instructions are \texttt{load}, \texttt{deref}, \texttt{store},
\texttt{index}, \texttt{js}. Special top-level keys are \texttt{focus},
\texttt{map}, \texttt{source} and \texttt{next\_instruction}. User
Interface state is controlled via the special \texttt{scene} subtree of
state. Each node may use special keys like \texttt{text},
\texttt{width}, \texttt{height}, \texttt{color}, \texttt{position}, and
\texttt{children}, as well as arbitrary other keys for user data.

\emph{What can be changed at the user level?} System state can be
modified and instructions can be executed, but only using the cumbersome
capabilities of the platform. In case of BootstrapLab, this means using
the \ac{JS} debugging console to edit state and call a function to
execute a certain number of instructions.

\hypertarget{implement-temporary-infrastructure}{\section{Implement Temporary
Infrastructure}\label{implement-temporary-infrastructure}}

\begin{quote}
Use the platform to implement tools for working within the substrate,
most importantly a \emph{state viewer} or editor. These tools constitute
a ``ladder'' that we will pull up behind us once we have ascended to
in-system implementations of these tools.
\end{quote}

In most cases, the base platform will provide some way of viewing and
modifying state, but this is typically inconvenient to use. The next
step in bootstrapping a self-sustainable system involves implementing
temporary infrastructure that lets us work with state more conveniently.

\hypertarget{early-computing-and}{\subsection{\texorpdfstring{Early Computing and
\acs{COLA}}{Early Computing and }}\label{early-computing-and}}

Temporary infrastructure to support in-system development can be found
in many developments of self-sustainable systems. A historical example
is the Teletype loader for the Altair 8800. Here, the base platform was
the Altair hardware with its memory and native CPU instructions. The
only way to modify state through the platform was through the use of
hardware switches at the front of the computer
(Figure~\ref{fig:altair}), which could be used to read and set values in
a given range of memory.

Programming \emph{in-system} looked like the tedious setting of switches
to poke numerical instructions to memory. To make entering programs
easier, the recommended first step when using the Altair 8800 was to
manually input instructions for a \emph{boot loader} that communicated
over the serial port. When finished, this could be run to load
instructions from a paper tape. From here, programmers could write
instructions more conveniently using a Teletype terminal and have them
loaded into the Altair memory.

In the \ac{COLA}
architecture~\parencite[Section\ 6.1 "Bootstrapping"]{COLAs}, there is a
four-step process, the first three of which appear to be throwaway. This
includes a compiler for their state model in C++. This is aptly
``jettisoned without remorse'' once it has been re-implemented in
itself, though it is unclear how a state model can perform computation
(only after this do they implement the ``behavioural layer'').
Regardless, this clearly echoes the bootstrapping process for
programming languages (Section~\ref{concepts-and-terminology}).

The problem with these steps is that they are hard to port to a context
involving structured, graphical notation and interactive system
evolution. Our task is to get the system into a state where the
platform, in a sense, can be ``jettisoned'' in terms of our attention,
even though the platform-implemented substrate will be running in the
background.

\hypertarget{temporary-infrastructure-in-bootstraplab}{\subsection{Temporary Infrastructure in
BootstrapLab}\label{temporary-infrastructure-in-bootstraplab}}

On its own, our chosen platform for BootstrapLab only has one way to
view parts of the state: issuing \ac{JS} commands via the developer
console to poll a current value. This is almost as tedious as toggling
switches on the Altair. Being able to see a live view of all of the
state would be a highly useful facility early on (recall
Section~\ref{web-pages-web-apps-and-browsers} in which we praised the
browser's Element Inspector). In this case, Force~\ref{avoid-bp} won
relative to Force~\ref{escape-plaf}; we capture this as
Heuristic~\ref{plaf-ed}. We implemented a tree view in the substrate
based on an existing \ac{JS} library. State editing can continue to be
done via the console (see Figure~\ref{fig:three-cols}).

\begin{heuristic}[Platform editor]
\label{plaf-ed}
As soon as possible, use the platform to implement a temporary state viewer and/or editor. This temporary infrastructure will later be discarded, but given a capable enough platform, it is very easy to implement. For this reason, it is valuable for simplifying further in-system development. Again, Force\ \ref{avoid-bp} outweighs Force\ \ref{escape-plaf}.
\end{heuristic}

The \ac{JS} tree view is a complex set of functionality set to work and
display in one specific way, and all control over this resides at the
substrate level. The infrastructure cannot be modified from within the
system. Therefore, we regard this situation as \emph{temporary}. It is a
ladder that we climb to end up in a state where we can implement a
(better) state editor in-system. Once a suitable in-system editor
exists, we can pull up the ladder (or if you like, ``jettison it without
remorse'').

\begin{figure}
\centering
\includegraphics[width=\linewidth]{three-columns.png}
\caption[BootstrapLab interface]{The full BootstrapLab interface. From the left: graphics window, temporary HTML state viewer, and browser developer tools.}
\label{fig:three-cols}
\end{figure}

At this point of the bootstrapping process, BootstrapLab's interface
consists of three sections (Figure~\ref{fig:three-cols}). On the right,
we have the browser console, inherited through from the platform's
interface. In the middle, we have the output of the platform's main
graphics technology, the \ac{DOM}, displaying the temporary state
viewer. Because we have not chosen to expose \ac{DOM} control from
within the system, the system only affects this area indirectly through
ordinary state changes. Finally, on the left, we have the
THREE.js-backed graphics window, where we will later build a state
editor whose behaviour (including appearance) \emph{will} be controlled
from within the system.

Ideally, we would have actually supported interactive state
\emph{editing} in the temporary infrastructure, not just viewing. In our
case, however, we tolerated state editing through console commands until
implementing a state editor in terms of the left-hand graphics window
(see Section~\ref{pay-off-outstanding-substrate-debt}).

Another example of temporary infrastructure is zoom-and-pan in the
graphics window. Working within a small box is very restrictive if we
want to use it for viewing and editing the entirety of the system state.
The finite region can be opened up into an infinite workspace by adding
the ability to pan and zoom the camera with the mouse. This was
important to have early on for BootstrapLab, so once again
Force~\ref{avoid-bp} overrode Force~\ref{escape-plaf} and we implemented
this in \ac{JS}.

\emph{What can be changed at the user level?} The basic activities of
viewing or editing state should be made easier by the temporary
infrastructure. For the Altair 8800, instruction entry was improved. For
\ac{COLA}, the basic state model was made available in the first place.
For BootstrapLab, we targeted state visibility.

\hypertarget{implement-a-high-level-language}{\section{Implement a High-Level
Language}\label{implement-a-high-level-language}}

\begin{quote}
The substrate's instruction set (ASM) is cumbersome, so ensure programs
can be expressed in-system via high-level constructs. Decide how to
represent expressions as structured state and whether to
\emph{interpret} or \emph{compile} them into ASM. Ideally, develop such
an engine in ASM gradually and interactively. Alternatively, implement
it at the platform level and later \emph{port} it to ASM or the
high-level language itself.
\end{quote}

The temporary infrastructure created in the preceding step may be enough
to allow limited development in-system. However, it does not yet provide
the barely tolerable programming experience we would need in order to
feel comfortable ditching the platform. For this, an additional step is
needed.

To make programming in-system pleasant enough, we need a high-level
programming language that executes on top of the system substrate. This
means that programs and all their necessary runtime state will be stored
in the system state and the execution will be done either by a compiler
to the substrate's instruction set or an interpreter.

\hypertarget{shortcuts-for-low-level-substrates}{\subsection{Shortcuts for Low-Level
Substrates}\label{shortcuts-for-low-level-substrates}}

For a programming system built atop a limited platform (\eg{} hardware),
the temporary infrastructure may be the best tool that is available for
programming. In that case, we would write the compiler or interpreter
directly using the instruction set. However, as long as the platform has
higher capabilities or one has access to alternative platforms, this may
not be optimal. When Paul Allen and Bill Gates wrote the famous BASIC
programming language for the Altair 8800, they did not do this \emph{on}
the Altair, but instead used an Intel 8080 CPU emulator written and
running on Harvard's PDP-10. The high-level language was thus developed
\emph{outside the system.}

In \ac{COLA}, it is unclear how the Lisp-like programming language is
built beyond the broad outlines. What is clear is that the bootstrapping
process is carried out by means of source code files written in some
text editor. In other words, it wisely takes advantage of the
affordances of its Unix platform, avoiding the Turing Tarpit failure
mode described in Section~\ref{the-major-design-conflict}.

\hypertarget{high-level-language-for-bootstraplab}{\subsection{High-Level Language for
BootstrapLab}\label{high-level-language-for-bootstraplab}}

If we take \ac{JS}, and strip away the concrete syntax, we get a
resulting tree structure of function definitions, object literals, and
imperative statements. A similar structure with similar semantics would
be obtained from other dynamic languages. In fact, this would largely
resemble Lisp S-expressions under Lisp semantics; hardly surprising
considering Lisp's famously minimal syntax of expression trees.
Furthermore, the evaluation procedure for Lisp is simple and
well-established.

For these reasons, we designed a Lisp-like tree language in the
substrate. This way, we provide high-level constructs (\texttt{if-else},
loops, functions, recursion, and so on) for in-system programming.
Alignment (Force~\ref{alignment}) encouraged us to revisit Lisp's design
to better fit with our substrate. For example, ordinary Lisp is based on
lists whose entries have \emph{implicit} meanings based on their
positions. This fits with the substrate made of S-expressions. Our
substrate comes with named labels and suggests a language based around
maps whose entries are explicitly \emph{named}, so we called it
\emph{Masp.}\footnote{This is not too hard to come up with, but we would
  like to credit the origin of the name to~\parencite{Masp} and related
  discussion.} Figure~\ref{fig:lisp} contrasts the two.

\tomas{Maybe use more verbose JSON like syntax, because figuring out the nesting rules below is not obvious. (Plus you need to have curly brackets if you want your language to take over the world, right??)}

\begin{figure}
\raggedright
Lisp:
\begin{verbatim}
(define fac
  (lambda (n)
    (if (= n 0)
      1
      (* n (fac (decr n)))))
(fac 3)
\end{verbatim}
Masp:
\begin{verbatim}
apply: define,  name: fac,  as:
  apply: lambda,  arg_names: { 1: n },  body:
    to: n,  apply:
      0: 1,  _:
        apply: *,  1: n,  2:
          apply: fac,  n:
            apply: decr,  1: n
apply: fac,  n: 3
\end{verbatim}
\caption[Lisp vs. Masp]{Lisp, built around lists, vs. Masp, built around maps.}
\label{fig:lisp}
\end{figure}

The equivalent Masp code is more verbose when rendered in ASCII.
However, one of our key goals is to enable the use of other, better
notations if desired, which we will discuss in the next section. Here,
we start from an internal representation that has \emph{more}
information (explicit named arguments) than Lisp, but we can choose to
display this however we feel appropriate (perhaps by showing a name
label only for the entry being edited).

\hypertarget{choosing-an-appropriate-implementation}{\subsection{Choosing an Appropriate
Implementation}\label{choosing-an-appropriate-implementation}}

There are two basic decisions for implementing the high-level language.
First, will we do it directly in-system using the instruction set, or
using richer capabilities provided by the platform? Second, the language
can be either interpreted or compiled. The four combinations have
different properties.

A \emph{platform interpreter} is the easiest one to implement, but it
cannot be used to easily bootstrap itself. To ``jettison'' the platform
implementation, we later need to \emph{port} the interpreter to the ASM
language. (Porting it to the high-level language would not suffice,
since we would still need the platform interpreter to actually run it.)

A \emph{platform compiler}, while harder to implement, is slightly
easier to jettison because it only needs to be ported to the newly
developed high-level language. The platform compiler can translate it to
ASM, which we can already run in-system. This compiler can then turn any
high-level expressions into ASM, including its own source expressions!

Yet harder to implement is an \emph{in-system interpreter}, directly in
ASM, but it will exist in-system. However, the interpreter will be less
maintainable than if it were written in a high-level language and will
likely need to be ported to a high-level language eventually.

Finally, an \emph{in-system compiler} is the most challenging to
implement. It will allow the language to exist in-system sooner and
possibly more efficiently but, as above, will likely need to be
converted to a high-level programming language to allow in-system
improvements.

When implementing the interpreter or compiler in-system, all its
intermediate state will also be stored in-system. However, in-system
state can be used even when implementing the interpreter or compiler
\emph{on the platform.} This takes advantage of the platform's
high-level language while leveraging the product system for debugging
and visualisation, simplifying a later port to in-system implementation
(see Heuristic~\ref{in-state-op}). The transition from platform to
in-system implementation can be even more gradual; once the
\emph{intermediate state} is stored in-system, it becomes possible to
port \emph{parts} of the interpreter piecemeal to in-system
instructions, invoking them from the remaining parts running outside.

\begin{heuristic}[In-state operation]
\label{in-state-op}
Store high-level-language processing \emph{state} in-system even if the language \emph{processor} remains running on the platform. This will ease porting the processor to in-system implementation and support a gradual transition.
\end{heuristic}

\hypertarget{implementing-masp-for-bootstraplab}{\subsection{Implementing Masp for
BootstrapLab}\label{implementing-masp-for-bootstraplab}}

In BootstrapLab, Force~\ref{escape-plaf} encouraged us to get executing
Masp expressions early to get experience with the language. We chose to
implement a \emph{platform interpreter} for Masp using \ac{JS} as this
was the easiest way to achieve that.

A naïve approach would simply implement the standard Lisp interpreter
routines (\texttt{eval} and \texttt{apply}) as recursive \ac{JS}
functions. However, this would miss an opportunity for visualisation and
debugging that is already present in our substrate. Instead, we followed
Heuristic~\ref{in-state-op} and had intermediate interpreter
\emph{state} reside in-system. This made a later in-system port easier
by doing half of the work now.

Lisp evaluation is done by walking over the expression tree. At any
point, we are looking at a subtree and will evaluate it until reaching a
primitive value. Ordinarily, the ``current subexpression'' is an
argument to \texttt{eval} at the top of the stack, where the stack
records our path from the original top-level expression. Since we
already had a tree visualisation, we used that instead of a stack. We
did, however, need to maintain references to parent tree nodes (see
Appendix~section~\ref{graphs-vs.-trees}) in order to backtrack towards
the next unevaluated subexpression once the current one is evaluated.
Furthermore, instead of \emph{destructively} replacing tree nodes with
their ``more-evaluated'' versions, we ``annotate'' the tree instead.
This design choice follows Subtext~\parencite{Subtext} and will make it
possible to trace provenance and enable novel programming experiences.
Figures~\ref{fig:masp-1}--\ref{fig:masp-n} show some examples.

\begin{figure}
\centering
\includegraphics{masp/1-apply-fac.png}
\caption[Masp Factorial evaluation step 1]{The \texttt{expr} part of the Masp context contains the current expression being evaluated. This represents the initial state for applying the factorial function with parameter \texttt{n} bound to 1.}
\label{fig:masp-1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=6cm]{masp/2-eval-fac-n.png}
\caption[Masp Factorial evaluation step 2]{After some evaluation steps, both the original expression (the name \texttt{fac}) and its value (its function closure) are visible. Similarly, the literal expression \texttt{1} has evaluated to itself.}
\label{fig:masp-2}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=6cm]{masp/3-expand-fac.png}
\caption[Masp Factorial evaluation step 3]{The next step of evaluation, read as: ``To the value \texttt{1} (which came from the expression \texttt{n}), apply this function literal in an environment where \texttt{n} is bound to \texttt{1}''.}
\label{fig:masp-3}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=8cm]{masp/4-apply-mul.png}
\caption[Masp Factorial evaluation step 4]{Some steps later, we have an application of a built-in multiplication function whose JS code is visible. The second operand is an as-yet unevaluated recursive application of \texttt{fac}.}
\label{fig:masp-n}
\end{figure}

\note{Perhaps the idea of bootstrapping abstractions from the low-level (Heuristic\ \ref{use-asm}) has been refuted? Instead of writing BL-ASM in-system to build things up, it's been so tedious that I haven't touched it and instead leaped to Masp in JavaScript! It is of course still possible in principle, but the complex reality of how I did things and the design decisions I made, caused it to be uneconomical.}

\emph{What can be changed at the user level?} Depending on which of the
four implementation paths were chosen, the semantics of the language may
or may not (yet) be modifiable from the user level. The user is almost
able to use the high-level language in-system for convenient programming
\ldots{} but may be unable to enter the expressions conveniently in the
first place. This matter will be addressed shortly.

\hypertarget{pay-off-outstanding-substrate-debt}{\section{Pay Off Outstanding Substrate
Debt}\label{pay-off-outstanding-substrate-debt}}

\begin{quote}
Port all remaining temporary infrastructure into the system, taking
advantage of the infrastructure itself and the high-level language. The
result is a \emph{self-sustainable} programming system.
\end{quote}

If we had developed both the state editor and the high-level programming
language in-system, we would already have an elementary self-sustainable
system at this point. This would have been our only option if we had
been somehow stuck with only a primitive platform, as was the case at
the dawn of computing in the 1940s. With a richer platform available,
one can choose to implement a state viewer, editor and high-level
programming language on it following Heuristic~\ref{plaf-ed}. Since
these will now run outside of the product system, they will be
functionally part of the substrate---yet they do not belong there. This
\emph{substrate debt}, incurred due to Force~\ref{escape-plaf}, now
needs to be paid off.

\hypertarget{substrate-debt-in-bootstraplab}{\subsection{Substrate Debt in
BootstrapLab}\label{substrate-debt-in-bootstraplab}}

In the ideal development journey, we would have a high-level programming
language and a basic state editor in-system by now. This did not happen
for BootstrapLab.

The Masp interpreter we developed used in-system state, but controlled
it from \ac{JS}. Our state viewer was also fully implemented in \ac{JS}.
Editing took place through the browser development console. The
alternative, creating a Masp interpreter and state editor in-system
using the low-level ASM instructions, had been technically possible but
prohibitively tedious. The in-system tooling was far from supplanting
the existing platform interface of \ac{JS} in the text editor.
Continuing to use the latter was, therefore, the only sensible choice to
make progress.

Nevertheless, to make the high-level language and editor a part of
self-sustainable programming system, they ultimately need to be
implemented in-system. Thus we incurred a \emph{substrate debt} due to
Force~\ref{escape-plaf} which we now need to pay off. The advantage of
delaying this work is that we can at least port \ac{JS} to Masp, which
is more convenient than using ASM. Generally, such substrate debt should
be paid off as soon as the indebted implementation is complete. In
total, we had three parts of it to pay off:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The temporary state viewer, to be superseded by an in-system editor
\item
  Its replacement state editor, to be ported from JavaScript to Masp
\item
  The Masp interpreter, to be ported from JavaScript to ASM
\end{enumerate}

In BootstrapLab, we took a two-step approach to supplanting the
temporary state viewer. We first replaced a viewer that exists fully
outside of the system with an editor that uses in-system state and
graphics, but is controlled from \ac{JS}. We then started to port the
editor code from the platform to in-system Masp, which is where we are
at the time of writing.

\hypertarget{supplanting-the-temporary-state-viewer}{\subsection{Supplanting the Temporary State
Viewer}\label{supplanting-the-temporary-state-viewer}}

Once we could run Masp programs in the substrate, we needed a better way
of entering and editing them. We desired a state editor in the graphics
window to make the existing state view obsolete. Considering the
proof-of-concept nature of this work, we created a rudimentary tree
editor that nevertheless surpassed the existing practice of issuing
commands in the \ac{JS} console.

To edit state in \ac{JS}, we needed to either address its parent with a
full path from the top level, or to use a reference previously obtained
this way. To set a primitive value, we would type a \ac{JS} command
including the key name and the value. This was not a high bar to clear.
Evidently, we could greatly improve the experience by simply clicking on
the relevant key name and typing.

\begin{figure}
\centering
\includegraphics[width=9cm]{editor.png}
\caption[In-system tree editor vs. HTML state viewer]{Left: tree editor in graphics window. Right: temporary state viewer in the \acs{DOM}.}
\label{fig:editor}
\end{figure}

We implemented a basic tree view in the graphics window
(Figure~\ref{fig:editor}). Nodes can be expanded and collapsed, and
entries can be changed by clicking and typing. The display is
``on-demand'' and breadth-first: map entries are read upon expanding a
node. This means that cycles in our graph substrate do not pose a fatal
problem, as they did in the temporary state view (see
Appendix~section~\ref{graphs-vs.-trees}). The basic CRUD operations are
accounted for as follows:

\begin{itemize}
\tightlist
\item
  Update (primitive): The \texttt{Tab} key commits the value and selects
  the next entry.
\item
  Create: If the above runs past the end of the map, special ``new
  entry'' fields for entering a new key and value are created. These
  disappear if abandoned without committing.
\item
  Update (composite): \texttt{Enter} commits a new, empty map and
  selects the ``new entry'' field within it.
\item
  Delete: \texttt{Backspace} on an empty value will delete the entry. If
  it was the only entry, it will be replaced with the ``new entry''
  field.
\item
  Read: The display of the entry in the graphics window provides this.
\end{itemize}

It is worth noting that Alignment (Force~\ref{alignment}) applies here
too: the structure of the substrate clearly has implications for the
structure of the editing interface. If our substrate consisted of
low-level bytes, the traditional hex editor interface would be an
immediate requirement. Such an interface could plausibly be simpler to
implement than the complex nested tree editing we needed for
BootstrapLab. This suggests a potential feedback into the choice of
substrate: \emph{a more complex substrate will require a more complex
editor.}

We might even be tempted to conclude that it only makes sense to use a
low-level substrate, since we can complete a basic editor sooner and
subsequently work in-system. This neglects the fact, however, that the
higher-level structures of our substrate would inevitably be required at
some point. Thus we would have to do the same work anyway, but only once
we had suffered through the human-unfriendly low-level substrate.

It is also remarkable that, in this restricted interaction domain, we
finally \emph{did} manage to surpass our default \ac{JS} text editor.
There is a cost to typing out concrete syntax like \texttt{:} and
\texttt{\{\}} for \ac{JS} map structures, as well as ensuring
indentation is correct. For entering state structures, we found the
structured editing style to be quicker. As a result, where previously we
might have added new persistent state in our \ac{JS} startup code, we
now directly entered it into the system and persisted it manually.

There is a caveat to all this. The whole exercise was in the service of
paying our substrate debt from earlier---pulling up the state viewer
``ladder'' that had got us to this point. Ideally, we would have built
up its replacement in-system. Yet as pointed out, \ac{JS} was still the
most appealing way to program at this stage, so we used it for this
editor as well. In other words, we took on a new debt in order to pay
off the first one! To resolve it, we would port the \ac{JS} to Masp---a
process which is underway at the time of writing for both the Masp
interpreter and the state editor.

In general, at the end of this stage the substrate should not contain
anything that we wanted to be modifiable in-system. Thus:

\emph{What can be changed at the user level?} The structural ``syntax''
and semantics of the high-level language can be changed. The graphical
interface of the system can also be changed, including the concrete
notation for programs and data, which we turn to next.

\hypertarget{provide-for-domain-specific-notations}{\section{Provide for Domain-Specific
Notations}\label{provide-for-domain-specific-notations}}

\begin{quote}
Use the self-sustaining state editor to construct a more convenient
interface for editing high-level expressions. Add \emph{novel notations
and interfaces} as needed. Use these not just for programming new
end-user applications, but also to improve the product system itself.
\end{quote}

Because BootstrapLab is currently in the middle of the previous stage,
this section describes our plans for when this is complete. At such a
point in the journey, the editor implementation would now be part of the
product system, so we could modify it from within to our heart's
content.

We admitted earlier how, in BootstrapLab, we had not managed to bring
the system interface up to a level where it became more effective than
\ac{JS}. With the implementation of a state editor, we came closer.
Indeed, for entering general state structures, it is not obvious how to
improve on it. Yet when it comes specifically to Masp expression
structures, we must enter their verbose details even though they are
highly regular and could be captured through fewer interactions. If we
streamline this \emph{subdomain} of the BootstrapLab interface, it would
make Masp programming just as convenient as typing \ac{JS}, if not more
so---and we could finally escape the text editor entirely.

\hypertarget{a-taster}{\subsection{A Taster}\label{a-taster}}

First, we propose a restricted proof-of-concept of notational variation
from within the system. We choose to target a small part of the problem:
the Masp \texttt{apply} node, a frequent enough occurence that a small
improvement will be helpful.

In the general state editor, one must type each of these key-value pairs
for a function application:

\begin{verbatim}
apply: setColor
red: 11
green: 22
blue: 33
\end{verbatim}

Instead, we desire something like autocomplete for parameters. Instead
of typing \texttt{apply}, we press \texttt{a} and enter
\texttt{setColor}. Subsequent tabbing should fill in the parameter names
automatically and let us type the arguments. Furthermore, as a small
notational difference we will omit the word \texttt{apply}:

\begin{verbatim}
setColor
red: _
green: _
blue: _
\end{verbatim}

The underscores represent unfilled fields right after this structure
gets created.

To reprogram the editor to work like this, we would do the following
from within the editor. Navigate to the Masp code structures for the
editor that synthesise the graphics structures to display a given state
node. Enter Masp code that checks for the key \texttt{apply} in the
given node and, if present, only renders the value of the key instead of
the key itself.\footnote{Admittedly, this will display all structures
  with an \texttt{apply} key this way, but further discretion is just as
  achievable with further programming. The point is that this can be
  changed at the user level.} Then, navigate to the code that handles
key input. Add code that, when \texttt{a} is pressed, will insert a new
map containing the \texttt{apply} key, render this to the graphics, and
send text input to its value text box. Finally, navigate to the code
that commits an entry on a \texttt{Tab} keypress. Change this to detect
if it is for an \texttt{apply} key and, if so, to look up the symbol in
the value node and treat it as a Masp function closure. For each entry
in the \texttt{arg\_names} field, add an entry to the map with a dummy
value, render this to graphics, and then proceed with the default
behaviour (highlight the next entry in the map). Depending on the
precise implementation, it may be the case that only subsequent edits
will be rendered this way. Otherwise, care may be necessary to refresh
and re-render the entire editor state.

\hypertarget{a-more-ambitious-novel-interface}{\subsection{A More Ambitious Novel
Interface}\label{a-more-ambitious-novel-interface}}

The above ``taster'' is a simple example of an interface that could be
plausibly implemented early in BootstrapLab's self-sustaining lifetime.
Beyond this, it points to a more general class of extensions which would
support \emph{projectional editing.} Projectional editors are a class of
programming interfaces that provide domain-specific interfaces for
certain program subexpressions, such as \LaTeX-style mathematical
expressions to replace ASCII renderings (recall
Section~\ref{linguistic-freedom}). We would do well to import such ideas
into BootstrapLab. We proceed to sketch how such an interface would be
added to the system, and how its ramifications are different from
ordinary non-self-sustainable projectional editors.

As an example, suppose we want to program some fancy graphics. Fancy
graphics require sophisticated vector mathematical formulae. In textual
programming languages, these are expressed as ASCII with limited infix
notation. The Gezira/Nile project~\parencite{Gezira,Nile} attempted to
improve on this with Unicode mathematical syntax. Obviously the extreme
endpoint would be \LaTeX. All we have at the moment is something worse
than all of these: verbose, explicit tree views spanning multiple lines.

We think ahead with a view towards making the fancy graphics programming
more pleasant. Suppose we decide that we would ideally like to implement
them with the aid of concise mathematical notation, as opposed to our
current state of verbose trees. How can we achieve this?

The broad approach would be similar to our previous taster example. We
would have to start, again, at the code that renders state into
graphics. Add a condition that checks for a \texttt{math} key, which we
would use as a tag to hint at this display preference. Enter code to
translate operator names to Unicode symbols, place them at infix
positions, place parentheses appropriately, and render the whole thing
to a single line in the tree view (ideally keeping the tree structure of
the expressions in the graphics state). Then, modify the input handling
and tree navigation code to appropriately work on this \emph{inline}
tree structure. And so on.

The above points are, of course, a high-level sketch, but it is
\emph{programming} all the same and is plausible to achieve with a
high-level language. Techniques from the literature would be helpful,
such as Hazel's calculus for editing structures with
holes~\parencite{Hazel}, or bi-directional synchronisation between the
rendered graphics and the state's ground truth~\parencite{SnS}.

\hypertarget{real-example-colour-preview}{\subsection{Real Example: Colour
Preview}\label{real-example-colour-preview}}

While the above speculation has value, it is only fair that we show a
real example. We only had time to implement a very modest
proof-of-concept: instead of a hex string for colours, let us see a
rectangle with that colour instead.

Some Masp code (Figure~\ref{lst:rendermapentry}) lives under the global
register called \texttt{render\_map\_entry}. It is invoked from the
\ac{JS} function for rendering map entries in the tree editor. It checks
if a map entry is named ``color'', and if so, returns an appropriately
coloured box with a grey border. Figure~\ref{fig:hex-vs-boxes} shows the
difference.

These results so far could have been achieved without going to the
trouble of implementing the hook in Masp. \ac{JS} would have sufficed.
However, having this code in Masp lets us do something not possible with
the equivalent \ac{JS}. The system has access to the explicitly
structured Masp code and can choose how to display it.

As this Masp code is evaluated on its own source tree, it encounters the
hex constant \texttt{0xaaaaaa} representing the grey border and displays
this \emph{with the very notation it implements.} See
Figure~\ref{fig:grey-box} for the difference. This is a minimal
demonstration of Innovation Feedback
(Section~\ref{the-key-benefit-innovation-feedback}): there is no
artificial barrier to innovations (in this case, displaying colour
previews) applying to their own implementation code.

\begin{figure}
\begin{lstlisting}
to: key_name,  apply:
  _: { apply: quote,  to: unhandled }
  color:
    apply: block
    1:
      apply: local,  name: box,  is:
        width: 0.45,  height: 0.2
        center: { right: 0.875,  up: -0.1,  forward: -0.9 }
        children:
          1:
            width: 0.5,  height: 0.25
            center: { right: 0,  up: 0,  forward: -1 }
            color: 0xaaaaaa
    2: { apply: set,  map: box,  key: color,  to: value }
    3: box
\end{lstlisting}
\caption[Masp code for local colour preview]{This Masp code checks if a map entry is named ``color''. If so, it returns an appropriately coloured box with a grey border. Otherwise, it returns the string \texttt{unhandled}.}
\label{lst:rendermapentry}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=8cm]{hex-strings-vs-coloured-boxes.png}
\caption[Local colour preview in BootstrapLab]{Before (left) and after (right) activating the Masp rendering hook.}
\label{fig:hex-vs-boxes}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=12cm]{grey-box.png}
\caption[Innovation Feedback in BootstrapLab]{The grey colour constant displays as the hex string \texttt{0xaaaaaa} in the right-hand HTML tree view. However, in the left-hand tree editor, this code runs on its own source representation, turning the colour constant into a grey box instead. This is a minimal example of Innovation Feedback.}
\label{fig:grey-box}
\end{figure}

\hypertarget{the-key-takeaway}{\subsection{The Key Takeaway}\label{the-key-takeaway}}

In the non-self-sustainable world, a projectional editor is implemented
in some traditional programming language and interface; say, Java. The
domain-specific notations can benefit a wide variety of programs created
using the editor. Yet, this range of beneficiaries nevertheless forms a
``light cone'' emanating out from the editor, never including the editor
itself. For example, any vector formulae used to render the interface of
the editor will remain as verbose Java expressions, along with any code
for new additions to the editor. The tragedy of non-self-sustainable
programming is that it can never benefit from its own innovations.

Conversely, in BootstrapLab, the benefits of the new notation spread
across the whole system; the ``light cone'' \emph{includes} the editor
implementation itself. If we previously had to squint and parse verbose
maths trees in the implementation of the maths rendering, we can now
open up the code again and see it rendered in the more readable way that
it itself implements!

In \ac{COLA}, notational variation appears to be limited to variation in
concrete syntax. Our uncompromising insistence on \emph{explicit,
non-parsed structure} at the core of BootstrapLab, while costly in terms
of interface implementation, was precisely in order to be free of such a
restriction in the end. While one \emph{could} implement a multiline
text field with syntax highlighting in BootstrapLab, it is at least
crystal-clear that a vast array of other interfaces are possible,
unimpeded by any privileging of text strings.

\hypertarget{situation-task-user-importance}{\section{Situation, Task, User,
Importance}\label{situation-task-user-importance}}

We close this chapter with a description of BootstrapLab expressed in
the framework of~\cite{EvUISR}. It is worth separately applying this to
(a) BootstrapLab itself, (b) the technique we have presented as a
sequence of steps, and (c) the ``ideal BootstrapLab'' that we would
develop with more time and resources.

Firstly, BootstrapLab itself is made to help the author (User) discover
how to interactively achieve self-sustainability and explore its effects
(Task) for research (Situation). The claim to Importance is that such a
system did not previously exist (Problem Not Previously Solved).

The technique was developed to help individual programmers (User) escape
the limitations of their go-to programming environments for general
programming tasks (Task) where they are able and willing to put in this
investment (Situation). Such an investment of time and work may not be
possible or appropriate in some situations. However, we see it as
existing on the same continuum of existing programming investments, such
as writing a utility function or library to ultimately pay itself off in
productivity gains. This contribution falls under ``Generality'',
applying to all sorts of programming systems taken as the platform. It
also qualifies for ``Empowering New Participants'' in the sense that the
benefits of the Three Properties (especially Self-Sustainability) need
no longer be confined to specific programming systems like Smalltalk;
one should be able to have them ``bolted on'' to one's own preferred
platform.

Finally, the ``ideal BootstrapLab'' would be an example of this process
applied to our preferred platform, the Web browser (User, Situation). It
would function as a Smalltalk-like ``personal dynamic medium'' for both
exploring problem spaces and implementing solutions (Task), but one that
neatly slots into our familiar programming practices (\eg{} does not
require installing and learning Smalltalk). While it is necessarily
lifted up by programmers, the availability of mood-specific notations
could make it of use to non-programmers (Empowering New Participants).

While the ``Situation, Task, User, Importance'' structure is helpful for
summarising what we have done, it is quite broad and does not include
the Three Properties that we intended BootstrapLab to embody. Our
remaining task in this dissertation is to examine this issue of
evaluating BootstrapLab and programming systems more generally.
\clearpage{}
\cleardoublepage
\clearpage{}\hypertarget{tech-dims}{\chapter{Technical Dimensions of Programming Systems}\label{tech-dims}}

We introduced the concept of a \emph{programming system} in
Section~\ref{programming-systems-vs-languages}. Not only is such a
concept necessary for framing our work in Chapter~\ref{bl}, there is
also a growing interest in programming systems in both research and
industry. Yet while programming \emph{languages} are a well-established
concept, analysed and compared with a common vocabulary, no similar
foundation exists for the wider range of programming \emph{systems.} In
this chapter,\footnote{Adapted from our paper for Programming
  2023~\parencite{TechDims} which won the Editors' Choice Award for the
  journal.} we will examine this problem and propose a framework of
``Technical Dimensions'' to kickstart systematic research on programming
systems. We will then make our Three Properties
(Section~\ref{the-three-properties}) more precise as sets of dimensions
under this framework. We will then use these dimensions to assess how
BootstrapLab fulfils the Three Properties and evaluate it on that
basis.\footnote{It might seem appropriate to also perform an evaluation
  via the Cognitive Dimensions of Notation~\parencite{CogDims}. However,
  this would not actually tell us anything interesting; the novel
  contribution of this system is not its notation. The interface is
  minimal and unpolished for reasons of expediency. The point is not
  that we have come up with a new notation or UI that will improve
  programming; the notation is something that each user should fit to
  themselves according to subjective preference. The important goal is
  that the system \emph{supports} the usage of different notations for
  different contexts. Notations in BootstrapLab should be a free
  parameter, so it does not make sense to apply Cognitive Dimensions to
  BootstrapLab \emph{itself}, and it does not provide any value to
  analyse the placeholder interface in this way.}

\hypertarget{barriers-to-programming-systems-research}{\section{Barriers to Programming Systems
Research}\label{barriers-to-programming-systems-research}}

Researchers are studying topics such as \emph{programming
experience}~\parencite{PX} and \emph{live programming}~\parencite{LIVE}
that require considering not just the \emph{language}, but further
aspects of a given system. At the same time, companies are building new
programming environments like Replit~\parencite{ReplitWeb} or
``low-code'' tools like Dark~\parencite{DarkWeb} and
Glide~\parencite{GlideWeb}.

However, the academic research on programming suffers from a lack of
common vocabulary. While we may thoroughly assess programming
\emph{languages}, as soon as we add interaction or graphics into the
picture, evaluation beyond subjective ``coolness'' becomes fraught with
difficulty.\footnote{The same difficulty in the context of user
  interface systems has been analysed by~\textcite{EvUISR}. Interesting
  future work would be a detailed analysis of publications on
  programming systems to understand this issue in depth. One notable
  characteristic is that publications tend to present (parts of) new
  systems. This is the case for 5/6 and 6/7 papers in the LIVE 2020 and
  2021 workshops respectively~\parencite{LIVE20, LIVE21}. In contrast,
  publications in the field of programming \emph{languages} often
  address specific issues of interest to a greater number of languages.}
Comparisons make the most sense when comparing ``like for like'', yet
graphical programming systems may be so varied that it is unclear what
the stable points of comparison should be. Moreover, when designing new
systems, inspiration is often drawn from the same few standalone sources
of ideas. These might be influential past systems like Smalltalk,
programmable end-user applications like spreadsheets, or motivational
illustrations like those of~\textcite{BretVictor}.

Instead of forming a solid body of work, the ideas that emerge are
difficult to relate to each other. The research methods used to study
programming \emph{systems} lack the rigorous structure of programming
\emph{language} research methods. They tend to rely on singleton
examples, which demonstrate their author's ideas, but are inadequate
methods for comparing new ideas with the work of others. This makes it
hard to build on top and thereby advance the state of the art.

Studying \emph{programming systems} is not merely about taking a
programming language and looking at the tools that surround it. It
presents a \emph{paradigm shift}~\parencite{Kuhn} to a perspective that
is \emph{incommensurable} with that of languages. When studying
programming languages, what matters is in the program code; when
studying programming systems, what matters is in the behaviour of the
system. As documented by \textcite{PLrev}, looking at a \emph{system}
from a \emph{language} perspective makes it impossible to think about
concepts that arise from interaction with a system which are not
reflected in the language.

\hypertarget{our-proposal}{\section{Our Proposal}\label{our-proposal}}

We propose a common language as an initial step towards more progressive
research on programming systems. Our set of \emph{technical dimensions}
seeks to break down the holistic view of systems along various specific
``axes''. The dimensions identify a range of possible design choices,
characterised by two extreme points in the design space. They are not
fully quantitative, but they do allow comparison by locating systems on
a common axis. We do not intend for the extreme points to represent
``good'' or ``bad'' designs; we expect any position to be a result of
design trade-offs. At this early stage in the life of such a framework,
we encourage agreement on descriptions of systems first in order to
settle any normative judgements later.

The set of dimensions can be understood as a map of the design space of
programming systems. Past and present systems will serve as landmarks,
and with enough of them, we may reveal unexplored or overlooked
possibilities. In the absence of such a map, the field has not been able
to establish a virtuous cycle of feedback; it is hard for practitioners
to situate their work in the context of others' so that subsequent work
can improve on it. Our aim is to provide foundations for the study of
programming systems that would allow such development.

In short, while there is a theory for programming languages, programming
\emph{systems} deserve a theory too. It should apply from the vast scale
of operating systems to the comparatively small scale of language
implementations. It should be possible to analyse the common and unique
features of different systems, to reveal new possibilities, and to build
on past work in an effective manner. In Kuhnian terms~\parencite{Kuhn},
it should enable a body of ``normal science'': filling in the map of the
space of possible systems~\joel{(Figure \ref{fig:tech-dims-diagram})},
thereby forming a knowledge repository for future designers.

\joel{CORRECTIONS NOTE: INCLUDE TECH DIMS DIAGRAM PICTURE FILE!!!}

We will develop \emph{self-sustainability,} \emph{notational freedom,}
and \emph{explicit structure} as Technical Dimensions, following on from
the discussion in Section~\ref{the-three-properties-in-more-detail}. For
each one, we will give examples that illustrate the range of values it
spans. Then we will apply them to BootstrapLab. The rest of our
extensive catalogue of dimensions can be found in
Appendix~\ref{appendix-all-dims}, organised into related clusters:
\emph{interaction}, \emph{notation}, \emph{conceptual structure},
\emph{customisability}, \emph{complexity}, \emph{errors}, and
\emph{adoptability}.

\hypertarget{dimensions-qualitative-and-quantitative}{\section{Dimensions, Qualitative and
Quantitative}\label{dimensions-qualitative-and-quantitative}}

There is a problem where the most easily \emph{measurable} properties
are not necessarily very interesting, while the interesting properties
are not straightforwardly measurable. We have discussed our Three
Properties intuitively and qualitatively in Chapters~\ref{background}
and~\ref{analysis}. However, as they stand there is too much ambiguity
for anything resembling an objective, plausible consensus on how much
they are present in a given system. Therefore, in the next section we
will break them down into narrower dimensions that we can apply for
evaluating BootstrapLab. A few of these will be boolean (asking whether
something is possible or present in a system) but most will be
quantitative \emph{penalty} dimensions. This means that maximising the
value of one of our Three Properties (\eg{} Self-Sustainability) will
correspond to \emph{minimising} its constituent penalty dimensions.

\hypertarget{how-we-define-and-apply-the-dimensions}{\subsection{How We Define and Apply the
Dimensions}\label{how-we-define-and-apply-the-dimensions}}

We say a penalty dimension is ``quantitative'' in that its definition
intuitively describes an amount of which there can be more or less, even
if we leave the question of how to actually measure it numerically as
future work. We do not have the scope to compare the various ways these
quantities could be defined for measurement, and it would be misguided
to pick one simply for the sake of having numbers. Where a relevant
quantity does already exist (\eg{} lines of code) we may propose it as a
measure for the dimension. Otherwise, we will use a variation on the
Likert scale used in psychology~\parencite{Likert}. Instead of
``strongly agree'' to ``strongly disagree'', we will assign the scores
``minimal'', ``low'', ``moderate'', ``high'' and ``infinite''.

With such a scale, it would be possible to rigorously measure a system
against the dimensions by means of a questionnaire and analysing the
distribution of responses (expecting consensus around a single score,
and perhaps re-working the dimensions for which this is not the case).
However, such an approach is beyond the scope of this work. Instead,
when we apply these dimensions to evaluate BootstrapLab in
Chapter~\ref{bl}, we will give our own personal assessment of each score
along with its justification. We think that the narrow focus of the
dimensions makes it likely that such judgements would be aligned with
those of the reader. Even in the case of serious disagreement, this
narrow focus would make it easier to productively reach agreement in a
way that would be much harder for the complex, qualitative definitions
of the Three Properties from which they derive
(Section~\ref{the-three-properties-in-more-detail}). Therefore, while we
agree that giving our personal assessment in terms of the Three
Properties directly would be hard to judge objectively, we believe that
doing so on the finer scale of the dimensions is appropriate. Further
discussion of these issues and suggestions for future work will be found
in Section~\ref{improving-the-technical-dimensions}.

\hypertarget{aggregation-and-simplification}{\subsection{Aggregation and
Simplification}\label{aggregation-and-simplification}}

It is worth noting that even once we have broken down a high-level
concept into several low-level dimensions, the high-level concept can
still be considered a \emph{dimension} if we define some suitable
aggregation of the scores of its constituent dimensions (this could be a
simple sum, a weighted average, or something more sophisticated). We
will not practice this, but it is worth keeping in mind as we encounter
complications and decide how to respond to them.

For example, it might be objected that a dimension cannot simply apply
to a system as a whole, but actually takes different scores for
different \emph{parts} of a system. We can answer this objection with an
interpretation of the dimension as precisely such an aggregate of its
application across different parts of the system. Ultimately,
programming systems are complex and any property we speak of may apply
at multiple levels. For practical purposes including those of our
evaluation of BootstrapLab, we must make simplifications and apply our
dimensions to an entire system as best we can. Later in
Section~\ref{improving-the-technical-dimensions}, we will return to the
complexities we have elided here.

\hypertarget{the-three-properties-as-dimensions}{\section{The Three Properties as
Dimensions}\label{the-three-properties-as-dimensions}}

We will now proceed to break down each of our Three Properties into
dimensions (or, in the boolean case, ``criteria'', but we will stick to
the general term).

\hypertarget{dimensions-constituting-self-sustainability}{\subsection{Dimensions Constituting
Self-Sustainability}\label{dimensions-constituting-self-sustainability}}

In light of the points in Section~\ref{self-sustainability}, we can
discover some key dimensions of self-sustainability with the help of an
existing programming system that is not self-sustainable. Using the
terminology from Section~\ref{user-vs.-implementation-levels}, let us
cast the \emph{Web browser} as the \emph{product system} (\ie{} that
which we wish to make self-sustainable) and C++ as the \emph{platform}
(\ie{} the system we use to implement the product). What would it take
to make the browser self-sustainable?

\hypertarget{minimise-the-substrate-size}{\subsubsection{Minimise The Substrate
Size}\label{minimise-the-substrate-size}}

Recall from Section~\ref{platforms-and-substrates} that the
\emph{substrate} is the portion of the product system not accessible
from its user level. In the case of the web browser, it is the C++ code
constituting its implementation. To get a self-sustainable system, the
substrate must be minimised by shifting implementation out of it and
into the programming capabilities of the product system. In this case,
most of the named entities in the C++ code are stuck at the
implementation level, inaccessible at the user level of \ac{JS}, so we
must move the former into the latter.

To sketch how this process could be carried out systematically, we can
begin with the graphical surface of the product system. For each
graphical element, we inquire into the causes of its display; this will
include graphical rendering code, but also the data that is being
rendered and the code that generated it. By tracing backwards in this
way we discover the web of causes that produced the shape on the screen.
This will often go through the user level (\ac{JS}), but if we keep
tracing back, we will hit the implementation level. Each time this
happens, we port the code from the implementation level to the user
level.

We continue this until it is no longer feasible; for example, there will
ultimately have to be some native machine-code interpreter for \ac{JS}
in the running system. In practice, there would need to be the usual
investments in JIT compilation and optimisation technology as seen in
VMs for Smalltalk and other languages.

These ideas suggest a dimension of \emph{substrate size} as a penalty
for self-sustainability. In other words, a self-sustainable system
minimises this dimension. We already compared the strategies of doing
this minimisation earlier or later in
Section~\ref{the-major-design-conflict}. A reasonable measure of
substrate size does exist as the number of lines of code that implement
it, so we will use this measure in our evaluations later.

\hypertarget{minimise-persistence-effort-to-fix-delete-by-default}{\subsubsection{Minimise Persistence Effort to Fix ``Delete By
Default''}\label{minimise-persistence-effort-to-fix-delete-by-default}}

As we discussed from
Section~\ref{assumptions-and-consequences-in-batch-mode} onward, the
activities of a running process under Unix are considered disposable. In
order for a system to be self-sustainable, it has to be able to preserve
developments of its state through process termination. The standard VM
solution is to have most of the system state saved in an ``image'' file
and concentrate the substrate in a runnable binary that need not be
changed. However this is accomplished, \emph{persistence} of run-time
changes is necessary to encourage indefinite evolution of the system.
This applies to the whole browser, but could also be a concern for
individual tabs or web pages that can be closed or refreshed.

This suggests another penalty dimension of \emph{persistence effort.} To
illustrate the range of values, we offer the following examples:

\begin{itemize}
\tightlist
\item
  Any system which automatically persists to an ``image'' (Lisp,
  Smalltalk) or otherwise (Webstrates;~\cite{Webstrates}) causes
  \emph{minimal} persistence effort on the part of the user.\footnote{Arguably,
    this effort is zero, since the user does not have to think about it.
    However, we will stick to the term ``minimal'' for consistency with
    our stated scoring terminology.}
\item
  A system with a manual ``save'' button that persists all state would
  have almost-minimal persistence effort. This comprises both the need
  to remember to save and the act of pressing the button.
\item
  A system where one must repeat a manual procedure over different parts
  of the state to persist all of it would have \emph{moderate}
  persistence effort.
\item
  A typical programming language in a ``vanilla'' state (\eg{} excluding
  third-party libraries) has \emph{high} persistence effort for its
  runtime data structures, owing to the ``Delete By Default'' policy of
  the Unix Paradigm (Section~\ref{the-unix-paradigm}). With the use of a
  specific third-party library or framework (such as an
  Object-Relational Mapper) this persistence effort may be reduced. In
  the absence of such a framework, the programmer would have a lot of
  work to do in order to persist all state (wrap every variable and
  stack frame in code for loading and saving its value).
\item
  We could ascribe \emph{infinite}\footnote{An infinite score can be
    interpreted as saying: it would take less effort to duplicate the
    source code of the system and add persistence at its implementation
    level, than it would to persist state using user-level
    functionality.} persistence effort where it is impossible to persist
  state. This is easier to imagine in the case of an end-user
  application with no scripting capability; if the developers failed to
  persist something (\eg{} the position or sizing of a window) then the
  user cannot do anything about it. In the case of a programming system,
  hard barriers to persistence include inaccessible state (\eg{} in
  \ac{JS}, one cannot refer to stack frames or read their state) or a
  lack of enumerability (\eg{} there is no way to traverse all objects
  in the system and thereby persist them).
\end{itemize}

It may be objected that this measure should be considered on a piecemeal
basis \emph{per piece of state} instead of on the system as a whole. For
example, a system could have infinite persistence effort with respect to
some state (\eg{} stack frames;~\cite{Externalize}) but low persistence
effort with respect to everything else (this being the effort invested
to set up an Object-Relational Mapper for the rest of the state). As
mentioned in Section~\ref{aggregation-and-simplification}, given such a
fine-grained application of this measure and a method of weighting each
contribution, we could derive a convenient aggregate measure of
persistence effort for the whole system. However, this is too
complicated for the scope of our work here, so we will give an overall
impression of the property without systematically going into finer
detail.

\hypertarget{support-code-viewing-and-editing}{\subsubsection{Support Code Viewing and
Editing}\label{support-code-viewing-and-editing}}

The browser's \ac{JS} console makes it possible to make some changes
expressible as \ac{JS} commands, modulo the caveats in
Section~\ref{web-pages-web-apps-and-browsers}; these would need
mitigating. The source code can be viewed but not edited; we would need
to make a small change so that the source code viewer could also be used
to make persistent edits to code. These points suggest boolean
dimensions of \emph{code viewing} and \emph{code editing.} An example of
a system that has both is Smalltalk with its class browser.

\hypertarget{support-the-manipulation-of-code-as-data}{\subsubsection{Support the Manipulation of Code as
Data}\label{support-the-manipulation-of-code-as-data}}

Once we can type text inside the system, we will be able to write code.
However, this code will be inert unless the system can interpret data
structures as programs and actually execute them. This is the case
whether these data structures were created manually or by a program. If
this is not possible, re-programming the system will not be possible
(beyond selecting from a predefined list of behaviours). The browser
does already satisfy this criterion since \ac{JS} has an \texttt{eval()}
function that can execute a string of \ac{JS} code. This suggests a
boolean dimension of \emph{data execution.}

Any system with an \texttt{eval} function has this property, such as
Lisp. In the low-level binary world
(Section~\ref{the-low-level-binary-world}) the fact that the
\emph{instruction pointer} can be pointed at bytes in memory and
interpret them as instructions also qualifies. A negative example exists
in a language like C, where there is no \texttt{eval} function. In such
a case, one may employ the workaround of defining a mini-language
(whether textual, or a binary bytecode) and an interpreter C function.
It is important to be clear on which level the property would be thus
established: what we called the \emph{product system} (the program being
implemented by the C code) would have data execution but the
\emph{platform} (the C language itself) would remain without it.

\joel{
1. *Can you add new items to system namespaces without a restart?* The canonical example of this is in JavaScript, where "built-in" classes like `Array` or `Object` can be augmented at will (and destructively modified, but that would be a separate point). Concretely, if a user wishes to make a new `sum` operation available to all Arrays, they are not *prevented* from straightforwardly adding the method to the Array prototype as if it were just an ordinary object (which it is). Having to re-compile or even restart the system would mean that this cannot be meaningfully achieved from within the system. Conversely, being able to do this means that even "built-in" namespaces are modifiable by ordinary programs, which indicates less of a implementation level vs. user level divide and seems important for self-sustainability.
2. *Can programs generate programs and execute them?* This property, related to "code as data" or the presence of an `eval()` function, is a key requirement of self-sustainability. Otherwise, re-programming the system, beyond selecting from a predefined list of behaviors, will require editing an external representation and restarting it. If users can type text inside the system then they will be able to write code---yet this code will be inert unless the system can interpret internal data structures as programs and actually execute them.
3. *Are changes persistent enough to encourage indefinite evolution?* If initial tinkering or later progress can be reset by accidentally closing a window, or preserved only through a convoluted process, then this discourages any long-term improvement of a system from within. For example, when developing a JavaScript application with web browser developer tools, it is possible to run arbitrary JavaScript in the console, yet these changes apply only to the running instance. After tinkering in the console with the advantage of concrete system state, one must still go back to the source code file and make the corresponding changes manually. When the page is refreshed to load the updated code, it starts from a fresh initial state. This means it is not worth using the *running* system for any programming beyond tinkering.
4. *Can you reprogram low-level infrastructure within the running system?* This is a hopefully faithful summary of how the COLAs work aims to go beyond Lisp and Smalltalk in this dimension.
5. *Can the user interface be arbitrarily changed from within the system?* Whether classed as "low-level infrastructure" or not, the visual and interactive aspects of a system are a significant part of it. As such, they need to be as open to re-programming as any other part of it to classify as truly self-sustainable.}

\hypertarget{dimensions-constituting-notational-freedom}{\subsection{Dimensions Constituting Notational
Freedom}\label{dimensions-constituting-notational-freedom}}

In Section~\ref{notational-freedom} we mentioned the salient stages
prior to notational freedom, namely syntactic and linguistic freedom.
Recall that \emph{syntactic} freedom involves specifying grammars for
textual languages, while \emph{linguistic} freedom adds custom layout,
rendering and editing of textual symbols. In
Section~\ref{what-it-means-to-support-local-notations} we framed the
issue as one of \emph{removing} artificial barriers to using local
notations, while respecting the essential complexity of implementing a
notation itself. This suggests three penalty dimensions for the effort
involved in using custom syntax, linguistic forms, and general graphical
notations. One complication is that we defined these stages as
successive generalisations, \ie{} notational freedom includes and
implies linguistic freedom which includes syntactic freedom. It would
not be very helpful to observe that a system has high syntactic freedom
and then claim this gives it high linguistic freedom by virtue of the
former being contained within the latter. That is not quite what we
intend by the term ``linguistic freedom''. Instead, we would be
concerned with linguistic freedom \emph{above} the syntactic and
notational freedom \emph{above} the linguistic.

Therefore, our dimensions (all penalties) are as follows. They are
minimised if a custom syntax, language, or notation can be ``slotted
in'' once it exists, with no resistance from the system:

\paragraph{Custom Syntax Effort.}

The work required to use a custom syntax, not counting that required to
specify the syntax itself (\eg{} as a grammar).
\ac{COLA}~\parencite{COLAs} and OMeta~\parencite{OMeta} score low on
this, since they are specifically designed for this purpose. Most
programming languages have \emph{infinite} custom syntax effort, because
their parsers are separate programs that adhere to a fixed grammar that
cannot be changed by statements in the language. This includes \ac{JS}
despite its inclusion of a regex sub-syntax, HTML despite its inclusion
of \ac{JS} and CSS, and C\# despite its LINQ sub-language for queries;
these examples may exhibit syntactic \emph{diversity}, but there is no
way to include a user-supplied syntax for use in the source code.

\paragraph{Custom Language Effort.}

The work required to use custom language-like notation beyond syntax,
not counting that required to implement the rendering and interaction.
Most programming languages, \ac{COLA}, and OMeta get an infinite score
here, while MPS~\parencite{MPS} and Eco score low.

\paragraph{Custom Notation Effort.}

The work required to use custom graphical notation beyond what we called
language in Section~\ref{linguistic-freedom}, not counting that required
to implement the rendering and interaction. Only Eco, owing to a
screenshot showing inclusion of a picture, scores non-infinite on this
dimension. From their discussion in Section~9.2 of the
paper~\parencite{Eco}, it is likely to score High or Moderate rather
than Low because arbitrary graphical notations are a novel unexplored
use case for the system for which it has not been optimised.

\joel{
Consider the Web browser again; what would it take to achieve notational freedom in its JavaScript editor?

1. Again, we see that it does not yet satisfy the more modest condition of *syntactic freedom*. To achieve this, it would need to support *mood-specific languages* (see Section\ \ref{colas} below.) This means it would need some way of accepting user-supplied grammars (*Custom Grammars*) and some way of detecting which should be used for different parts of the source code (*Grammar Map.*) This latter task is made particularly troublesome because of a reliance on Implicit Structure (see Section\ \ref{explicit-structure}.)
2. *Even if* we get this syntactic freedom, we probably still have to force everything to fit in monospaced ASCII (or perhaps Unicode, as we see in the Nile/Gezira projects \parencite{Nile,Gezira}.) We still do not have full *linguistic freedom,* whereby we could, for example, render mathematics with the proper layout and formatting (as this does not quite fit into a horizontal list of non-overlapping characters.) This may require a leap from specifying grammars (which describe legal symbol sequences) to interfaces (how input causes shapes to appear, and how these are rendered.) Call these *Custom Interfaces* and *Interface Map.*
3. Once we have such infrastructure in place, it is not so small a step to generalise these interfaces to things that need not resemble a language (\eg{} a colour picker.) This gives us full *notational freedom.*

1. *Are there multiple syntaxes for textual notation?* Obviously, having more than one textual notation should count for notational diversity. However, for this dimension we want to take into account notations beyond the strictly textual, so we do not want this to be the only relevant question. Ideally, things should be weighted so that having a wide diversity of notations within some *narrow class* is not mistaken for notational diversity in a more global sense. We want to reflect that Unix, with its vast array of different languages for different situations, can never be as notationally diverse as a system with many languages *and* many graphical notations, for example.
2. *Does the system make use of GUI elements?* This is a focused class of non-textual notations that many of our example systems exhibit.
3. *Is it possible to view and edit data as tree structures?* Tree structures are extremely common in programming, but they are usually worked with as text in some way. A few of our examples provide a graphical notation for this common data structure, so this is one way they can be differentiated from the rest.
4. *Does the system allow freeform arrangement and sizing of data items?* We still felt Boxer and spreadsheets exhibited something not covered by the previous three questions, which is this. Within their respective constraints of rendering trees as nested boxes and single-level grids, they both provide for notational variation that can be useful to the user's context. These systems *could* have decided to keep boxes neatly placed or cells all the same size, but the fact that they allow these to vary scores an additional point for notational diversity.
}

\hypertarget{dimensions-constituting-explicit-structure}{\subsection{Dimensions Constituting Explicit
Structure}\label{dimensions-constituting-explicit-structure}}

The best way we have found to detect Explicit Structure is as a lack of
Implicit Structure, which we break down into \emph{producer} and
\emph{consumer} concerns. On the producer side, we have an editor with
an interface creating and changing a data structure. This is saved and
passed onto consumers, which can be collaborators using editors or a
programmer writing code to use the data structure.

It is tempting to define Implicit Structure in terms of the producer's
editing interface: a text editor has lots of it, while a structured or
projectional editor lacks it. But this is incompatible with our desire
for Notational Freedom; if someone wishes to use a text editor
\emph{interface} to type their data structures into existence, they
should be free to do so.

Equally tempting is to locate Implicit Structure in the interchange file
format, such as whether it is a text file. Yet as long as the system
handles the loading and saving for this file format, it makes no
difference from a consumer's point of view and they do not
\emph{experience} the downsides associated with Implicit Structure.

So if Implicit Structure is not about the interface, or how the data is
really stored, what is it? The definition we are interested in is about
how much users or programmers must be \emph{aware} of it and devote
cognitive resources to working with it. On the producer side, this
manifests as which types of syntax errors or more general \emph{format}
errors they are able to save and pass on to consumers
(Section~\ref{precursors-of-explicit-structure}). On the consumer side,
Implicit Structure is revealed by the amount of code we have to write to
deal with parsing, serialising, escaping, loading and saving, and so on.
Therefore we declare two penalty dimensions:

\paragraph{Format errors.}

How many different types of format errors can be introduced, saved as
invalid structures, and passed to consumers, such that they will halt
with an error? For example, text editors allow all possible syntax
errors to be saved and several format errors (\eg{} type mismatches and
use of undeclared names). However, a text editor interface that refused
to save invalid files could form part of a system with Explicit
Structure. Block or structure editors may prevent all format errors from
being saved, which would constitute the minimal value of this dimension.

\paragraph{String wrangling effort.}

How much code has to be written to convert between Implicit and Explicit
Structure? Explicit Structure implies a minimal value for this and would
look something like the following:

\begin{verbatim}
data = load('filename')
data.foo.bar = 'baz';
\end{verbatim}

Here, there are zero lines of string wrangling. Only one line,
translating between the filesystem and the internal system namespaces,
is required to prepare the data structure for use.

If such a \texttt{load} function is already present, then users
experience no string wrangling effort for the use cases of this
function, \ie{} the file formats it supports. If the function does not
exist, and a user must write string wrangling code on an ad-hoc basis,
this dimension is correspondingly high relative to that format. Suppose
the user factors this ad-hoc string wrangling into their \emph{own}
implementation of the \texttt{load} function; this implementation effort
would count towards the dimension, but would pay for itself in the
reduced string wrangling effort thereafter; this situation would lie
somewhere between the previous two.

These considerations all establish scores for this dimension
\emph{relative} to a particular file format or string syntax. These
could be aggregated to form a score for a particular program which uses
several such formats. However, if we are trying to assess the
\emph{programming system} along this dimension, we would have to somehow
aggregate across all possible programs one could create with the system,
including the various different formats they are likely to
include.\footnote{There is a large variety of \emph{existing} data
  storage formats (\eg{} JSON and XML) and an infinite variety of
  potential \emph{custom} formats that could be created on an ad-hoc
  basis (\eg{} chat messages containing special escape sequences).}

Recognising that different programming systems are targeted at different
goals and have differing strengths and weaknesses, the possibility space
could be refined into all \emph{likely} programs or use cases of the
programming system, weighted by the probability of a user of the system
wanting to create such a program. This opens up further decisions about
this user and whether we should additionally aggregate across possible
(or likely) users of the system. We could go further, but we think the
complexity is clear; as mentioned in
Section~\ref{dimensions-qualitative-and-quantitative}, we will simply
give our judgement about how BootstrapLab as a whole scores on this
dimension and leave more sophisticated approaches to future work
(Section~\ref{improving-the-technical-dimensions}).

\joel{
How can we detect explicit structure in a programming system? Consider once again the Web browser. It has two major subdivisions of state: the DOM tree and the JavaScript object graph. For change, it only has those special JavaScript objects known as functions, worked on via the console and the source code view. We can examine these three areas separately:

\paragraph{DOM Tree.} The DOM tree is accessed manually through the Element Inspector and programmatically through JavaScript APIs, but is in both cases largely explicitly structured. The main exception involves the APIs taking HTML strings to create elements, and the initial stage of loading the HTML and JS source files. But once these structures have been recovered and built, much can take place without the intermediary of strings.

The other important exception to this occurs in SVG structures. SVG uses element *attributes* for composite data like matrix transformations, and hence has to store these as strings. For example, a node might have a `transform` of `translate(100,200)`. This means that, in order to move the element 10 units horizontally, the programmer must write code to extract the first co-ordinate as a number, add 10, and render the whole expression back to a string.

Related to attributes, CSS classes are a mixed case; on the one hand, the `style` attribute contains CSS source code, yet the JavaScript API does include properties for accessing this information explicitly.

\paragraph{JSOG.} The JavaScript object graph is also explicitly structured at runtime, while object definitions in the source code are obviously not.

\paragraph{JS Code.} Unlike the other two areas, JavaScript code is not explicitly structured even in the running system. There is a minimal level of structure: namely, the source file is split into Function objects (intervening lines with any side effects have already been executed and are inaccessible.) Beyond this, however, the body of each function is only accessible as a string. The obvious condition to meet here is that the AST should be navigable via some JavaScript API (*AST Access.*) Such a single level of explicit structure is shared with spreadsheets (where any structure within a cell is implicit) and databases (data within a column is implicitly structured.)

It appears that there are two realms in which explicit structure may be sought, corresponding to the Volatility Split: the contents of the source files vs. the content of the running system. Each of these could be further split between State and Change; in the Web browser, State largely has explicit structure in memory, but not on disk, and Change lacks it in both places.

\todo{Unix Files, spreadsheet, database}
}

\hypertarget{evaluating-bootstraplab}{\section{Evaluating BootstrapLab}\label{evaluating-bootstraplab}}

Having finally distilled the Three Properties into Technical Dimensions,
we will now apply them to BootstrapLab to gauge how far we succeeded at
our goals.

\hypertarget{measures-of-self-sustainability}{\subsection{Measures of
Self-Sustainability}\label{measures-of-self-sustainability}}

\criterion{Substrate Size: 1550 LoC.}

BootstrapLab's homogeneity of state contributes to a smaller substrate
than a design where system registers and user data lived in two separate
partitions of state. There is deliberately only one system namespace:
the state graph rooted at the top-level registers. Some of these names
have special functions in the low-level ASM, but otherwise this
namespace is free for user additions. These can be added manually in the
in-system editor or in code by the primitive \texttt{store} instruction.

The present graphical state of the system lives entirely in a special
part of the system state: the \texttt{scene} tree. Therefore, at any
given moment, it is possible to change what the graphics window will
display. However, there are two limitations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The range of these changes is constrained to the range of graphical
  primitives currently understood by the substrate which it passes on to
  THREE.js. Currently these are limited to axis-aligned flat-coloured
  rectangles and basic text of a uniform size, style, colour, etc.
\item
  The behaviour that affects the graphics currently lives in \ac{JS}.
  This means that the logic according to which the tree editor renders
  map entries is inaccessible to in-system code.
\end{enumerate}

Indeed, there are about 1550 lines of \ac{JS} off-limits to the actions
of the system. At least 33\% of this, however, constitutes our substrate
debt (Section~\ref{substrate-debt-in-bootstraplab}): the Masp
interpreter and tree editor. In a further-developed version, these could
be moved out. Even so, in such a further-developed version, the
substrate may be larger anyway by exposing more types of graphical
primitives. This suggests that capabilities of the platform provide a
lower bound on the substrate size: if the platform provides a way to
draw a circle, but the substrate does not expose this to the system,
then we have reason to interpret this as an incomplete programming
system. On the other hand, the substrate may expose a more general set
of graphics operations that allow the system to draw circles itself, say
to a pixel surface.

\criterion{Persistence Effort: Moderate.} Part or all of the state graph
can be manually persisted via the \texttt{export\_state()} function in
the browser console. This means that in-system progress can be saved,
even though it would be better for the user experience to have this done
automatically. It is clear that indefinite evolution is \emph{permitted}
but perhaps not quite \emph{encouraged}.

\criterion{Code Editing: present.} Code editing is crude but feasible
via the in-system tree editor for most use cases. In rare cases, the
\ac{JS} console must be used.

\criterion{Data Execution: Present.} Because of Alignment
(Force~\ref{alignment}), low-level instructions that change state are
represented as ordinary maps with certain format constraints. The
instruction set is sufficient for constructing arbitrary graph
structures in the state, including programs composed of instructions.
The \texttt{next\_instruction} register can be pointed at such a list
and execution can be started using \texttt{run\_and\_render()} in the
\ac{JS} console. The analogous properties hold for high-level Masp code
which is also represented as maps.

\paragraph{Verdict.}

BootstrapLab's practical capacity to change its implementation is
limited by its substrate debt and its manual persistence adds friction
to working within the system. Still, there are no hard barriers to
self-sustainability.

\hypertarget{measures-of-notational-freedom}{\subsection{Measures of Notational
Freedom}\label{measures-of-notational-freedom}}

\criterion{Custom syntax effort: moderate.} Because of substrate debt,
it may not be possible to make changes at the user level such that a
string can be ``executed'' according to custom syntax and semantics via
a click or key combination. However, it is possible to use the
\texttt{js} ``escape hatch'' instruction to embed arbitrary \ac{JS} code
to do the appropriate processing. In the absence of substrate debt, it
would be possible to edit the relevant parts of the system to support
custom syntaxes---both textual, as strings, but also ``structural'' with
different map structures to those that Masp expects. This direct editing
of the system could still be costly, and adopting the techniques in the
Lisp half of \ac{COLA} \parencite{OECM} or OMeta \parencite{OMeta} could
bring custom syntaxes closer to being ``slotted in'' without difficulty.

\criterion{Custom language effort: moderate.} This follows similar
considerations, except the substrate debt related to graphical
capabilities and the lack of exposure of certain platform graphical
primitives are also relevant here. However, implementing language-like
notations may be aided by the existing layout capabilities of the tree
editor.

\criterion{Custom notation effort: moderate.} Again the reasoning is
similar, but in this case the tree editor layout capabilities may not be
directly helpful. Here, the lack of exposure of platform graphics
primitives limits what can be achieved. Still, as shown in
Section~\ref{real-example-colour-preview}, use of custom notations is
\emph{feasible} as long as the appropriate ``hook point'' is available,
which we added to the substrate specifically for the proof-of-concept.

\paragraph{Verdict.}

BootstrapLab in its current state \emph{permits} notational freedom but
at a moderate cost. This is still an improvement on the norm of
\emph{infinite} cost in programming systems (recall the examples in
Section~\ref{dimensions-constituting-notational-freedom}).

\joel{
\criterion{Are there multiple syntaxes for textual notation? No.} Only JavaScript syntax is available in the special `js` instruction. However, the system is built on explicit structure, so syntax does not make much of an appearance at all.

\criterion{Does the system make use of GUI elements? Yes.}
BootstrapLab's graphics window is a zoomable/draggable view containing a crude tree editor. Next to it is a rendering of the state tree in ordinary web HTML elements.

\criterion{Is it possible to view and edit data as tree structures? Yes.}
Tree-structured data can be viewed in the HTML-rendered tree view and the in-system tree editor. It can be edited only in the latter.

\criterion{Does the system allow freeform arrangement and sizing of data items? No.}
We did not have enough time to support the moving and resizing of items in the graphics window.

\criterion{Is there support for custom user-supplied notations? Potentially.}
The code for rendering the tree editor and accepting user input currently lives in the substrate. However, we gave a proof-of-concept in\ Section\ref{provide-for-domain-specific-notations} for how this could be moved in-system. Because of this, there is no inherent barrier to custom notations.

\criterion{Is there support for custom user-supplied grammars? Potentially.} Ditto.
}

\hypertarget{measures-of-explicit-structure}{\subsection{Measures of Explicit
Structure}\label{measures-of-explicit-structure}}

\criterion{Format errors: low.} The structure editing interface of the
tree editor eliminates the existence of syntax errors for data, Masp
code, and instructions. Within these structures, certain format errors
are possible (\eg{} failing to supply required arguments to an
instruction).

\criterion{String wrangling effort: low.} Because all data, including
instructions and Masp code, is embedded in map data structures edited
structurally, there is little need for the user to write parsing or
serialising code. The sole exceptions are with hexadecimal colour codes,
where the initial \texttt{\#} character may need stripping, and rendered
map entries, where the colon \texttt{:} needs attaching and stripping.
Strings are of course present, but as primitive values without
substructure (\eg{} names).

\paragraph{Verdict.}

BootstrapLab succeeds at our goal of being based on explicit structure.
All ``code'' or ``language'' structures are represented directly instead
of as text strings.

\hypertarget{conclusions}{\section{Conclusions}\label{conclusions}}

BootstrapLab embodies our Three Properties to a satisfactory extent; it
is strongest on Explicit Structure and weaker on Notational Freedom and
Self-Sustainability. In a system developed without attention to these
properties, the default practices of programming would end up raising
barriers to their realisation
(Section~\ref{accidental-complexity-beyond-languages}). We deliberately
designed BootstrapLab to support these properties and avoid hard
barriers to them, so there is significant potential for improvement from
further development efforts. We will outline this future work
in~Section~\ref{improving-bootstraplab}.

Beyond this dissertation, there is interest in developing new
programming systems. Such systems go beyond the simple model of code
written in a programming language using a more or less sophisticated
text editor. They combine textual and visual notations, create programs
through rich graphical interactions, and challenge accepted assumptions
about program editing, execution and debugging. Despite the growing
number of novel programming systems, it remains difficult to evaluate
the design of programming systems and to see how they improve over work
done in the past. To address the issue, we proposed a framework of
``technical dimensions'' that captures essential characteristics of
programming systems in a systematic fashion.

This framework puts the vast variety of programming systems, past and
present, on a common footing of commensurability. As more and more
systems are assessed in the framework, a picture of the space of
possibilities will gradually emerge. Some regions will be conspicuously
empty, indicating unrealised possibilities that could be worth trying;
this is how we regard BootstrapLab. In this way, a domain of ``normal
science'' is created for the design space. Designers of the next
generation of programming systems can then build upon the successes and
lessons of those that came before.
\clearpage{}
\cleardoublepage
\clearpage{}\hypertarget{ch-related-work}{\chapter{Related Work}\label{ch-related-work}}

In the preceding chapters, we referenced programming systems and
research literature that were directly relevant to the topics we were
discussing. At this point, having presented BootstrapLab and evaluated
it according to the Technical Dimensions, we can situate our
contributions in the setting of more general related work. We will cover
the research group from which many of our influences originate, work
relating to each of the Three Properties, and the study of programming
systems. Note that some references may be repeated from earlier for the
sake of completeness.

\hypertarget{steps-and-the-legacy-of-vpri}{\section{STEPS and the Legacy of
VPRI}\label{steps-and-the-legacy-of-vpri}}

The \ac{COLA} system design~\parencite{COLAs}, from which we have drawn
the most in this work, emerged from the now-retired Viewpoints Research
Institute (VPRI). VPRI aimed at creating ``fundamentally new computing
technologies'', which is particularly visible throughout the 6-year
project known as ``STEPS towards a new computing''
\parencite{Steps08,Steps09,Steps10,Steps11,Steps12}. The aim was to
fully replicate a familiar graphical end-user operating system, with
applications, in under 20,000 total lines of code. Such an ambitious
goal provided the constraint needed to force innovation in
distinguishing essential and accidental complexity and ways to reduce
the latter. Innovations included the widespread use of domain-specific
languages supported by OMeta~\parencite{OMeta} and investment in highly
flexible core abstractions as evidenced by \ac{COLA}'s object and
composition models \parencite{OROM,OECM}.

Two of our Three Properties, Self-Sustainability and Notational Freedom,
recur as themes in the STEPS work.\footnote{Explicit Structure is
  absent, but this is to be expected owing to its niche status; see
  Section~\ref{structure-editing-and-its-variations}.}
Self-Sustainability is exhibited by \ac{COLA}. Mood-Specific Languages
in \ac{COLA} and those supported by OMeta demonstrate what we called
\emph{syntactic freedom} in Section~\ref{syntactic-freedom}. The
Gezira~\parencite{Gezira} and Nile~\parencite{Nile} projects utilise a
custom mathematical syntax, taking advantage of Unicode characters for
expressing graphics code that is cumbersome in ordinary languages. While
this does not amount to Syntactic Freedom, it is a good example of the
sort of thing that Syntactic Freedom enables; we can expect more
innovations like this only if it is not too difficult to deploy a custom
syntax once one has been designed.

\hypertarget{self-sustainability-and-its-theory}{\section{Self-Sustainability and its
Theory}\label{self-sustainability-and-its-theory}}

The only name we are aware of for the concept we called
Self-Sustain-ability is ``self-sustaining'', seen in the two workshops
on such systems \parencite{SSS-08,SSS-10} which featured the \ac{COLA}
work. We derived our term ``Self-Sustainability'' to be able to refer to
a property that can be present or absent in programming systems. We have
referred to Self-Sustain\emph{able} systems rather than
Self-Sustain\emph{ing} systems for consistency with this.

Self-Sustainability appears in related work as Smalltalk variants. Much
of the STEPS work took place via the Squeak\footnote{\url{https://squeak.org/}}
variant, of which Pharo\footnote{\url{https://pharo.org/}} is a
descendant. Glamorous Toolkit\footnote{\url{https://gtoolkit.com/}} is a
``moldable development environment'' built in Pharo. The Lively
Kernel\footnote{\url{https://lively-kernel.org/}} is a Web
implementation of a Smalltalk-like environment; Fizzygum\footnote{\url{http://fizzygum.org/}}
is similar.

The problem with all of these, as regards our goals in this
dissertation, is that they are all complicated software systems, with
their own histories, made to be practically useful to researchers or
industry. As such, knowledge of the principles and tricks for
\emph{implementing} these systems is sequestered away in the practical
experience of their developers and not written down in a discoverable
location. Furthermore, it would be difficult to separate knowledge about
the property we are interested in (Self-Sustainability) from the various
other aspects of the implementation of these systems (such as useful
libraries or optimisations).

These facts made it clear to us that we would be best equipped to
understand Self-Sustainability by trying to achieve it ourselves in a
minimal context with minimal distractions. The related systems are
self-sustainable in order to be useful for certain communities;
BootstrapLab aims for Self-Sustainability to better understand it (along
with the other two Properties).

We are only aware of a few sources that aim at a similar goal of
understanding. The ``Meta-Helix'' approach of~\parencite{Meta-helix} is
intended to reduce confusion when implementing meta-circular
Meta-Object-Protocols. As we mentioned in
Section~\ref{precursors-of-self-sustainability}, meta-circularity is a
specific manifestation of Self-Sustainability. The exhaustive
development of Procedural Reflection for Lisp-like languages
in~\parencite{ProcRefl} is helpful for its philosophical rigour, \eg{}
the use-mention distinction and careful precision of terminology. The
process described in~\parencite{Bootfrom0} is a parallel of what we did
with BootstrapLab in the restricted context of batch-mode interpreters
of text strings. The introductory sections of~\parencite{COLAs}
and~\parencite{OROM} constitute a good explanation of
Self-Sustainability and why it is desirable, as
does~\parencite{CookClay}.

\hypertarget{video-games}{\section{Video Games}\label{video-games}}

Video games and game engines are led in the \emph{direction} of
Self-Sustainabil-ity by their nature as highly dynamic, long-lived
virtual environments. They are an example of the issues we covered in
Section~\ref{static-commitment}. The creative world-building nature of
games means that requirements change more often than other types of
software; development is partly a process of discovery of what the final
product should be. Accordingly, it is important to rapidly prototype and
iterate ideas, especially by artists or other specialists who may not be
expert programmers. This incentivises ways to try out new ideas without
the costly operation of restarting a large, resource intensive process
or the even more costly operation of re-compiling the underlying
program. It also incentivises editing tools (for game levels, internal
scripting languages, or configuration) to be part of the game software
itself. After development, these internal ``developer tools'' may either
be stripped from the version shipped to customers or hidden (in which
case, enterprising customers will discover them eventually).

Since games also have strong requirements for real-time performance
(responsiveness to input, rendering of complex scenes, simulating
physics, synchronising a shared world across the internet, and managing
worlds too large to fit into memory all at once) languages like C++ are
a standard choice for implementation. However, the default data
structuring mechanisms of these languages (such as C++ classes) must
necessarily be avoided for directly modelling highly dynamic
relationships between objects in the simulated world. A C++ class
promises a \emph{static commitment} to \emph{always} contain its listed
member variables of the specified types, member functions of the
specified signatures, and to \emph{always} remain in any inheritance
relationships with other classes. This rules out a majority of the
dynamic change that is inherent to the behaviour of a game and its
development process. For this reason, standard game programming
patterns~\parencite{GPP} build infrastructure to work around this and
support the modelling of objects whose relationships and contained
properties may change during run time. ``Entity Component Systems''
\parencite{ECS} are a widely used architecture for this purpose. The
general pattern of working around static commitment is known as
``Greenspun's Tenth Rule'' \parencite{Greenspun10}:

\begin{quote}
Any sufficiently complicated C or Fortran program contains an ad-hoc,
informally-specified, bug ridden, slow implementation of half of
CommonLisp.
\end{quote}

\hypertarget{novel-notations-versus-notational-freedom}{\section{Novel Notations versus Notational
Freedom}\label{novel-notations-versus-notational-freedom}}

``Visual Programming'' contains many examples of custom notations for
program code and data. Sketchpad~\parencite{Sketchpad} is an early,
influential example of diagrammatic notation augmented with the dynamic
capabilities of computation. The Apparatus editor\footnote{\url{http://aprt.us/}}
is a Web-based editor for dynamic graphics influenced by Sketchpad. Bret
Victor's presentations~\parencite{DDV} demonstrate programmatic graphics
based on direct manipulation instead of textual code. Data is
represented in Boxer~\parencite{Boxer} and Forms/3~\parencite{Forms3} as
named, nested boxes; in Boxer, programs reside in textual code boxes.
Programming By Example and Programming By
Demonstration~\parencite{WWID,YWIMC} involve custom notations designed
for either representing program structures or for supplying example
input-output pairs from which to infer general behaviour.
Sketch-n-Sketch~\parencite{SnS} uses a textual and graphical notation
that are synchronised with each other.

There are many more examples of custom programming~notations and
interfaces \parencite{VPcodex,VPsurvey,GalleryUIs}. Despite the
abundance of earnest attempts at general-purpose or special-purpose
notations, programming is still mostly performed via plain text. This is
understandable given that much of the cited research is experimental and
that programming infrastructure (editors, compilers, version control
etc.) only supports plain text. There is also a potential failure mode
of imposing a single notation for all purposes and the fact that
different people have preferences about the tools they work with.

Thus, while we respect the effort invested in Visual Programming and
custom notations and wish these efforts success, we avoid the conclusion
that there is an optimal notation or set of notations (across users and
situations) waiting to be found. Instead, we see as-yet unrealised gains
in supporting and encouraging the \emph{ad-hoc} use of custom notations
on an opportunistic basis, wherever the user judges them to be most
helpful. We observe much effort expended over the years on developing
custom notations but comparatively little on enabling them to be used
together \emph{à la carte}, which is why we focus on Notational
\emph{Freedom.}

We see efforts towards Notational Freedom in JetBrain's
MPS~\parencite{MPS}, the Eco editor~\parencite{Eco}, and the
Mood-Specific Languages of \ac{COLA}~\parencite{COLAs} and
OMeta~\parencite{OMeta}. Our issue with MPS is similar to what we said
about Smalltalk-like systems in
Section~\ref{self-sustainability-and-its-theory}: it is impressive and
useful as an industry tool in which to get things done, but its size and
complexity makes it hard to learn the essential aspects of supporting
Notational Freedom. Eco has the advantage of being a research project
whose paper \emph{does} cover its design and implementation, so its
approach deserves a place in future work on BootstrapLab (see
Section~\ref{import-from-related-work}).

\hypertarget{structure-editing-and-its-variations}{\section{Structure Editing and Its
Variations}\label{structure-editing-and-its-variations}}

Explicit Structure has precedent in structure editors, projectional
editors and block-based languages ~\parencite{StrucEd}, but these
approaches have met many difficulties in terms of widespread adoption.
Text editing and plain text formats are still entrenched as the \emph{de
facto} standard in programming. \emph{Outside} of programming, we
observe the opposite situation, which allows us to point there for
intuition about why Explicit Structure is a sensible concept and could
be beneficial.

For example, photo editing and vector graphics programs exist and are
optimised for the types of interactions involved in those domains. Photo
and vector graphics files are not required to be readable in a text
editor (\ie{} we are free to distribute graphics in forms other than
ASCII art) and so these domains do not suffer from the accidental
complexities of text formats. If we observe that the textual syntax of
programs is really a \emph{proxy} for tree and graph structures, then
this invites the investigation of the costs and benefits of treating
programming structures the same way we do other types of files.

We are aware of two projects especially concerned with Explicit
Structure: the Subtext programming system~\parencite{Subtext} and the
Infra~\parencite{Infra} data interchange format. Subtext explores novel
programming ideas that are only feasible from a basis of Explicit
Structure, while Infra is proposed as a common format unifying text and
binary data. We find these sources particularly valuable for explaining
Explicit Structure and arguing its benefits.

\joel{
# Against Conventional Wisdom
A plausible hypothesis about *why* programming is the way it is---and hence why this thesis has a novel contribution to make---concerns a mismatch between programming's *military-industrial* history and its modern potential for *personal* computing. This is the logic behind the work of Kell and Basman.
\cite{Kell-os}
\cite{Externalise}
\cite{Kell-mmm}
\cite{OAP}
\cite{Entangle}
\cite{Entangle-critique}
\cite{TcherDiss}
\cite{SwStudies}
\cite{Wisdom}
\cite{Top}
}

\hypertarget{programming-systems-and-their-analysis}{\section{Programming Systems and their
Analysis}\label{programming-systems-and-their-analysis}}

Our ``programming systems'' approach lies between a narrow focus on
programming languages and a broad focus on programming as a
socio-political and cultural subject. The concept of a programming
system is technical in scope, although we acknowledge the technical side
often has important social implications as in the case of the
``Adoptability'' dimension (Section~\ref{adoptability}). This contrasts
with the more socio-political focus found in~\textcite{TcherDiss} or in
software studies~\parencite{SwStudies}. It overlaps with Kell's
conceptualisation of Unix, Smalltalk, and Operating Systems
generally~\parencite{Kell-OS}.

The distinction between more narrow \emph{programming languages} and
broader \emph{programming systems} is more subtle. Richard Gabriel noted
an invisible paradigm shift from the study of ``systems'' to the study
of ``languages'' in computer science during the 1990s~\parencite{PLrev},
and this observation informs our distinction here. One consequence of
the change is that a \emph{language} is often formally specified apart
from any specific implementations, while \emph{systems} resist formal
specification and are often \emph{defined by} an implementation. We
recognise typical programming language implementations (\eg{} including
an ordinary compiler and text editor) as a \emph{small region} of the
space of possible systems, at least as far as interaction and notations
might go. Our attention is drawn to \emph{interactive programming
system} aspects of languages, such as text editing and command-line
workflows.

\hypertarget{programming-systems-research}{\subsection{Programming systems
research}\label{programming-systems-research}}

There is renewed interest in programming systems in the form of recent
non-traditional programming tools:

\begin{itemize}
\tightlist
\item
  Computational notebooks such as Jupyter~\parencite{Jupyter} facilitate
  data analysis by combining code snippets with text and visual output,
  in a manner reminiscent of Literate Programming~\parencite{LitProg}.
  They are backed by stateful ``kernels'' and used interactively.
\item
  ``Low code'' end-user programming systems allow application
  development (mostly) through a \ac{GUI}. One example is
  Coda~\parencite{CodaWeb}, which combines tables, formulas, and scripts
  to enable non-technical people to build ``applications as documents''.
\item
  Domain-specific programming systems such as Dark~\parencite{DarkWeb},
  which claims a ``holistic'' programming experience for cloud API
  services. This includes a language, a direct manipulation editor, and
  near-instantaneous building and deployment.
\item
  Even for general purpose programming with conventional tools, systems
  like Replit~\parencite{ReplitWeb} have demonstrated the benefits of
  integrating all needed languages, tools, and user interfaces into a
  seamless experience, available from the browser, that requires no
  setup.
\end{itemize}

Research that follows the programming systems perspective can be found
in a number of research venues. Those include Human-Computer Interaction
conferences such as \href{https://uist.acm.org/}{UIST}\footnote{ACM
  Symposium on User Interface Software and Technology} and
\href{https://conferences.computer.org/VLHCC/}{VL/HCC}\footnote{IEEE
  Symposium on Visual Languages and Human-Centric Computing}. However,
work in those often emphasises the user experience over technical
description. Programming systems are often presented in workshops such
as \href{https://liveprog.org/}{LIVE} and
\href{https://2021.programming-conference.org/home/px-2021}{PX}\footnote{Programming
  eXperience}. However, work in those venues is often limited to the
authors' individual perspectives and suffers from the aforementioned
difficulty of comparing to other systems.

Concrete examples of systems were given in
Section~\ref{examples-of-programming-systems}. Recent systems which
motivated some of our dimensions include Subtext~\parencite{Subtext},
which combines code with its live execution in a single editable
representation; Sketch-n-sketch~\parencite{SnS}, which can synthesise
code by direct manipulation of its outputs; Hazel~\parencite{Hazel}, a
live functional programming environment with typed holes to enable
execution of incomplete or ill-typed programs; and
Webstrates~\parencite{Webstrates}, which extends Web pages with
real-time sharing of state.

\hypertarget{already-known-characteristics}{\subsection{Already-known
characteristics}\label{already-known-characteristics}}

There are several existing projects identifying characteristics of
programming systems. Some revolve around a single one, such as levels of
liveness~\parencite{Liveness}, or plurality and
communicativity~\parencite{Kell-C}. Others propose an entire collection.
\emph{Memory Models of Programming Languages}~\parencite{Mem-mods}
identifies the ``everything is an X'' metaphors underlying many
programming systems; for example, the ``everything is a file'' of Unix
and the ``everything is an object'' of Smalltalk. The \emph{Design
Principles of Smalltalk}~\parencite{STdesign} documents the
philosophical goals and dicta used in the design of Smalltalk; the
``Gang of Four'' \emph{Design Patterns}~\parencite{DesPats} catalogues
specific implementation tactics; and the \emph{Cognitive Dimensions of
Notation}~\parencite{CogDims} introduces a common vocabulary for
software's \emph{notational surface} and for identifying their
trade-offs.

The latter two directly influence our Technical Dimensions framework.
Firstly, the Cognitive Dimensions are a set of qualitative properties
which can be used to analyse \emph{notations}. We are extending this
approach to the ``rest'' of a system, beyond its notation, with
\emph{Technical} Dimensions. Secondly, our individual dimensions
naturally fall under larger \emph{clusters} that we present in a regular
format, similar to the presentation of the classic Design Patterns. As
for characteristics identified by others, part of our contribution is to
integrate them under a common umbrella: the existing concepts of
liveness, pluralism, and uniformity metaphors (``everything is an X'')
become dimensions in our framework.

\hypertarget{methodology}{\subsubsection{Methodology}\label{methodology}}

We follow the attitude of \emph{Evaluating Programming
Systems}~\parencite{EvProgSys} in distinguishing our work from HCI
methods and empirical evaluation. We are generally concerned with
characteristics that are not obviously amenable to statistical analysis
(\eg{} mining software repositories) or experimental methods like
controlled user studies, so numerical quantities are generally not
featured.

Similar development seems to be taking place in HCI research focused on
user interfaces. The UIST guidelines~\parencite{UISTAuthor} instruct
authors to evaluate system contributions holistically, and the community
has developed heuristics for such evaluation, such as \emph{Evaluating
User Interface Systems Research}~\parencite{EvUISR}. Our set of
dimensions offers similar heuristics for identifying interesting aspects
of programming systems, though they focus more on underlying technical
properties than the surface interface.

Finally, we believe that the aforementioned paradigm shift from
programming systems to programming languages has hidden many ideas about
programming that are worth recovering and developing
further~\parencite{ComplementaryBasic}. Thus our approach is related to
the idea of \emph{complementary science} developed by
Chang~\parencite{Chang} in the context of history and philosophy of
science. Chang argues that even in disciplines like physics, superseded
or falsified theories may still contain interesting ideas worth
documenting. In the field of programming, where past systems are
discarded for many reasons besides empirical failure, Chang's
\emph{complementary science} approach seems particularly suitable.
\clearpage{}
\cleardoublepage
\clearpage{}\hypertarget{future-work-and-conclusions}{\chapter{Future Work and Conclusions}\label{future-work-and-conclusions}}

Having followed the development of BootstrapLab in Chapter~\ref{bl} and
its evaluation along the Technical Dimensions from
Chapter~\ref{tech-dims}, we now turn to the limitations of these two
contributions and sketch the future work that they suggest. Some of the
forthcoming points have already been introduced by necessity as part of
earlier chapters, but here we have an opportunity to expand on them in
more detail. We first address our Technical Dimensions framework,
acknowledging the pragmatic simplifications we had to make and exploring
the challenges of making it more rigorous. Subsequently, we acknowledge
BootstrapLab's state as a work-in-progress, suggesting how to continue
its development and apply its approach to other domains. Finally, we
bring this work to a close by reviewing what we have presented and how
it relates to the broader vision from
Section~\ref{how-should-things-work}.

\hypertarget{improving-the-technical-dimensions}{\section{Improving the Technical
Dimensions}\label{improving-the-technical-dimensions}}

In Chapter~\ref{tech-dims}, we proposed a systematic approach to
analysing programming systems that go beyond languages. We took our
complex and qualitative Three Properties and derived quantitative
\emph{dimensions} to act as a proxy for them. These dimensions were
narrow enough to apply to BootstrapLab. However, we were limited by
scope to \emph{argue} for the scores we gave, which is far from the
everyday process of self-evident ``measurement'' that we ideally desire
to have.

In this discussion, we will take the approach of prioritising
\emph{conceptual} clarity. We will put practical issues to one side and
inquire about what a rigorously perfected Technical Dimensions would
look like, even if the answer would be practically infeasible to work
with. Then we will add the practical concerns back in. In the end,
future work consists both of improving the theoretical concepts
\emph{and} developing practical methods of using them. We note that some
of the following issues were acknowledged in the Appendix of our
Technical Dimensions paper~\parencite{TechDims}. However, the discussion
here should be taken to be a more updated version which supersedes that
of the paper wherever they overlap.

\hypertarget{scoping-the-dimensions}{\subsection{Scoping The Dimensions}\label{scoping-the-dimensions}}

Even if some property fails to hold for an entire programming system, it
may well still hold for some part of the system. For example, take our
\emph{persistence effort} dimension from
Section~\ref{dimensions-constituting-self-sustainability} and imagine a
Smalltalk-like system where everything is automatically persisted except
for a single, special global called \texttt{x}. It would be unhelpful to
characterise this system as having infinite persistence effort simply
because it is technically impossible to persist the entire state.
Informally, we see that it has \emph{mostly} minimal persistence effort
with the sole exception of \texttt{x}, for which it is infinite. This
example was deliberately extreme, but a more realistic one is the Web
platform whose \ac{JS} stack cannot be referenced or traversed by
\ac{JS} code.

The true scope of a dimension like ``persistence effort'' is more of a
\emph{field} in the physical sense, defined at every atomic piece of
state in the system (the \emph{field points}). Similarly, ``custom
syntax effort'' from
Section~\ref{dimensions-constituting-notational-freedom} is defined for
individual syntaxes that a user may wish to use in the system, whether
they already exist or merely potentially could exist. This highlights
the additional difficulty that we may wish to characterise a system not
only by how it happens to be right now, but by how it would perform
across many \emph{potential} use cases. We mentioned the complexity of
considering ``actual'' vs.~``potential'' field points when defining
\emph{string wrangling effort} in
Section~\ref{dimensions-constituting-explicit-structure}; this dimension
properly applies per ``situation'' consisting of a specific user,
programming against a specific string format, in a specific program.
These terms (user, string format, program created with the programming
system) all invite further definition.

Making all this more precise, and establishing the minimal scope of the
other dimensions we have proposed, is an open problem. As the next best
option, we gave scores for BootstrapLab as a whole in Section
\ref{evaluating-bootstraplab} while elaborating on any relevant
complications in prose.

\hypertarget{aggregation-functions-and-weights}{\subsection{Aggregation Functions and
Weights}\label{aggregation-functions-and-weights}}

Having realised that the dimensions apply as more of a ``field'', we
could recover the simpler coarser-level score that we want as some sort
of \emph{aggregation} of the finer-level scores. We mentioned this in
Section~\ref{aggregation-and-simplification} to pre-empt any concerns
about our simplified approach to the dimensions: in the absence of a
rigorous treatment of the ``scoping problem'' just discussed, we were
forced to do the aggregation \emph{intuitively} based on our
understanding of BootstrapLab.

Future work would consider what the aggregation function should be: a
simple addition (even an integral) over scores, an average, or something
else. Where \emph{potential} field points (users, programs, notations,
etc.) are concerned, the infinite possibilities mean some sort of
weighted aggregation would be necessary. We might compress the infinite
range into a finite number of categories, one of which is a catch-all
``other'' category, and assign a weight for the probability or relevance
of each category. This introduces a further question of how these
weights are established or justified; intuitively, we know that
programming systems have strengths and weaknesses and are built to cater
to different problem domains or types of user, but how could this be
made more rigorous? We must leave this, and the full development of the
other ideas we have sketched here, as open questions.

\hypertarget{defining-quantitative-measures-or-resolution-criteria}{\subsection{Defining Quantitative Measures or Resolution
Criteria}\label{defining-quantitative-measures-or-resolution-criteria}}

So far, our concerns have been conceptual; we have been talking about
hypothetical ``scores'' and ``weights''. In our evaluation of
BootstrapLab, we remained at this ``almost-quantitative'' level: we
scored using the terms ``minimal'', ``moderate'', and so on (or
``present'' / ``absent'' for boolean criteria). We justified these
scores by means of argument and intuition. This is suboptimal from a
research perspective; a fully developed dimensions framework should
enable researchers to agree or at least productively disagree (perhaps
leading to new dimensions or definitions on which they \emph{do} agree).

One improvement would be to further define \emph{resolution criteria}
for our score terms to the point that two parties, following the same
definitions, would independently converge on the same scores.
Alternatively, we might pursue \emph{real} quantitative scores with
concrete numbers. The challenge here would be avoiding the trap of
properties that are easily quantifiable yet irrelevant or uninteresting.
A good quantification (or set of quantified dimensions) should feel like
a strict \emph{improvement} on the qualitative description, rather than
something that has lost an important feature of the qualitative
description. In its absence, we would err on the side of staying with
the qualitative and holding out for a future quantitative definition,
instead of committing to the suboptimal quantitive definition for the
sake of having numbers at all.

\hypertarget{obtaining-consensus-on-scores}{\subsection{Obtaining Consensus on
Scores}\label{obtaining-consensus-on-scores}}

Even with narrow, precise definitions of how a dimension should be
scored, it is a further task to establish consensus on \emph{what} the
score is for a given system. A perfectly crisp definition would be
followed the same way by all parties and lead to the same conclusion,
but we would not expect this in practice. Variations could arise from
researchers interpreting terms in the definitions differently,
aggregating differently over field points, or circumscribing systems
differently (see the following
Section~\ref{the-circumscription-problem-of-systems}).

The point of the Technical Dimensions framework is to edge towards an
\emph{objective} analysis of programming systems, on which different
researchers can readily agree. A situation where there is an implicit
``subject'' parameter (system S scores X along dimension D
\emph{according to person P}) may be a necessary evil in the short term,
but researchers should strive to debug their disagreements and improve
the dimensions to the point where the ``person'' can be dropped.

\hypertarget{the-circumscription-problem-of-systems}{\subsection{The Circumscription Problem of
Systems}\label{the-circumscription-problem-of-systems}}

One issue that has been present throughout this dissertation, and
touched on in Section~\ref{systems-based-around-languages}, concerns
what exactly we refer to with the names ``Smalltalk'', ``Lisp'',
``Java'', and so on. Definition~\ref{def:programming-system} certainly
helps, but there is still a lot of freedom in how we draw the boundary
around named programming systems.

For example, there are different distributions and implementations of
Smalltalk, different versions of each one, and different concrete
running instances used by people including different libraries and
personal tweaks. We have implicitly taken ``Smalltalk'' to be some
suitable aggregation over these, evoking what is common to all of them
and smoothing over rare variations that would complicate our analyses.
If one Smalltalk user modified their system to no longer be
self-sustainable, this does not change the fact that the ``typical''
Smalltalk is self-sustainable. On the other hand, suppose we discovered
a widely-used Smalltalk distribution that was deliberately diminished in
this property; perhaps this should force us to drop the term
``Smalltalk'' and split our analysis into two systems instead. Making
these points explicit and rigorous would involve similar work to the
aforementioned issues with dimensions and their scoring.

We see this issue as no \emph{worse} than the parallel in programming
languages, where people routinely talk about ``C++'' or ``Python'' even
though these have different implementations, versions and individual
installations. However, it is slightly easier to point to the
``essence'' of a programming language due to its definition in terms of
formal syntax and semantics, or at least an official specification by a
standards body. In contrast, programming systems have more of a \emph{de
facto} existence as running software \parencite{PLrev} which invites
appeals to popularity, community size, or influence as a substitute for
formal or official definitions.

\hypertarget{improving-bootstraplab}{\section{Improving BootstrapLab}\label{improving-bootstraplab}}

In Chapter~\ref{bl} we closely and carefully followed the construction
of our prototype programming system, BootstrapLab. We then evaluated it
against our Three Properties (as sets of dimensions) in
Section~\ref{evaluating-bootstraplab}. While it shows promise in
demonstrating the technical feasibility of custom notations and
innovation feedback, its capabilities are not as impressive as we would
like, owing to its early stage of development. However, this was for a
worthy cause. If we had sped ahead with its development, we would have
fallen into the trap we noted in
Section~\ref{self-sustainability-and-its-theory}, adding another
impressive programming system to the list without any transferrable
knowledge. Instead, by taking our slower approach---reflecting on how we
made design and implementation decisions and making them explicit---we
have contributed a \emph{method} that is easier to understand than
BootstrapLab's source code or commit history. From a position of being
satisfied with this tradeoff, we can set out the next steps for
BootstrapLab.

\hypertarget{pay-off-substrate-debt}{\subsection{Pay Off Substrate Debt}\label{pay-off-substrate-debt}}

BootstrapLab currently sits between the final two steps of the journey,
described in
Sections~\ref{pay-off-outstanding-substrate-debt}--\ref{provide-for-domain-specific-notations}.
We provided isolated examples of Notational Freedom
(Section~\ref{real-example-colour-preview}) and of Self-Sustainability
(evidenced by the Innovation Feedback in Figure~\ref{fig:grey-box}).
This does succeed at establishing BootstrapLab as a proof-of-concept,
but to go further we would need to finish paying the ``substrate debts''
we incurred. These consist of porting the Masp interpreter to Assembler
and the Tree Editor to Masp. Additionally, the system will inevitably
need access to more and more of the functionality available in the
platform such as audio, networking, and threading. These could be
exposed through the substrate, as we did for graphics via the
\texttt{scene} tree.

\hypertarget{make-assembler-more-usable}{\subsection{Make Assembler More
Usable}\label{make-assembler-more-usable}}

With the benefit of hindsight, we would recommend going for an
instruction set that is convenient enough to \emph{use} such that
immediately building programs in-system is a worthwhile endeavour. As we
admitted at the end of Section~\ref{designing-the-instruction-set}, our
own wild adventure in minimality was a mistake in this regard, causing
us to stay in \ac{JS}, implement the high-level language there and port
it later. It would be interesting to see the process of gradually
building each component of a high-level language engine interactively
in-system. Out of the four possibilities in
Section~\ref{choosing-an-appropriate-implementation}, we chose the
\emph{platform interpreter}, so exploring the others would be
illuminating---particularly the \emph{platform compiler}, which could
self-host relatively quickly.

\hypertarget{alternative-implementation-strategies}{\subsection{Alternative Implementation
Strategies}\label{alternative-implementation-strategies}}

It would be interesting to forego any temporary infrastructure
(Section~\ref{implement-temporary-infrastructure}) at all, or build up
entirely in-system without using platform tools. This would require more
careful substrate design to get this process going effectively. While it
could give some insight or appreciation for the hardships of early
computing, its practical value in the modern environment is unclear and
may be best considered a challenge for hacker wizardry.

\hypertarget{make-the-system-less-fragile}{\subsection{Make the System Less
Fragile}\label{make-the-system-less-fragile}}

Because self-sustainability by definition exposes core infrastructure to
potential user modification, the risks from mistakes or bugs are
magnified. Smalltalk is famously capable of executing the code
\texttt{true\ become:\ false} which results in it breaking. We
encountered an instance of this class of issue in BootstrapLab. In the
process of replacing a keyboard handler in-system, we typed a small
change which immediately took effect. This edit was supposed to be only
a part of a larger change, which in hindsight should have been committed
to the system atomically. Because it was applied immediately, the new
keyboard handler effectively became an incomplete function and typing
was no longer possible.

This highlights the need, in any practical realisation of
self-sustainabil-ity, for ``guardrails'' securing accidental changes to
core infrastructure or ``versioning'' that allows changes to be directed
at ``the next version of the system'' and applied atomically. This
complements the \ac{COLA} authors'
recommendation~\parencite[p. 23]{COLAs} for stable ``points of
reference'' in a system in which everything is flexible and homogenous,
which would likely be disorienting for a newcomer accustomed to
traditional programming.

\hypertarget{import-from-related-work}{\subsection{Import From Related Work}\label{import-from-related-work}}

To reduce the custom syntax, language and notation effort from its
present score of ``moderate'', we would seek to learn from the
approaches of OMeta~\parencite{OMeta} Eco~\parencite{Eco} and
MPS~\parencite{MPS}, particularly as regards implementation (since we
already agree that their end-results are desirable). Similarly for
self-sustainability, we would like to build \ac{COLA}'s object
model~\parencite{OROM} in the graphical substrate of
BootstrapLab\footnote{We already built the object model in a different
  system \parencite{CCS20}, but its shortcomings motivated the approach
  we took in BootstrapLab instead.} and see if we can implement the
\ac{COLA} design that way.

\tomas{Possibly draw a diagram of what are all the things that have to match? Like code-data in substrate, substrate-highLevelLanguage etc.}

\hypertarget{bootstrap-on-other-platforms-and-substrates}{\subsection{Bootstrap on Other Platforms and
Substrates}\label{bootstrap-on-other-platforms-and-substrates}}

At every step of the development journey, there were choice points where
we naturally could only move forward with one of the options. Future
work could explore the other branches. We cannot provide an exhaustive
listing here, but will give some examples.

At the first step (Choose A Platform), all sorts of other platforms
could be chosen. While \ac{COLA} built on top of one ``slice'' of
Unix---files, build tools and process memory---we see another
possibility in focusing on the hierarchical \emph{file system} as a
state model to inherit through to a substrate. This is one obvious
\emph{structured} substrate lurking within Unix and some of our work
here is no doubt applicable to it: directories act as maps, filenames as
keys and file contents as values. Symlinks could add graph structure to
this tree where needed. Similar ideas can found in the Hull design
\parencite{Hull}.

We acknowledge that it might feel perverse to have files contain
``primitive'' values, such as a single number, or to represent
instructions as directory trees, since files are normally used as
``large'' objects. However, it must be noted that there is precedent for
using them more generally for data large and small, such as in Plan
9~\parencite{Plan9} and \texttt{procfs}~\parencite{PAF}. If this was
still too much to stomach, the default option for ``code'' (shell
scripts) could simply be inherited on the understanding that this would
impose a dependency on implicitly-structured text at the core of the
system. What is most unclear is how graphics would be displayed and
interacted with---possibly requiring a special binary as part of the
substrate, for opening and synchronising a main window.

Supposing we keep our chosen web-based platform, we could still consider
alternative substrates. One possibility is inheriting the \ac{DOM} as
the state model. This is the choice made by
Webstrates~\parencite{Webstrates}, which stores textual \ac{JS} code for
programmatic change. Following our approach, we might want a lower-level
and structured instruction set instead. This would, at the very least,
need to be capable of changing parent/child/sibling relationships, node
attributes, and inner textual content. One warning is that the rest of
the \ac{DOM} API that would need to be exposed, in order to be able to
produce a functional modern web page or web app, is somewhat daunting in
scope. It would also be necessary to have some way of listening for
changes to \ac{DOM} nodes so that any constraints can be maintained or
dependencies can be updated. Webstrates does provide synchronisation
between networked clients on the same page, so perhaps its methods could
be adapted.

\joel{
We believe that, by identifying which parts of our journey ought to be transferrable to other contexts, it should be possible to develop a *general technique* for interactively bootstrapping self-sustainable systems from any starting platform.
}

\hypertarget{review}{\section{Review}\label{review}}

We began in Chapter~\ref{intro} with a vision of open software that can
be adapted by its users without expending disproportionate work on
accidental complexity. We introduced the key concept of a
\emph{programming system} along with Three Properties that would
contribute to this vision: Self-Sustainability, Notational Freedom, and
Explicit Structure. Our thesis was that it is possible to build a
programming system with these properties on top of our chosen starting
platform, the Web browser.

We then went on to establish the terms and concepts in which we would
frame our work fulfilling this claim. In Chapter~\ref{background} we
defined programming systems as a generalisation of languages, giving
examples of the diverse types of systems we are interested in. We then
showed how the Three Properties have precedent in existing patterns and
concepts. These ``precursor'' properties are well-adapted to a certain
set of assumptions about how programming works, but do not tell us much
about how to achieve the Properties in interactive, graphical systems
with Explicit Structure. We categorised different sets of assumptions
about how programming works as ``paradigms'' in Chapter~\ref{analysis}
and explained why the Batch-Mode assumptions, as inherited through Unix,
make our goals more difficult. We also introduced ideas that would help
us understand our task, such as the differences between low-level and
minimally human-friendly state models
\joel{(Section\ \ref{two-fundamentals-state-and-change}),} and the basic
structure of a self-sustainable system as \emph{platform},
\emph{substrate} and
\emph{product}\joel{(Section\ \ref{user-vs.-implementation-levels})}.

With these important concepts understood, we presented our proof of the
thesis statement in Chapter~\ref{bl}: an account of the design forces
and decisions involved in creating \emph{BootstrapLab}, whose
development steps are sufficiently general to act as a template for
alternative paths through the design space. We then proposed
\emph{technical dimensions} in Chapter~\ref{tech-dims} as a means to
verify the extent of our Three Properties, plus more generally other
properties of programming systems, and evaluated BootstrapLab using this
framework.

\hypertarget{conclusions}{\section{Conclusions}\label{conclusions}}

Our efforts taught us that the process of developing a self-sustainable
system roughly mirrors the historical development of programming that
shaped much of how we do things today. Technology like the assembler and
the compiler was born from a truly impoverished platform of flat memory,
numerical instructions, printed output and rows of switches.
Self-sustainable systems like Unix were gradually raised out of this
primordial world, yet it still has a tendency to show through and force
human minds to wrestle with it.

This work can be interpreted as a sketch of how we might build similar
infrastructure on the back of modern computing environments with
explicitly structured representation of data and graphical interfaces.
In other words, we have opened an investigation into what programming
could look like if it were \emph{re}-bootstrapped today, not on top of
flat memory, but on a richer base platform such as the web browser.

In his 1997 OOPSLA keynote ``The Computer Revolution Hasn't Happened
Yet''~\parencite{CompRev}, Alan Kay hoped that future users of Squeak
would use it to start a virtuous cycle of innovation: ``Think of how you
can obsolete the damn thing by using its own mechanisms for getting the
next version of itself.'' Twenty-six years later, the
self-sustainability pioneered by Smalltalk remains as elusive as ever
outside of its communities. Our hope is that through our contribution
here, we have increased the range of its potential beneficiaries. We
wish to empower programmers to add self-sustainability to their own
preferred systems by following the steps we discovered, advancing that
much further in the struggle against accidental complexity.
\clearpage{}
\appendix
\cleardoublepage
\clearpage{}\hypertarget{bl-trivia}{\chapter{BootstrapLab Trivia}\label{bl-trivia}}

\hypertarget{the-cutting-room-floor}{\section{The Cutting Room Floor}\label{the-cutting-room-floor}}

Force \ref{escape-plaf} directed us to do without several advanced
substrate features we were tempted to include. For example, it would be
useful to attach state change listeners to keep parts of the state in
sync with others. We could go even further and include constraint-based
programming features.

On another note, our substrate is based on ``maps'' without a predefined
ordering of the entries. However, there is always some order in which
they will be displayed:

\begin{verbatim}
{ red: 100, green: 255, blue: 0 }
\end{verbatim}

Thus it might be nice to be able to set this on a per-map basis. A
convenient way to expose this in-system would be via another map, or
``order map'' which would be a list map of key names:

\begin{verbatim}
{ 1: 'red', 2: 'green', 3: 'blue' }
\end{verbatim}

A practical use of this is for enabling iteration through a map's keys
or entries. If we wish to be rigorous, the order map itself would have
an order map, which would (by default) be the same for all order maps:

\begin{verbatim}
{ 1: 1, 2: 2, 3: 3 }
\end{verbatim}

Of course, with such a conceptually infinite sequence of order maps,
care must be taken to implement it in a finite, on-demand way. Perhaps
some clever circular reference would work, as COLA does for its
\emph{vtable} relation~\parencite{OROM}. This raises the question of how
to obtain an order map in-system. If we make it an ordinary key on all
maps, we must be careful to render it only on-demand and to exclude it
from ordinary iteration through keys. Plus, would we want the visual
clutter of always displaying it? It might be better to make it
accessible through a special instruction \texttt{order-map}.

We then face a further \emph{synchronisation} problem, where we must
alter the display order whenever the order map is changed, and insert or
remove entries from the order map to match its source.

Other thoughts along these lines included \emph{parent} maps for
delegating lookups (similar to \ac{JS}'s prototype system),
\emph{inverse} maps, and \emph{meta} maps for possibly collecting all of
these (drawing inspiration from Lua's metatables). Of these, we will
only discuss inverse maps in more detail.

Inverse maps come from the view of a map as a mathematical function from
key names to values. Often in advanced data structures (such as those
for graphical diagrams) it is essential to know ``who points to me'' via
some key. For example, the question ``Is this node the \texttt{source}
of anyone else?'' is a natural one, but normally it is impossible to
answer based on ordinary dictionary keys. In ordinary programming
languages, this information needs to be kept track of separately; say,
in a manually synchronised list called \texttt{sources} that lives on
the node. It is frustrating that the ``forward'' question is trivially
answered by just following a map entry, yet the ``backward'' question
has to be hacked around like this.\footnote{Norvig's ``Relation''
  pattern~\parencite{DynPat} for dynamic languages is relevant to this
  sort of concern.}

An inverse map would somehow collect all references to a map from other
ones. A user-level ``map'' would be implemented by two dictionary
structures, the forward and backward halves, which are automatically
kept in sync by the substrate implementation. The previously mentioned
issues of access, mutation and others also rear their ugly heads here,
so we can be forgiven for discarding the idea for the sake of making
progress. Still, a properly worked out implementation would provide a
valuable service for a high-level substrate.

\hypertarget{graphs-vs.-trees}{\section{Graphs vs.~Trees}\label{graphs-vs.-trees}}

A classic debate in the world of explicit structure is whether to use
restricted \emph{tree} structures or to allow arbitrary \emph{graphs}. A
tree has the advantage that every node has a single parent, which is a
useful canonical answer to the question ``what context am I in?''. On
the other hand, many practical problems do not fit inside a tree
structure; either because they are DAGs, and a node can have multiple
parents, or because they involve cyclic relations. Because we did not
know what sort of things we would require in BootstrapLab, we erred on
the side of freedom and supported full graph relations. This bit back at
us in two ways, both involving the graphics domain.

Firstly, cyclic structures need to be rendered with care; a
\naive~depth-first search will never terminate. For a long time, we did
not have any cyclic structures and got away with a depth-first approach
to \ac{DOM} generation in the temporary state view
(Section~\ref{temporary-infrastructure-in-bootstraplab}).

Secondly, while this was the case, the graphics sub-region of state
needed to be a tree. Spatial containment and other visual nesting
(e.g.~for the tree editor) is a tree structure, as is the underlying
parent-child relationship of THREE.js objects. Many aspects of rendering
the tree editor required the ability to ask ``what context am I in?''
but this is unanswered by default in a graph substrate. Providing a
``parent'' key for each node would not do---this would be a cyclic
reference. Instead, we kludged it: the first map to reference another
map becomes its ``parent'', and this lasts until the reference is
deleted. This parent property is available from \ac{JS}; as we port the
tree editor to Masp, we will have to decide how to expose it in-system
(probably through a special instruction).

Of course, we eventually did require cyclic structures---for the tree
editor! Each graphics node in the editor has a \texttt{source} key
providing a way for edits to propagate back to the source state node.
All edit nodes live in the graphics tree, including the one
corresponding to the root node of the state. In this case, the
\texttt{source} points all the way upwards to this root node. This cycle
broke our state view and there was much gnashing of teeth to hack around
this. Eventually, we bit the bullet and improved the state view \ac{JS}
to cope with cycles---having previously hoped we were done with this
temporary infrastructure.

Let this be a warning that Alignment (Force~\ref{alignment}) will come
for you in the end. If your substrate allows cycles, your state view
must tolerate them!

\hypertarget{the-minimal-random-access-instruction-set-and-its-perils}{\section{The Minimal Random-Access Instruction Set (And Its
Perils)}\label{the-minimal-random-access-instruction-set-and-its-perils}}

Recall Heuristic~\ref{simple-asm} which instructed us to pursue an
easy-to-implement instruction set. We pursued this goal to the extreme
out of curiosity for what was possible. Of course, it turned out that
the corresponding explosion in the number of instructions necessary to
do a simple thing outweighed any implementation advantage\ldots{}

We did this by breaking down higher-level instructions to their
component operations until we felt we could go no further. This led to a
sort of ``microcode'' level where each instruction's implementation
corresponded to some single-line \ac{JS} operation. In other words, the
platform itself blocked any further decomposition.

Our method for achieving this can be illustrated if we start with a
hypothetical complex instruction, e.g.~\texttt{copy\ a.b.c\ to\ x.y.z}.
The actual \emph{work} involved in executing this in \ac{JS} would
involve three steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Traverse the path \texttt{a}, \texttt{b}, \texttt{c} and save the
  value in a local variable
\item
  Traverse the path \texttt{x}, \texttt{y} and save the (map) value too
\item
  Set the key \texttt{z} in the map to the saved value.
\end{enumerate}

If we score \emph{strictly by \ac{JS} implementation size} (a mistake,
in hindsight), we could improve by simply splitting up these steps into
instructions of their own. Any other ``complex'' instructions that used
some of the same steps (e.g.~path traversal) will also be covered by
these, and the total \ac{JS} will be reduced.

For the first path traversal, we start at the root map (or more
generally, any given starting map) and follow each of the keys in turn.
We have only one step here (follow key) repeated three times. That's
another micro-instruction!

At this stage, we have this truly simple instruction:
\texttt{follow-key\ k}. It clearly relies on some implicit state
register for the current map, and takes a single parameter. We pushed
the limits of sanity by going further, factoring the parameter
\emph{out} into another state register, so the resulting instruction is
just \texttt{follow-key} (we called it \texttt{index}). In other words,
we applied the following heuristic:

\begin{heuristic}[Registers for parameters]
Factor out instruction ``parameters'' into special state registers where possible.
\label{reg-for-param}
\end{heuristic}

The motivation for this is a vague intuition about sharing parameter
values. Under a parameter scheme, copying the same thing to multiple
destinations will duplicate the ``source'' parameter many times, even
though the only thing that's changing is the destination. The converse
is true for operations with the same destination---maybe not overwriting
copies, but arithmetic or other accumulating operations. By breaking
these parameters into state, we set a source or destination once only.
This has a subjective aesthetic appeal from the point of view of
minimality, and an even more dubious efficiency value. We emphasise that
it was an experiment and advise against it for the purposes of
implementing a system quickly.

As mentioned at the end of Section~\ref{designing-the-instruction-set},
we end up with only four registers (\texttt{next\_instruction},
\texttt{focus}, \texttt{map}, \texttt{source}) and five\footnote{Or six,
  if we analyse the overloaded \texttt{store} instruction as
  \texttt{store-reg} and \texttt{store-map}.} core instructions
(\texttt{load}, \texttt{store}, \texttt{deref}, \texttt{index},
\texttt{js}). These have a structural representation in-system, but also
a convenient textual syntax for brevity in textual media (like this
dissertation).

Combinations of these express the expected copying and jumping
operations. For example, \texttt{load\ source-reg}, \texttt{deref},
\texttt{store\ dest-reg} copies the value in top-level
\texttt{source-reg} to \texttt{dest-reg}. The first instruction loads
the literal string \texttt{source-reg} into the \texttt{focus}; the
second replaces \texttt{focus} with the contents of its named register;
the third copies the \texttt{focus} to the named destination.\footnote{It
  turns out that, if you extract the destination parameter from
  \texttt{store}, you meet an infinite regress and will be unable to
  store to any top-level register. For example, if we extract the
  parameter to \texttt{dest\_reg}, we have to somehow give it the value
  it previously took in the instruction---but this is precisely a
  \texttt{store} operation and we're already in the middle of one.}

The \texttt{copy\ a.b.c\ to\ x.y.z} from earlier would decompose as
follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{load\ a}, \texttt{deref}, \texttt{store\ map},
  \texttt{load\ b}, \texttt{index}, \texttt{load\ c}, \texttt{index},
  \texttt{load\ map}, \texttt{deref}, \texttt{store\ source}
\item
  \texttt{load\ x}, \texttt{deref}, \texttt{store\ map},
  \texttt{load\ y}, \texttt{index}
\item
  \texttt{load\ z}, \texttt{store}
\end{enumerate}

(Recall that \texttt{index} replaces \texttt{map} with the result of
following its key named by \texttt{focus}, and \texttt{store} without
any arguments copies from \texttt{source} to the \texttt{focus} key
entry within \texttt{map}.)

A jump is accomplished by overwriting the address in
\texttt{next\_instruction} (i.e.~a map containing a \texttt{map} field
and a \texttt{key} field). The map or the key can be overwritten in a
single instruction, but if an entirely new address is required, this
needs to be built up separately and overwritten atomically. In other
words, we cannot overwrite the \texttt{map} and then overwrite the
\texttt{key}. The ugly reality is, after overwriting the \texttt{map},
it will have jumped to a different instruction somewhere else!

A conditional jump is sneaked in by indexing a map to obtain the new
list of instructions (which is the map that will overwrite the
\texttt{map} under \texttt{next\_instruction}). For example, in the
following register snapshot:

\begin{verbatim}
...
weather: 'stormy'
map: {
    sunny: { ... sunny code sequence ... }
    rainy: { ... rainy code sequence ... }
    _:     { ... other code sequence ... }
}
\end{verbatim}

One of the three code paths will be selected according to whatever
happens to be in the \texttt{weather} register via the following
instructions: \texttt{load\ weather}, \texttt{deref},
\texttt{store\ focus}, \texttt{index}. The \texttt{map} register will
hold the result, in this case the ``other'' code sequence (recall that
the special key \texttt{\_} is used as an ``else'' clause for lookups).
What remains is then to copy this within \texttt{next\_instruction}.

It is easy to see how this applies for strict equality matching, but
what about comparisons? We simply turn the condition into one of a fixed
set of constants. For \(3 < 7\) we would subtract to get \(-4\) and then
apply the mathematical \texttt{sign} function to obtain \(-1\) (the
other possibilities being 0 or 1). We would then index a map containing
keys \texttt{-1}, \texttt{0} and \texttt{1}.

Finally, operations like subtraction and \texttt{sign} were included as
special instructions or achieved via the \texttt{js} escape hatch into
\ac{JS}. We continued to experiment with other arithmetic instructions,
including vector arithmetic (useful for graphics), but never got round
to implementing an operand stack.

\joel{ NOPE
# Appendix: Tree Editor
One interesting issue is the "display update" problem. For the \ac{JS} tree view, we simply intercept all state updates and use `querySelector` to lookup the \ac{DOM} node with the map's internal ID. Internal IDs are not currently accessible in-system, though we could provide instructions for this purpose. How, then, can we ensure that the relevant "display state" for a map entry is updated when it changes?

Even if we had an answer for this, there is a bigger problem. The \ac{DOM} state is not part of the "state" of our substrate. When our state changes, this triggers a \ac{DOM} state change. But the system's graphics are based on a special region of ordinary system state. Therefore, a state change will trigger another state change (to the graphics state.) What if the "graphics state" is being visualised in the tree editor? It will need to change too! And so on.

State change should cause state change (finite extent) in scene tree, if that state is visualised there.

In other words, there exists some address `->` graphics node mapping (e.g. in map metadata) inside the substrate.

Analogous to Virtual Memory Management GDT, LDT descriptor tables.

Yet, this makes too much complexity e.g. the graphics tree format part of the substrate!!

Alternatively: consider the humble hex editor. It doesn't change memory, trigger a hardware interrupt, and then sync the display data to match. Causality goes not:

```
Edit --> Mem --> OnMemChange --> Display
```

But:

```
Edit ---> Mem
     \--> Display
```

Aha! But how do machine-level debugger GUIs work? When instructions, the OS, or whatever ... change memory, how does it notice and display the changes??

It must either re-poll everything after a run/step, or get a changelog from OS...?

Changelog could be a special part of state expected to change constantly, so we just poll it on demand. We assume it's stale by default when looking at its visual representation.
}
\clearpage{}
\cleardoublepage
\clearpage{}\hypertarget{appendix-all-dims}{\chapter{Technical Dimensions Catalogue}\label{appendix-all-dims}}

Here, we present our proposed technical dimensions in detail. While they
do contain some novel ideas of our own, they also integrate a wide range
of existing concepts under a common umbrella. Note that because the
material here was published prior to this
dissertation~\parencite{TechDims}, our Three Properties and their
dimensions in Section~\ref{the-three-properties-as-dimensions} represent
an evolution of some of the concepts here. Specifically:

\begin{itemize}
\tightlist
\item
  \emph{Surface / internal notations}
  (Sections~\ref{dimensions-surface-notation-and-internal-notation}--\ref{examples-two-strings-in-memory-explicitly-structured-internal-notation})
  is an earlier iteration of what we defined as Explicit Structure
  (Section~\ref{explicit-structure}).
\item
  Some aspects of the \emph{Notation} dimensions
  (Section~\ref{notation}), particularly \emph{uniformity of notations}
  (Section~\ref{dimension-uniformity-of-notations}), influenced our
  Notational Freedom (Section~\ref{notational-freedom}).
\item
  The description of \emph{self-sustainability} here
  (Section~\ref{dimension-self-sustainability}) is an earlier version of
  what we fully developed in Section~\ref{self-sustainability}.
\end{itemize}

The intention of this catalogue is to provide a \emph{reference} to be
looked up and \emph{used} as needed, not something that should be read
from start to finish. We recommend skimming through the catalogue for
anything particularly interesting before proceeding to
Section~\ref{evaluating-the-dark-programming-system}. There, we will
reference several dimensions in the context of a specific example, at
which point it may be helpful to come back for more detail. For a quick
overview, we include a concise reference sheet on the next page, though
it may make more sense after reading the relevant sections.

We present the dimensions grouped under \emph{clusters}. These may be
regarded as ``topics of interest'' or ``areas of inquiry'' when studying
a given system, grouping together related dimensions against which to
measure it.

Each cluster is named and opens with a boxed \emph{summary}, followed by
a longer \emph{discussion}, and closes with a list of any
\emph{relations} to other clusters along with any \emph{references} if
applicable. Within the main discussion, individual \emph{dimensions} are
listed. Sometimes, a particular value along a dimension (or a
combination of values along several dimensions) can be recognised as a
familiar pattern---perhaps with a name already established in the
literature. These are marked as \emph{examples}. Finally, interspersed
discussion that is neither a \emph{dimension} nor an \emph{example} is
introduced as a \emph{remark}.

\includepdf[pages={2}]{../table.pdf}

\hypertarget{interaction}{\section{Interaction}\label{interaction}}

\mybox{How do users manifest their ideas, evaluate the result, and generate new ideas in response?}

An essential aspect of programming systems is how the user interacts
with them when creating programs. Take the standard form of statically
typed, compiled languages with straightforward library linking: here,
programmers write their code in a text editor, invoke the compiler, and
read through error messages they get. After fixing the code to pass
compilation, a similar process might happen with runtime errors.

Other forms are yet possible. On the one hand, some typical interactions
like compilation or execution of a program may not be perceptible at
all. On the other hand, the system may provide various interfaces to
support the plethora of other interactions that are often important in
programming, such as looking up documentation, managing dependencies,
refactoring or pair programming.

We focus on the interactions where programmer interacts with the system
to construct a program with a desired behaviour. To analyse those, we
use the concepts of \emph{gulf of execution} and \emph{gulf of
evaluation} from \emph{The Design of Everyday
Things}~\parencite{Norman}.

\hypertarget{dimension-feedback-loops}{\subsection{Dimension: feedback loops}\label{dimension-feedback-loops}}

In using a system, one first has some idea and attempts to make it exist
in the software; the gap between the user's goal and the means to
execute the goal is known as the \emph{gulf of execution}. Then, one
compares the result actually achieved to the original goal in mind; this
crosses the \emph{gulf of evaluation}. These two activities comprise the
\emph{feedback loop} through which a user gradually realises their
desires in the imagination, or refines those desires to find out ``what
they actually want''.

A system must contain at least one such feedback loop, but may contain
several at different levels or specialised to certain domains. For each
of them, we can separate the gulf of execution and evaluation as
independent legs of the journey, with possibly different manners and
speeds of crossing them.

\begin{figure}
  \centering
  \includegraphics[width=0.5\linewidth]{feedback-loops.png}
  \caption[Feedback Loops in a statically-checked language]{The nested feedback loops of a statically-checked programming language.\label{fig:feedback-loops}}
\end{figure}

For example, we can analyse statically checked \emph{programming
languages} (e.g.~Java, Haskell) into several feedback loops (Figure
\ref{fig:feedback-loops}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Programmers often think about design details and calculations on a
  whiteboard or notebook, even before writing code. This
  \emph{supplementary medium} has its own feedback loop, even though
  this is often not automatic.
\item
  The code is written and is then put through the static checker. An
  error sends the user back to writing code. In the case of success,
  they are ``allowed'' to run the program, leading into cycle 3.

  \begin{itemize}
  \tightlist
  \item
    The execution gulf comprises multiple cycles of the supplementary
    medium, plus whatever overhead is needed to invoke the compiler
    (such as build systems).
  \item
    The evaluation gulf is essentially the waiting period before static
    errors or a successful termination are observed. Hence this is
    bounded by some function of the length of the code (the same cannot
    be said for the following cycle 3.)
  \end{itemize}
\item
  With a runnable program, the user now evaluates the \emph{runtime}
  behaviour. Runtime errors can send the user back to writing code to be
  checked, or to tweak dynamically loaded data files in a similar cycle.

  \begin{itemize}
  \tightlist
  \item
    The execution gulf here may include multiple iterations of cycle 2,
    each with its own nested cycle 1.
  \item
    The \emph{evaluation} gulf here is theoretically unbounded; one may
    have to wait a very long time, or create very specific conditions,
    to rule out certain bugs (like race conditions) or simply to
    consider the program as fit for purpose.
  \item
    By imposing \emph{static checks}, some bugs can be pushed earlier to
    the evaluation stage of cycle 2, reducing the likely size of the
    cycle 3 \emph{evaluation} gulf.
  \item
    On the other hand, this can make it harder to write statically valid
    code, which may increase the number of level-2 cycles, thus
    increasing the total \emph{execution} gulf at level 3.
  \item
    Depending on how these balance out, the total top-level feedback
    loop may grow longer or shorter.
  \end{itemize}
\end{enumerate}

\hypertarget{example-immediate-feedback}{\subsection{Example: immediate
feedback}\label{example-immediate-feedback}}

The specific case where the \emph{evaluation} gulf is minimised to be
imperceptible is known as \emph{immediate feedback}. Once the user has
caused some change to the system, its effects (including errors) are
immediately visible. This is a key ingredient of \emph{liveness}, though
it is not sufficient on its own. (See \emph{Relations})

The ease of achieving immediate feedback is obviously constrained by the
computational load of the user's effects on the system, and the system's
performance on such tasks. However, such ``loading time'' is not the
only way feedback can be delayed: a common situation is where the user
has to manually ask for (or ``poll'') the relevant state of the system
after their actions, even if the system finished the task quickly. Here,
the feedback could be described as \emph{immediate upon demand} yet not
\emph{automatically demanded}. For convenience, we choose to include the
latter criterion---automatic demand of result---in our definition of
immediate feedback.

In a \emph{REPL} or \emph{shell}, there is a \emph{main} cycle of typing
commands and seeing their output, and a \emph{secondary} cycle of typing
and checking the command line itself. The output of commands can be
immediate, but usually reflects only part of the total effects or even
none at all. The user must manually issue further commands afterwards,
to check the relevant state bit by bit. The secondary cycle, like all
typing, provides immediate feedback in the form of character ``echo'',
but things like syntax errors generally only get reported \emph{after}
the entire line is submitted. This evaluation gulf has been reduced in
the JavaScript console of web browsers, where the line is ``run'' in a
limited manner on every keystroke. Simple commands without
side-effects,\footnote{Of course, these are detected via some
  conservative over-approximation which excludes expressions that
  \emph{might} side-effect.} such as calls to pure functions, can give
instantly previewed results---though partially typed expressions and
syntax errors will not trigger previews.

\hypertarget{example-direct-manipulation}{\subsection{Example: direct
manipulation}\label{example-direct-manipulation}}

Direct manipulation \parencite{DirectManip} is a special case of an
immediate feedback loop. The user sees and interacts with an artefact in
a way that is as similar as possible to real life; this typically
includes dragging with a cursor or finger in order to physically move a
visual item, and is limited by the particular haptic technology in use.

Naturally, because moving real things with one's hands does not involve
any waiting for the object to ``catch up'',\footnote{In some situations,
  such as steering a boat with a rudder, there is a delay between input
  and effect. But on closer inspection, this delay is between the rudder
  and the boat; we do not see the hand pass through the wheel like a
  hologram, followed by the wheel turning a second later. In real life,
  objects touched directly give immediate feedback; objects controlled
  further down the line might not!} direct manipulation is necessarily
an immediate-feedback cycle. If, on the other hand, one were to move a
figure on screen by typing new co-ordinates in a text box, then this
could still give \emph{immediate feedback} (if the update appears
instant and automatic) but would \emph{not} be an example of direct
manipulation.

\emph{Spreadsheets} contain a feedback loop for direct manipulation of
values and formatting, as in any other WYSIWYG application. Here, there
is feedback for every character typed and every change of style. This is
not the case in the other loop for formula editing and formula
invocation. There, we see a larger execution gulf for designing and
typing formulas, where feedback is only given upon committing the
formula by pressing enter. This makes it an ``immediate feedback'' loop
only \emph{on-demand}, as defined above.

\hypertarget{dimension-modes-of-interaction}{\subsection{Dimension: modes of
interaction}\label{dimension-modes-of-interaction}}

The possible interactions in a programming system are typically
structured so that interactions, and the associated feedback loops, are
only available in certain \emph{modes}. For example, when creating a new
project, the user may be able to configure the project through a
conversational interface like \texttt{npm\ init} in modern JavaScript.
Such interactions are no longer available once the project is created.
This idea of interaction modes goes beyond just programming systems,
appearing in software engineering methodologies. In particular, having a
separate \emph{implementation} and \emph{maintenance} phase would be an
example of two modes.

\emph{Editing vs debugging.} A good example is the distinction between
\emph{editing} and \emph{debugging} mode. When debugging a program, the
user can modify the program state and get (more) immediate feedback on
what individual operations do. In some systems, one can even modify the
program itself during debugging. Such feedback loops are not available
outside of debugging mode.

\emph{Lisp systems} sometimes distinguish between \emph{interpreted} and
\emph{compiled} mode. The two modes do not differ just in the efficiency
of code execution, but also in the interactions they enable. In the
interpreted mode, code can be tested interactively and errors may be
corrected during the code execution (see \emph{Error response}). In the
compiled mode, the program can only be tested as a whole. The same two
modes also exist, for example, in some Haskell systems where the REPL
uses an interpreter (GHCi) distinct from the compiler (GHC).

\emph{Jupyter notebooks.} A programming system may also unify modes that
are typically distinct. The Jupyter notebook environment does not have a
distinct debugging mode; the user runs blocks of code and receives the
result. The single mode can be used to quickly try things out, and to
generate the final result, partly playing the role of both debugging and
editing modes. However, even Jupyter notebooks distinguish between
editing a document and running code.

\hypertarget{dimension-abstraction-construction}{\subsection{Dimension: abstraction
construction}\label{dimension-abstraction-construction}}

A necessary activity in programming is going between abstract schemas
and concrete instances. Abstractions can be constructed from concrete
examples, first principles or through other methods. A part of the
process may happen in the programmer's mind: they think of concrete
cases and come up with an abstract concept, which they then directly
encode in the system. Alternatively, a system can support these
different methods directly.

One option is to construct abstractions \emph{from first principles}.
Here, the programmer starts by defining an abstract entity such as an
interface in object-oriented programming languages. To do this, they
have to think what the required abstraction will be (in the mind) and
then encode it (in the system).

Another option is to construct abstractions \emph{from concrete cases}.
Here, the programmer uses the system to solve one or more concrete
problems and, when they are satisfied, the system guides them in
creating an abstraction based on their concrete case(s). In a
programming language IDE this manifests as the ``extract function''
refactor, whereas in other systems we see approaches like macro
recording.

\emph{Pygmalion.} In Pygmalion \parencite{Pygmalion}, all programming is
done by manipulating concrete icons that represent concrete things. To
create an abstraction, you can use ``Remember mode'', which records the
operations done on icons and makes it possible to bind this recording to
a new icon.

\emph{Jupyter notebook.} In Jupyter notebooks, you are inclined to work
with concrete things, because you see previews after individual cells.
This discourages creating abstractions, because then you would not be
able to look inside at such a fine grained level.

\emph{Spreadsheets.} Up until the recent introduction of lambda
expressions into Excel, spreadsheets have been relentlessly concrete,
without any way to abstract and reuse patterns of computation other than
copy-and-paste.

\hypertarget{relations}{\subsection{Relations}\label{relations}}

\begin{itemize}
\tightlist
\item
  \emph{Errors} (Section \ref{errors}) A longer evaluation gulf delays
  the detection of errors. A longer execution gulf can increase the
  \emph{likelihood} of errors (e.g.~writing a lot of code or taking a
  long time to write it). By turning runtime bugs into statically
  detected bugs, the combined evaluation gulfs can be reduced.
\item
  \emph{Adoptability} (Section \ref{adoptability}): The \emph{execution}
  gulf is concerned with software using and programming in general. The
  time taken to realise an idea in software is affected by the user's
  familiarity and the system's \emph{learnability}.
\item
  \emph{Notation} (Section \ref{notation}): Feedback loops are related
  to \emph{notational structures}. In a system with multiple notations,
  each notation may have different associated feedback loops. The motto
  ``The thing on the screen is supposed to be the actual thing''
  \parencite{NakedObjects}, adopted in the context of live programming,
  relates \emph{liveness} to a direct connection between surface and
  internal notations. The idea is that interactable objects should be
  equipped with faithful behaviour, instead of being intangible shadows
  cast by the hidden \emph{real} object.
\end{itemize}

\hypertarget{notation}{\section{Notation}\label{notation}}

\mybox{How are the different textual / visual programming notations related?}

Programming is always done through some form of notation. We consider
notations in the most general sense and include any structured gesture
using textual or visual notation. Textual notations primarily include
programming languages, but also things like configuration files. Visual
notations include graphical programming languages. Other kinds of
structured gestures include user interfaces for constructing visual
elements used in the system.

\hypertarget{dimension-notational-structure}{\subsection{Dimension: notational
structure}\label{dimension-notational-structure}}

In practice, most programming systems use multiple notations. Different
notations can play different roles in the system. On the one hand,
multiple \emph{overlapping notations} can be provided as different ways
of programming the same aspects of the system. In this case, each
notation may be more suitable to different kinds of users, but may have
certain limitations (for example, a visual notation may have a limited
expressive power). On the other hand, multiple \emph{complementing
notations} may be used as the means for programming different aspects of
the system. In this case, programming the system requires using multiple
notations, but each notation may be more suitable for the task at hand;
think of how HTML describes document structure while JavaScript
specifies its behaviour.

\hypertarget{example-overlapping-notations}{\subsection{Example: overlapping
notations}\label{example-overlapping-notations}}

A programming system may provide multiple notations for programming the
same aspect of the system. This is typically motivated by an attempt to
offer easy ways of completing different tasks: say, a textual notation
for defining abstractions and a visual notation for specifying concrete
structures. The crucial issue in this kind of arrangement is
\emph{synchronising} the different notations; if they have different
characteristics, this may not be a straightforward mapping. For example,
source code may allow more elaborate abstraction mechanisms like loops,
which will appear as visible repetition in the visual notation. What
should such a system do when the user edits a single object that
resulted from such repetition? Similarly, textual notation may allow
incomplete expressions that do not have an equivalent in the visual
notation. For programming systems that use \emph{overlapping notations},
we need to describe how the notations are synchronised.

\emph{Sketch-n-Sketch} \parencite{SnS} employs overlapping notations for
creating and editing SVG and HTML documents. The user edits documents in
an interface with a split-screen structure that shows source code on the
left and displayed visual output on the right. They can edit both of
these and changes are propagated to the other view. The code can use
abstraction mechanisms (such as functions) which are not completely
visible in the visual editor (an issue we return to in \emph{expression
geography} below). Sketch-n-Sketch can be seen as an example of a
\emph{projectional editor}.\footnote{Technically, traditional
  projectional editors usually work more directly with the abstract
  syntax tree of a programming
  language.\note{TODO: Insert some more references to research on "projectional editors"}}

\emph{UML Round-tripping.} Another example of a programming system that
utilises the \emph{overlapping notations} structure are UML design tools
that display the program both as source code and as a UML diagram. Edits
in one result in automatic update of the other. An example is the
Together/J\footnote{https://www.mindprod.com/jgloss/togetherj.html}
system. To solve the issue of notation synchronisation, such systems
often need to store additional information in the textual notation,
typically using a special kind of code comment. In this example, after
the user re-arranges classes in UML diagrams, the new locations need to
be updated in the code.

\hypertarget{example-complementing-notations}{\subsection{Example: complementing
notations}\label{example-complementing-notations}}

A programming system may also provide multiple complementing notations
for programming different aspects of its world. Again, this is typically
motivated by the aim to make specifying certain aspects of programming
easier, but it is more suitable when the different aspects can be more
clearly separated. The key issue for systems with complementing
notations is how the different notations are connected. The user may
need to use both notations at the same time, or they may need to
progress from one to the next level when solving increasingly complex
problems. In the latter case, the learnability of progressing from one
level to the next is a major concern.

\emph{Spreadsheets and HyperCard.} In Excel, there are three different
complementing notations that allow users to specify aspects of
increasing complexity: (i) the visual grid, (ii) formula language and
(iii) a macro language such as Visual Basic for Applications. The
notations are largely independent and have different degrees of
expressive power. Entering values in a grid cannot be used for
specifying new computations, but it can be used to adapt or run a
computation, for example when entering different alternatives in What-If
Scenario Analysis. More complex tasks can be achieved using formulas and
macros. A user gradually learns more advanced notations, but experience
with a previous notation does not help with mastering the next one. The
approach optimises for easy learnability at one level, but introduces a
hurdle for users to surmount in order to get to the second level. The
notational structure of \emph{HyperCard} is similar and consists of (i)
visual design of cards, (ii) visual programming (via the GUI) with a
limited number of operations and (iii) HyperTalk for arbitrary
scripting.

\emph{Boxer and Jupyter.} Boxer \parencite{Boxer} uses
\emph{complementing notations} in that it combines a visual notation
(the layout of the document and the boxes of which it consists) with
textual notation (the code in the boxes). Here, the textual notation is
always nested within the visual. The case of Jupyter notebooks is
similar. The document structure is graphical; code and visual outputs
are nested as editable cells in the document. This arrangement is common
in many other systems such as Flash or Visual Basic, which both combine
visual notation with textual code, although one is not nested in the
other.

\hypertarget{dimensions-surface-notation-and-internal-notation}{\subsection{Dimensions: surface notation and internal
notation}\label{dimensions-surface-notation-and-internal-notation}}

All programming systems build up structures in memory, which we can
consider as an \emph{internal notation} not usually visible to the user.
Even though such structures might be revealed in a debugger, they are
hidden during normal operation. What the user interacts with instead is
the \emph{surface notation}, typically one of text or shapes on a
screen. Every interaction with the surface notation alters the internal
notation in some way, and the nature of this connection is worth
examining in more detail. To do this, we illustrate with a simplified
binary choice for the form of these notations.

\hypertarget{examples-implicit-vs.-explicit-structure}{\subsection{Examples: implicit vs.~explicit
structure}\label{examples-implicit-vs.-explicit-structure}}

Let us partition notations into two families. Notations with
\emph{implicit structure} present as a sequence of items, such as
textual characters or audio signal amplitudes. Those with \emph{explicit
structure} present as a tree or graph without an obvious order, such as
shapes in a vector graphics editor. These two types of notations can be
transformed into each other: the implicit structure contained in a
string can be \emph{parsed} into an explicit syntax tree, and an
explicit document structure might be \emph{rendered} into a sequence of
characters with the same implicit structure.

Now consider an interface to enter a personal name made up of a forename
and a surname. For the surface notation, there could be a single text
field to hold the names separated with a space; here, the sub-structure
is implicit in the string. Alternatively, there could be two fields
where the names are entered separately, and their separation is
explicit. A similar choice exists for the internal notation built up in
memory: is it a single string, or two separate strings?

We can see that these choices give four combinations. More
interestingly, they exhibit unique characters owing to two key
asymmetries. Firstly, surface notation is mostly used by humans, while
the internal notation is mostly used by the computer. Secondly, and most
significantly, computer programs can only work with explicit structure,
while humans can understand both explicit and implicit structure.
\joel{informal vs formal structure?} Because of the practical
consequences of this asymmetry, we will examine the combinations with
emphasis on the \emph{internal} notation first.

\hypertarget{examples-one-string-in-memory-implicitly-structured-internal-notation}{\subsection{Examples: one string in memory (implicitly structured
internal
notation)}\label{examples-one-string-in-memory-implicitly-structured-internal-notation}}

The simplest case here would be with implicit structure in the surface
notation, i.e.~a single text box for the full name. Edits to the surface
are straightforwardly mirrored internally and persisted to disk. This
corresponds to \emph{text editing}. We can generalise this to an idea of
\emph{sequence editing} if we view the fundamental act as
\emph{recording} events to a list over time. For text, these are key
presses; for an audio editing interface they would be samples of sound
amplitude.

In the other case, with two text boxes, we have \emph{sequence
rendering}. The information about the separation of the two strings,
present in the interface, is not quite ``thrown away'' but is made
\emph{implicit} as a space character in the string. This combination
corresponds to Visual Basic generating code from GUI forms, video
editors combining multiple clips and effects into a single stream, and
3D renderers turning scene graphs into pixels. Another example is
line-based diff tools, which provide side-by-side views and related
interfaces, yet must ultimately forward the user's changes to the
underlying text file.

Critically, in both of these cases, a computer program can only
manipulate the stored sequences \emph{as} sequences; that is, by
inserting, removing, or serially reading. The appealing feature here is
that these operations are simple to implement and may be re-usable
across many types of sequences. However, any further structure is
implicit and, to work with it programmatically, a user must write a
program to \emph{parse} it into something explicit. Furthermore, errors
introduced at this stage may simply be \emph{recorded} into the
sequence, only to be discovered much later in an attempt to use the
data.

\hypertarget{examples-two-strings-in-memory-explicitly-structured-internal-notation}{\subsection{Examples: two strings in memory (explicitly structured
internal
notation)}\label{examples-two-strings-in-memory-explicitly-structured-internal-notation}}

\joel{TODO: cite The Many Forms of a Single Fact}

With two text boxes, both notations match, so there is not much work to
do. As with sequence editing, edits on the surface can be mirrored to
the internal notation. This corresponds to vector graphics editors and
3D modelling tools, as well as \emph{structure editors} for programming
languages. For this reason we call this combination \emph{structure
editing}.

With a single text field, we have \emph{structure recovery.} Parsing
needs to happen each time the input changes. This style is found in the
DOM inspector in browser developer tools, where HTML can be edited as
text to make changes to the document tree structure. More generally,
this is the mode found in compilers and interpreters which accept
program source text yet internally work on tree and graph structures. It
is also possible to do a sort of structure editing this way, where the
experience is made to resemble text editing but the output is explicitly
structured.

In both of these cases, in order to write programs to transform,
analyse, or otherwise work with the digital artefact the user has
created, one can trivially navigate the stored structure instead of
parsing it for every use. Parsing is either done away with altogether or
is reduced to a transient process that happens during editing; this
means errors can be caught at the moment they are introduced instead of
remaining latent.

\hypertarget{dimension-primary-and-secondary-notations}{\subsection{Dimension: primary and secondary
notations}\label{dimension-primary-and-secondary-notations}}

In practice, most programming systems use multiple notations. Even in
systems based on traditional programming languages, the \emph{primary
notation} of the language is often supported by \emph{secondary
notations} such as annotations encoded in comments and build tool
configuration files. However, it is possible for multiple notations to
be primary, especially if they are \emph{overlapping} as defined
earlier.

\emph{Programming languages.} Programming systems built around
traditional programming languages typically have further notations or
structured gestures associated with them. The primary notation in UNIX
is the C programming language. Yet this is enclosed in a programming
\emph{system} providing a multi-step mechanism for running C code via
the terminal, assisted by secondary notations such as shell scripts.
Some programming systems attempt to integrate tools that normally rely
on secondary notations into the system itself, reducing the number of
secondary notations that the programmer needs to master. For example, in
the Smalltalk descendant Pharo, versioning and package management is
done from within Pharo, removing the need for secondary notation such as
\texttt{git} commands and dependency configuration files.\footnote{The
  tool for versioning and package management in Pharo can still be seen
  as an \emph{internal} domain-specific language and thus as a secondary
  notation, but its basic structure is \emph{shared} with other
  notations in the Pharo system.}

\emph{Haskell.} In Haskell, the primary notation is the programming
language, but there are also a number of secondary notations. Those
include package managers (e.g.~the \texttt{cabal.project} file) or
configuration files for Haskell build tools. More interestingly, there
is also an informal mathematical notation associated with Haskell that
is used when programmers discuss programs on a whiteboard or in academic
publications. The idea of having such a mathematical notation dates back
to the \emph{Report on Algol 58} \parencite{Alg58}, which explicitly
defined a ``publication language'' for ``stating and communicating
problems'' using Greek letters and subscripts.

\hypertarget{dimension-expression-geography}{\subsection{Dimension: expression
geography}\label{dimension-expression-geography}}

A crucial feature of a notation is the relationship between the
structure of the notation and the structure of the behaviour it encodes.
Most importantly, do \emph{similar expressions} in a particular notation
represent \emph{similar behaviour}?\footnote{See Basman's
  \parencite{NotYetCraft} similar discussion of ``density''.} Visual
notations may provide a more or less direct mapping. On the one hand,
similar-looking code in a block language may mean very different things.
On the other hand, similar looking design of two HyperCard cards will
result in similar looking cards---the mapping between the notation and
the logic is much more direct.

\emph{C/C++ expression language.} In textual notations, this may easily
not be the case. Consider the two C conditionals:

\begin{itemize}
\tightlist
\item
  \texttt{if\ (x==1)\ \{\ ...\ \}} evaluates the Boolean expression
  \texttt{x==1} to determine whether \texttt{x} equals \texttt{1},
  running the code block if the condition holds.
\item
  \texttt{if\ (x=1)\ \{\ ...\ \}} \emph{assigns} \texttt{1} to the
  variable \texttt{x}. In C, assignment is an expression
  \emph{returning} the assigned value, so the result \texttt{1} is
  interpreted as \texttt{true} and the block of code is \emph{always}
  executed.
\end{itemize}

A notation can be designed to map better to the logic behind it, for
example, by requiring the user to write \texttt{1==x}. This solves the
above problem as \texttt{1} is a literal rather than a variable, so it
cannot be assigned to (\texttt{1=x} is a compile error).

\hypertarget{dimension-uniformity-of-notations}{\subsection{Dimension: uniformity of
notations}\label{dimension-uniformity-of-notations}}

One common concern with notations is the extent to which they are
uniform. A uniform notation can express a wide range of things using
just a small number of concepts. The primary example here is
S-expressions from Lisp. An S-expression is either an atom or a pair of
S-expressions written \texttt{(s1\ .\ s2)}. By convention, an
S-expression \texttt{(s1\ .\ (s2\ .\ (s3\ .\ nil)))} represents a list,
written as \texttt{(s1\ s2\ s3)}. In Lisp, uniformity of notations is
closely linked to uniformity of representation.\footnote{Notations
  generally are closely linked to representation in that the notation
  may mirror the structures used for program representation. Basman et
  al.~\parencite{Externalize} refer to this as a distinction between
  ``dead'' notation and ``live'' representation forms).} In the
idealised model of LISP 1.5, the data structures represented by an
S-expression are what exists in memory. In real-world Lisp systems, the
representation in memory is more complex. A programming system can also
take a very different approach and fully separate the notation from the
in-memory representation.

\emph{Lisp systems.} In Lisp, source code is represented in memory as
S-expressions, which can be manipulated by Lisp primitives. In addition,
Lisp systems have robust macro processing as part of their semantics:
expanding a macro revises the list structure of the code that uses the
macro. Combining these makes it possible to define extensions to the
system in Lisp, with syntax indistinguishable from Lisp. Moreover, it is
possible to write a program that constructs another Lisp program and not
only run it interpretively (using the \texttt{eval} function) but
compile it at runtime (using the \texttt{compile} function) and execute
it. Many domain-specific languages, as well as prototypes of new
programming languages (such as Scheme), were implemented this way. Lisp
the language is, in this sense, a ``programmable programming language''.
\parencite{LispIntro,ProgProgLang}

\hypertarget{references}{\subsection{References}\label{references}}

\emph{Cognitive Dimensions of Notation} \parencite{CogDims} provide a
comprehensive framework for analysing individual notations, while our
focus here is on how multiple notations are related and how they are
structured. It is worth noting that the Cognitive Dimensions also define
\emph{secondary notation}, but in a different sense to ours. For them,
secondary notation refers to whether a notation allows including
redundant information such as colour or comments for readability
purposes.

The importance of notations in the practice of science, more generally,
has been studied by \parencite{PaperTools} as ``paper tools''. These are
formula-like entities which can be manipulated by humans in lieu of
experimentation, such as the aforementioned mathematical notation in
Haskell: a ``paper tool'' for experimentation on a whiteboard.
Programming notations are similar, but they are a way of communicating
with a machine; the experimentation does not happen on paper alone.

\hypertarget{relations-1}{\subsection{Relations}\label{relations-1}}

\begin{itemize}
\tightlist
\item
  \emph{Interaction} (Section \ref{interaction}): The feedback loops
  that exist in a programming system are typically associated with
  individual notations. Different notations may also have different
  feedback loops.
\item
  \emph{Adoptability} (Section \ref{adoptability}): Notational structure
  can affect learnability. In particular, complementing notations may
  require (possibly different) users to master multiple notations.
  Overlapping notations may improve learnability by allowing the user to
  edit the program in one way (perhaps visually) and see the effect in
  the other notation (such as code.)
\item
  \emph{Errors} (Section \ref{errors}). A process that merely records
  user actions in a sequence (such as text editing) will, in particular,
  record any \emph{errors} the user makes and defer their handling to
  later use of the data, keeping the errors \emph{latent}. A process
  which instead treats user actions as edits to a structure, with
  constraints and correctness rules, will be able to catch errors at the
  moment they are introduced and ensure the data coming out is
  error-free.
\end{itemize}

\hypertarget{conceptual-structure}{\section{Conceptual Structure}\label{conceptual-structure}}

\mybox{How is meaning constructed? How are internal and external incentives balanced?}

\hypertarget{dimension-conceptual-integrity-vs.-openness}{\subsection{Dimension: conceptual integrity
vs.~openness}\label{dimension-conceptual-integrity-vs.-openness}}

The evolution of programming systems has led away from \emph{conceptual
integrity} towards an intricate ecosystem of specialised technologies
and industry standards. Any attempt to unify parts of this ecosystem
into a coherent whole will create \emph{incompatibility} with the
remaining parts, which becomes a major barrier to adoption. Designers
seeking adoption are pushed to focus on localised incremental
improvements that stay within the boundaries established by existing
practice. This creates a tension between how highly they can afford to
value conceptual elegance, and how open they are to the pressures
imposed by society. We will turn to both of these opposite
ends---\emph{integrity} and \emph{openness}---in more detail.

\hypertarget{example-conceptual-integrity}{\subsection{Example: conceptual
integrity}\label{example-conceptual-integrity}}

\begin{quote}
I will contend that Conceptual Integrity is the most important
consideration in system design. It is better to have a system omit
certain anomalous features and improvements, but to reflect one set of
design ideas, than to have one that contains many good but independent
and uncoordinated ideas. (Fred~Brooks, \emph{Aristocracy, Democracy and
System Design} \parencite{brooks95aristo})
\end{quote}

\note{The essence of this style can be captured by the phrase “the right thing”. To such a designer it is important to get all of the following characteristics right: Simplicity … Correctness … Consistency … Completeness --- Richard Gabriel}

\begin{quote}
Conceptual integrity arises not (simply) from one mind or from a small
number of agreeing resonant minds, but from sometimes hidden co-authors
and the thing designed itself. (Richard ~Gabriel, \emph{Designed As
Designer} \parencite{DesignedAsDesigner})
\end{quote}

Conceptual integrity strives to reduce complexity at the source; it
employs \emph{unified concepts} that may \emph{compose orthogonally} to
generate diversity. Perhaps the apotheosis of this approach can be found
in early Smalltalk and Lisp machines, which were complete programming
systems built around a single language. They incorporated capabilities
commonly provided \emph{outside} the programming language by operating
systems and databases. Everything was done in one language, and so
everything was represented with the datatypes of that language. Likewise
the libraries and idioms of the language were applicable in all
contexts. Having a \emph{lingua franca} avoided much of the friction and
impedance mismatches inherent to multi-language systems. A similar drive
exists in the Python programming language, which follows the principle
that ``There should be one---and preferably only one---obvious way to do
it'' in order to promote community consensus on a single coherent style.

In addition to Smalltalk and Lisp, many programming languages focus on
one kind of data structure \parencite{MemMod}:

\begin{itemize}
\tightlist
\item
  In COBOL, data consists of nested records as in a business form.
\item
  In Fortran, data consists of parallel arrays.
\item
  In SQL, data is a set of relations with key constraints.
\item
  In scripting languages like Python, Ruby, and Lua, much data takes the
  form of string-indexed hash tables.
\end{itemize}

Finally, many languages are \emph{imperative}, staying close to the
hardware model of addressable memory, lightly abstracted into primitive
values and references into mutable arrays and structures. On the other
hand, \emph{functional} languages hide references and treat everything
as immutable structured values. This conceptual simplification benefits
certain kinds of programming, but can be counterproductive when an
imperative approach is more natural, such as in external input/output.

\hypertarget{example-conceptual-openness}{\subsection{Example: conceptual
openness}\label{example-conceptual-openness}}

\emph{Perl, contra Python}. In contrast to Python's outlook, Perl
proclaims ``There is more than one way to do it'' and considers itself
``the first postmodern programming language'' \parencite{Perl}. ``Perl
doesn't have any agenda at all, other than to be maximally useful to the
maximal number of people. To be the duct tape of the Internet, and of
everything else.'' The Perl way is to accept the status quo of evolved
chaos and build upon it using duct tape and ingenuity. Taken to the
extreme, a programming system becomes no longer a \emph{system},
properly speaking, but rather a \emph{toolkit for improvising}
assemblages of \emph{found} software. Perl can be seen as championing
the values of \emph{pluralism}, \emph{compatibility}, or
\emph{conceptual openness} over conceptual integrity. This philosophy
has been called \emph{Postmodern Programming} \parencite{PoMoProNotes}.

\emph{C++, contra Smalltalk}. Another case is that of C++, which added
to C the Object-Oriented concepts developed by Smalltalk while remaining
100\% compatible with C, down to the level of ABI and performance. This
strategy was enormously successful for adoption, but came with the
tradeoff of enormous complexity compared to languages designed from
scratch for OO, like Smalltalk, Ruby, and Java.

\emph{Worse, contra Better}. Richard Gabriel first described this
dilemma in his influential 1991 essay \emph{Worse is Better}
\parencite{WIB} analysing the defeat of Lisp by UNIX and C. Because UNIX
and C were so easy to port to new hardware, they were ``the ultimate
computer viruses'' despite providing only ``about 50\%--80\% of what you
want from an operating system and programming language''. Their
conceptual openness meant that they adapted easily to the evolving
conditions of the external world. The tradeoff was decreased conceptual
integrity, such as the undefined behaviours of C, the junkyard of
working directories, and the proliferation of special purpose
programming languages to provide a complete development environment.

\tp{Smalltalk objects are "all levels of granularity"; UNIX files are large-scale; Haskell data structures small-scale; very big virtual machines; there is also the web / distributed file system?}

\emph{UNIX and Files}. Many programming languages and systems impose
structure at a ``fine granularity'': that of individual variables and
other data and code structures. Conversely, systems like UNIX and the
Web impose fewer restrictions on how programmers represent things. UNIX
insists only on a basic infrastructure of ``large objects''
\parencite{KellOS}, delegating all fine-grained structure to client
programs. This scores many points for conceptual openness. \emph{Files}
provide a universal API for reading and writing byte streams, a
low-level construct containing so many degrees of freedom that it can
support a wide variety of formats and ecosystems. \emph{Processes}
similarly provide a thin abstraction over machine-level memory and
processors.

Concepual integrity is necessarily sacrificed for such openness; while
``everything is a file'' gestures at integrity, in the vein of
Smalltalk's ``everything is an object'', exceptions proliferate.
Directories are special kinds of files with special operations, hardware
device files require special \texttt{ioctl} operations, and many
commands expect files containing newline separators. Additionally,
because client programs must supply their \emph{own} structure for
fine-grained data and code, they are given little in the way of mutual
compatibility. As a result, they tend to evolve into competing silos of
duplicated infrastructure \parencite{KellOS,Mythical}.

\emph{The Web}. Web HTTP endpoints, meanwhile, have proven to be an even
more adaptable and viral abstraction than UNIX files. They operate at a
similar level of abstraction as files, but support richer content and
encompass internet-wide interactions between autonomous systems. In a
sense, HTTP GET and PUT have become the ``subroutine calls'' of an
internet-scale programming system. Perhaps the most salient thing about
the Web is that its usefulness came as such a surprise to everyone
involved in designing or competing with it. It is likely that, by
staying close to the existing practice of transferring files, the Web
gained a competitive edge over more ambitious and less familiar
hypertext projects like Xanadu \parencite{TedNelson}.

The choice between compatibility and integrity correlates with the
personality traits of \emph{pragmatism} and \emph{idealism}. It is
pragmatic to accept the status quo of technology and make the best of
it. Conversely, idealists are willing to fight convention and risk
rejection in order to attain higher goals. We can wonder which came
first: the design decision or the personality trait? Do Lisp and Haskell
teach people to think more abstractly and coherently, or do they filter
for those with a pre-existing condition? Likewise, perhaps introverted
developers prefer the cloisters of Smalltalk or Lisp to the adventurous
``Wild West'' of the Web.

\hypertarget{dimension-composability}{\subsection{Dimension: composability}\label{dimension-composability}}

In short, \emph{you can get anywhere by putting together a number of
smaller steps.} There exist building blocks which span a range of useful
combinations.
\note{JE. LEGOs might be a more friendly example than Linear Algebra.
Such a property can be analogised to *linear independence* in mathematical vector spaces: a number of primitives (basis vectors) whose possible combinations span a meaningful space.}
Composability is, in a sense, key to the notion of ``programmability''
and every programmable system will have some level of composability
(e.g.~in the scripting language.)

\emph{UNIX} shell commands are a standard example of composability. The
base set of primitive commands can be augmented by programming command
executables in other languages. Given some primitives, one can ``pipe''
one's output to another's input (\texttt{\textbar{}}), sequence
(\texttt{;} or \texttt{\&\&}), select via conditions, and repeat with
loop constructs, enabling full imperative programming. Furthermore,
command compositions can be packaged into a named ``script'' which
follows the same interface as primitive commands, and named subprograms
within a script can also be defined.

In \emph{HyperCard}, the \emph{Authoring Environment} is
\emph{non}-composable for programming buttons: there is simply a set of
predefined behaviours to choose from. Full scriptability is available
only in the \emph{Programming Environment}.

The \emph{Haskell type system}, as well as that of other functional
programming languages, exhibits high composability. New types can be
defined in terms of existing ones in several ways. These include
records, discriminated unions, function types and recursive constructs
(e.g.~to define a \texttt{List} as either a \texttt{Nil} or a
combination of element plus other list.) The C programming language also
has some means of composing types that are analogous in some ways, such
as structs, unions, enums and indeed even function pointers. For every
type, there is also a corresponding ``pointer'' type. It lacks, however,
the recursive constructs permitted in Haskell types.

\note{*Web* Mashups in Web 2.0? Yahoo Pipes?}

\hypertarget{dimension-convenience}{\subsection{Dimension: convenience}\label{dimension-convenience}}

In short, \emph{you can get to X, Y or Z via one single step.} There are
ready-made solutions to specific problems, not necessarily generalisable
or composable. Convenience often manifests as ``canonical'' solutions
and utilities in the form of an expansive standard library.

Composability without convenience is a set of atoms or gears;
theoretically, anything one wants could be built out of them, but one
must do that work. This situation has been criticised as the \emph{Lisp
Curse} \parencite{LispCurse}.

Composability \emph{with} convenience is a set of convenient specific
tools \emph{along with} enough components to construct new ones. The
specific tools themselves could be transparently composed of these
building blocks, but this is not essential. They save users the time and
effort it would take to ``roll their own'' solutions to common tasks.

For example, let us turn to a convenience factor of \emph{UNIX} shell
commands, having already discussed their composability above. Observe
that it would be possible, in principle, to pass all information to a
program via standard input. Yet in actual practice, for convenience,
there is a standard interface of \emph{command-line arguments} instead,
separate from anything the program takes through standard input. Most
programming systems similarly exhibit both composability and
convenience, providing templates, standard libraries, or otherwise
pre-packaged solutions, which can nevertheless be used programmatically
as part of larger operations.

\note{ex: something in the UI world? one click vs. long winded "principled" way of doing the thing? (macros? applescript?)}

\hypertarget{dimension-commonality}{\subsection{Dimension: commonality}\label{dimension-commonality}}

\note{JE This seems like data modelling issues that happen during application design, not programming system design.}

Humans can see Arrays, Strings, Dicts and Sets all have a ``size'', but
the software needs to be \emph{told} that they are the ``same''.
Commonality like this can be factored out into an explicit structure (a
``Collection'' class), analogous to database \emph{normalisation}. This
way, an entity's size can be queried without reference to its particular
details: if \texttt{c} is declared to be a Collection, then one can
straightforwardly access \texttt{c.size}.

Alternatively, it can be left implicit. This is less upfront work, but
permits instances to \emph{diverge}, analogous to \emph{redundancy} in
databases. For example, Arrays and Strings might end up with ``length'',
while Dict and Set call it ``size''. This means that, to query the size
of an entity, it is necessary to perform a case split according to its
concrete type, solely to funnel the diverging paths back to the
commonality they represent:

\begin{verbatim}
if (entity is Array or String)  size := entity.length
else if (entity is Dict or Set) size := entity.size
\end{verbatim}

\joel{Web APIs e.g. onmousedown/onmouseup, imperative onmousemove instead of reified mouse pointer observable (this belongs more in a Factoring of Structure / Complexity dimension...)
   - tbh this is also a "machine legibility" issue; a human can recognise onmousemove and onmousedown as having something in common -- "mouse" -- but the computer just sees two non-equal strings as different as zQx6= and omlette.
   - onmousedown further makes the *mouse* part explicit, but the sub-device -- the button -- is passed as a numerical argument. ...
   - What really annoyed me, and seems most relevant, is that mouse buttons and keyboard keys the same in a very significant way -- they're binary-state buttons -- which means they ought to "implement the same interface", so the system will let me treat them the same insofar as they have commonalities like this. It should be trivial to rebind keyboard keys to the mouse buttons or vice versa, but this "poor factoring" obstructs this.
   - viz. OOP interfaces and abstraction, this factoring is forcing you to rely on irrelevant concrete details of the object. Instead of `if (isMouseButton) listenMouseButton(fn) else if (isKey) listenKey(fn)`, it should just be `listen(fn)`.}

\note{
EXAMPLES: interfaces/base classes; structural vs nominal typing
EXAMPLES: non-programming language world?
HyperCard - had shared backgrounds, which arose from the need of writing the help files.
}

\hypertarget{examples-flattening-and-factoring}{\subsection{Examples: flattening and
factoring}\label{examples-flattening-and-factoring}}

Data structures usually have several ``moving parts'' that can vary
independently. For example, a simple pair of ``vehicle type'' and
``colour'' might have all combinations of (Car, Van, Train) and (Red,
Blue). In this \emph{factored} representation, we can programmatically
change the colour directly: \texttt{pair.second\ =\ Red} or
\texttt{vehicle.colour\ =\ Red}.

In some contexts, such as class names, a system might only permit such
multi-dimensional structure as an \emph{exhaustive enumeration}: RedCar,
BlueCar, RedVan, BlueVan, RedTrain, BlueTrain, etc. The system sees a
flat list of atoms, even though a human can see the sub-structure
encoded in the string. In this world, we cannot simply ``change the
colour to Red'' programmatically; we would need to case-split as
follows:

\begin{verbatim}
if (type is BlueCar) type := RedCar
else if (type is BlueVan) type := RedVan
else if (type is BlueTrain) type := RedTrain
...
\end{verbatim}

The \emph{commonality} between RedCar, RedVan, BlueCar, and so on has
been \emph{flattened}. There is implicit structure here that remains
\emph{un-factored}, similar to how numbers can be expressed as singular
expressions (16) or as factor products (2,2,2,2). \emph{Factoring} this
commonality gives us the original design, where there is a pair of
values from different sets.

In \emph{relational databases}, there is an opposition between
\emph{normalisation} and \emph{redundancy}. In order to fit multi-table
data into a \emph{flat} table structure, data needs to be duplicated
into redundant copies. When data is \emph{factored} into small tables as
much as possible, such that there is only one place each piece of data
``lives'', the database is in \emph{normal form} or \emph{normalised}.
Redundancy is useful for read-only processes, because there is no need
to join different tables together based on common keys. Writing,
however, becomes risky; in order to modify one thing, it must be
synchronised to the multiple places it is stored. This makes highly
normalised databases optimised for writes over reads.

\hypertarget{remark-the-end-of-history}{\subsection{Remark: the end of
history?}\label{remark-the-end-of-history}}

Today we live in a highly developed world of software technology. It is
estimated that 41,000 person years have been invested into Linux. We
describe software development technologies in terms of \emph{stacks} of
specialised tools, each of which might capitalise over 100 person-years
of development. Programming systems have become programming ecosystems:
not designed, but evolved. How can we noticeably improve programming in
the face of the overwhelming edifice of existing technology? There are
strong incentives to focus on localised incremental improvements that
don't cross the established boundaries.

The history of computing is one of cycles of evolution and revolution.
Successive cycles were dominated in turn by mainframes, minicomputers,
workstations, personal computers, and the Web. Each transition built a
whole new technology ecosystem replacing or on top of the previous. The
last revolution, the Web, was 25 years ago, with the result that many
people have never experienced a disruptive platform transition. Has
history stopped, or are we just stuck in a long cycle, with increasingly
pent-up pressures for change? If it is the latter, then incompatible
ideas now spurned may yet flourish.

\hypertarget{references-1}{\subsection{References}\label{references-1}}

\begin{itemize}
\tightlist
\item
  How to Design a Good API and Why it Matters \parencite{APIdesign}
\end{itemize}

\hypertarget{customizability}{\section{Customizability}\label{customizability}}

\mybox{Once a program exists in the system, how can it be extended and modified?}

Programming is a gradual process. We start either from nothing, or from
an existing program, and gradually extend and refine it until it serves
a given purpose. Programs created using different programming systems
can be refined to different extents, in different ways, at different
stages of their existence.

Consider three examples. First, a program in a conventional programming
language like Java can be refined only by modifying its source code.
However, you may be able to do so by just adding new code, such as a new
interface implementation. Second, a spreadsheet can be modified at any
time by modifying the formulas or data it contains. There is no separate
programming phase. However, you have to modify the formulas directly in
the cell---there is no way of modifying it by specifying a change in a
way that is external to the cell. Third, a \emph{self-sustaining}
programming system, such as Smalltalk, does not make an explicit
distinction between ``programming'' and ``using'' phases, and it can be
modified and extended via itself. It gives developers the power to
experiment with the system and, in principle, replace it with a better
system from within.

\hypertarget{dimension-staging-of-customisation}{\subsection{Dimension: staging of
customisation}\label{dimension-staging-of-customisation}}

For systems that distinguish between different stages, such as writing
source code versus running a program, customisation methods may be
different for each stage. In traditional programming languages,
customisation is done by modifying or adding source code at the
programming stage, but there is no (automatically provided) way of
customising the created programs once they are running.

There are a number of interesting questions related to staging of
customisation. First, what is the notation used for customisation? This
may be the notation in which a program was initially created, but a
system may also use a secondary notation for customisation (consider
Emacs using Emacs Lisp). For systems with a stage distinction, an
important question is whether such changes are \emph{persistent}.

\emph{Smalltalk, Interlisp and similar.} In image-based programming
systems, there is generally no strict distinction between stages and so
a program can be customised during execution in the same way as during
development. The program image includes the programming environment.
Users of a program can open this, navigate to a suitable object or a
class (which serve as the \emph{addressable extension points}) and
modify that. Lisp-based systems such as \emph{Interlisp} follow a
similar model. Changes made directly to the image are persistent. The
PILOT system for Lisp \parencite{Pilot} offers an interactive way of
correcting errors when a program fails during execution. Such
corrections are then applied to the image and are thus persistent.

\emph{Document Object Model (DOM) and Webstrates}: In the context of Web
programming, there is traditionally a stage distinction between
programming (writing the code and markup) and running (displaying a
page). However, the DOM can also be modified by browser Developer
Tools---either manually, by running scripts in a console, or by using a
userscript manager such as Greasemonkey. Such changes are not persistent
in the default browser state, but are made so by Webstrates
\parencite{Webstrates} which synchronise the DOM between the server and
the client. This makes the DOM collaborative, but not (automatically)
\emph{live} because of the complexities this implies for event handling.

\hypertarget{dimension-addressing-and-externalisability}{\subsection{Dimension: addressing and
externalisability}\label{dimension-addressing-and-externalisability}}

Programs in all programming systems have a representation that may be
exposed through notation such as source code. When customising a
program, an interesting question is whether a customisation needs to be
done by modifying the original representation, or whether it can be done
by \emph{adding} something alongside the original structure.

In order to support customisation through addition, a programming system
needs a number of characteristics introduced by Basman et
al.~\parencite{Externalize,OpenAuthorial}. First, the system needs to
support \emph{addressing}: the ability to refer to a part of the program
representation from the outside. Next, \emph{externalisability} means
that a piece of addressed state can be exhaustively transferred between
the system and the outside world. Finally, \emph{additive authoring}
requires that system behaviours can be \emph{changed} by simply
\emph{adding} a new expression containing addresses---in other words,
anything can be \emph{overridden} without being \emph{erased}. Of
particular importance is how addresses are specified and what extension
points in the program they can refer to. The system may offer an
automatic mechanism that makes certain parts of a program addressable,
or this task may be delegated to the programmer.

\emph{Cascading Style Sheets (CSS)}: CSS is a prime example of additive
authoring within the Web programming system. It provides rich
addressability mechanisms that are partly automatic (when referring to
tag names) and partly manual (when using element IDs and class names).
Given a web page, it is possible to modify almost any aspect of its
appearance by simply \emph{adding} additional rules to a CSS file. The
Infusion project \parencite{Infusion} offers similar customisability
mechanisms, but for behaviour rather than just styling. There is also
the recent programming system Varv~\parencite{Varv}, which embodies
additive authoring as a core principle.

\emph{Object Oriented Programming (OOP) and Aspect Oriented Programming
(AOP)}: in conventional programming languages, customisation is done by
modifying the code itself. OOP and AOP make it possible to do so by
adding code independently of existing program code. In OOP, this
requires manual definition of extension points, i.e.~interfaces and
abstract methods. Functionality can then be added to a system by
defining a new class (although injecting the new class into existing
code without modification requires some form of configuration such as a
dependency injection container). AOP systems such as AspectJ
\parencite{AspectJ} provides a richer addressing mechanism. In
particular, it makes it possible to add functionality to the invocation
of a specific method (among other options) by using the \emph{method
call pointcut}. This functionality is similar to \emph{advising} in
Pilot \parencite{Pilot}.

\hypertarget{dimension-self-sustainability}{\subsection{Dimension:
self-sustainability}\label{dimension-self-sustainability}}

For most programming languages, programming systems, and ordinary
software applications, if one wants to customise beyond a certain point,
one must go beyond the facilities provided in the system itself. Most
programming systems maintain a clear distinction between the \emph{user
level}, where the system is used, and \emph{implementation level}, where
the source code of the system itself resides. If the user level does not
expose control over some property or feature, then one is forced to go
to the implementation level. In the common case this will be a
completely different language or system, with an associated learning
cost. It is also likely to be lower-level---lacking expressive
functions, features or abstractions of the user level---which makes for
a more tedious programming experience.

It is possible, however, to carefully design systems to expose deeper
aspects of their implementation \emph{at the user level}, relaxing the
formerly strict division between these levels. For example, in the
research system \emph{3-Lisp}~\parencite{ProcRefl}, ordinarily built-in
functions like the conditional \texttt{if} and error handling
\texttt{catch} are implemented in 3-Lisp code at the user level.

The degree to which a system's inner workings are accessible to the user
level, we call \emph{self-sustainability}. At the maximal degree of this
dimension would reside ``stem cell''-like systems: those which can be
progressively evolved to arbitrary behaviour without having to ``step
outside'' of the system to a lower implementation level. In a sense, any
difference between these systems would be merely a difference in initial
state, since any could be turned into any other.

The other end, of minimal self-sustainability, corresponds to minimal
customisability: beyond the transient run-time state changes that make
up the user level of any piece of software, the user cannot change
anything without dropping down to the means of implementation of the
system. This would resemble a traditional end-user ``application''
focused on a narrow domain with no means to do anything else.

The terms ``self-describing'' or ``self-implementing'' have been used
for this property, but they can invite confusion: how can a thing
describe itself? Instead, a system that can \emph{sustain itself} is an
easier concept to grasp. The examples that we see of high
self-sustainability all tend to be \emph{Operating System-like}. UNIX is
widely established as an operating system, while Smalltalk and Lisp have
been branded differently. Nevertheless, all three have shipped as the
operating systems of custom hardware, and have similar responsibilities.
Specifically: they support the execution of ``programs''; they define an
interface for accessing and modifying state; they provide standard
libraries of common functionality; they define how programs can
communicate with each other; they provide a user interface.

\emph{UNIX}: Self-sustainability of UNIX is owed to the combination of
two factors. First, the system is implemented in binary files (via
ELF\footnote{Executable and Linkable Format.}) and text files (for
configuration). Second, these files are part of the user-facing
filesystem, so users can replace and modify parts of the system using
UNIX file interfaces.

\emph{Smalltalk and Combined Object Lambda Architectures}:
Self-sustainability in Smalltalk is similar to UNIX, but at a finer
granularity and with less emphasis on whether things reside in volatile
(process) or non-volatile (file) storage. The analogous points are that
(1) the system is implemented as objects with methods containing
Smalltalk code, and (2) these are modifiable using the class browser and
code editor. Combined Object Lambda Architectures, or
COLAs~\parencite{COLAs}, are a theoretical system design to improve on
the self-sustainability of Smalltalk. This is achieved by generalising
the object model to support relationships beyond classes.

\hypertarget{references-2}{\subsection{References}\label{references-2}}

In addition to the examples discussed above, the proceedings of
self-sustaining systems workshops
\parencite{SelfSustaining2008,SelfSustaining2010} provide numerous
examples of systems and languages that are able to bootstrap, implement,
modify, and maintain themselves; Gabriel's analysis of programming
language revolutions \parencite{PLrev} uses \emph{advising} in PILOT,
related Lisp mechanisms, and ``mixins'' in OOP to illustrate the
difference between the ``languages'' and ``systems'' paradigms.

\hypertarget{relations-2}{\subsection{Relations}\label{relations-2}}

\begin{itemize}
\tightlist
\item
  \emph{Flattening and factoring} (Section
  \ref{examples-flattening-and-factoring}): related in that
  ``customizability'' is a form of creating new programs from existing
  ones; factoring repetitive aspects into a reusable standard component
  library facilitates the same thing.
\item
  \emph{Interaction} (Section \ref{interaction}): this determines
  whether there are separate stages for running and writing programs and
  may thus influence what kind of customisation is possible.
\end{itemize}

\hypertarget{complexity}{\section{Complexity}\label{complexity}}

\mybox{How does the system structure complexity and what level of detail is required?}

There is a massive gap between the level of detail required by a
computer, which executes a sequence of low-level instructions, and the
human description of a program in higher-level terms. To bridge this
gap, a programming system needs to deal with the complexity inherent in
going from a high-level description to low-level instructions.

Ever since the 1940s, programmers have envisioned that ``automatic
programming'' will allow higher-level programming. This did not
necessarily mean full automation. In fact, the first ``automatic
programming'' systems referred to higher-level programming languages
with a compiler (or an interpreter) that expanded the high-level code
into detailed instructions.

Most programming systems use \emph{factoring of complexity} and
encapsulate some of the details that need to be specified into
components that can be reused by the programmer. The details may be
encapsulated in a library, or filled in by a compiler or interpreter.
Such factoring may also be reflected in the conceptual structure of the
system (Section \ref{examples-flattening-and-factoring}). However, a
system may also fully \emph{automate} some aspects of programming. In
those cases, a general-purpose algorithm solves a whole class of
problems, which then do not need to be coded explicitly. Think of
planning the execution of SQL queries, or of the inference engine
supporting a logic programming language like Prolog.

\hypertarget{remark-notations}{\subsection{Remark: notations}\label{remark-notations}}

Even when working at a high level, programming involves manipulating
some program notation. In high-level functional or imperative
programming languages, the programmer writes code that typically has
clear operational meaning, even when some of the complexity is relegated
to a library implementation or a runtime. When using declarative
programming systems like SQL, Prolog or Datalog, the meaning of a
program is still unambiguous, but it is not defined
operationally---there is a (more or less deterministic) inference engine
that solves the problem based on the provided description. Finally,
systems based on \emph{programming by example} step even further away
from having clear operational meaning---the program may be simply a
collection of sample inputs and outputs, from which a (possibly
non-deterministic) engine infers the concrete steps of execution.

\hypertarget{dimension-factoring-of-complexity}{\subsection{Dimension: factoring of
complexity}\label{dimension-factoring-of-complexity}}

The basic mechanism for dealing with complexity is \emph{factoring} it.
Given a program, the more domain-specific aspects of the logic are
specified explicitly, whereas the more mundane and technical aspects of
the logic are left to a reusable component. Often, this reusable
component is just a library. Yet in the case of higher-level programming
languages, the reusable component may include a part of a language
runtime such as a memory allocator or a garbage collector. In case of
declarative languages or programming by example, the reusable component
is a general purpose inference engine.

\hypertarget{dimension-level-of-automation}{\subsection{Dimension: level of
automation}\label{dimension-level-of-automation}}

Factoring of complexity shields the programmer from some details, but
those details still need to be explicitly programmed. Depending on the
customizability of the system, this programming may or may not be
accessible, but it is always there. For example, a function used in a
spreadsheet formula is implemented in the spreadsheet system.

A programming system with higher \emph{level of automation} requires
more than simply factoring code into reusable components. It uses a
mechanism where some details of the operational meaning of a program are
never explicitly specified, but are inferred automatically by the
system. This is the approach of \emph{programming by example} and
\emph{machine learning}, where behaviour is specified through examples.
In some cases, deciding whether a feature is \emph{automation} or merely
\emph{factoring of complexity} is less clear: garbage collection can be
seen as either a simple case of automation, or a sophisticated case of
factoring complexity.

There is also an interesting (and perhaps inevitable) trade-off. The
higher the level of automation, the less explicit the operational
meaning of a program. This has a wide range of implications. Smaragdakis
\parencite{NextGen} notes, for example, that this means the
implementation can significantly change the performance of a program.

\hypertarget{example-domain-specific-languages}{\subsection{Example: domain-specific
languages}\label{example-domain-specific-languages}}

Domain-specific languages \parencite{DSLs} provide an example of
factoring of complexity that does not involve automation. In this case,
programming is done at two levels. At the lower level, an (often more
experienced) programmer develops a domain-specific language, which lets
a (typically less experienced) programmer easily solve problems in a
particular domain: say, modelling of financial contracts, or specifying
interactive user interfaces.

The domain-specific language provides primitives that can be composed,
but each primitive and each form of composition has explicitly
programmed and unambiguous operational meaning. The user of the
domain-specific language can think in the higher-level concepts it
provides, and this conceptual structure can be analysed using the
dimensions in Section\textasciitilde{}\ref{conceptual-structure}. As
long as these concepts are clear, the user does not need to be concerned
with the details of how exactly the resulting programs run.

\hypertarget{example-programming-by-example}{\subsection{Example: programming by
example}\label{example-programming-by-example}}

An interesting case of automation is \emph{programming by example}
\parencite{PBE}. In this case, the user does not provide even a
declarative specification of the program behaviour, but instead
specifies sample inputs and outputs. A more or less sophisticated
algorithm then attempts to infer the relationship between the inputs and
the outputs. This may, for example, be done through program synthesis
where an algorithm composes a transformation using a (small) number of
pre-defined operations. Programming by example is often very accessible
and has been used in spreadsheet applications \parencite{PBEExcel}.

\joel{ Sad to get rid of this, but we should find a better way to include Kell's fragmentation.
## Remark: fragmentation
An interesting issue is that reusable components that enable higher levels of automation are often specific to each system. This, arguably, limits what we can achieve as components that enable higher-levels of automation are increasingly complex to implement. For example, the resolution algorithm that is at the core of a Prolog system is typically tightly bound to the particular system and cannot be easily reused by another programming system.

As noted in \parencite{KellOS,Mythical}, incompatible reusable components that exist for multiple systems also limit compositionality. One possible exception from the rule is the Z3 theorem prover, which is used as an implementation mechanism by multiple programming systems including Dafny and F*, as well as by numerous program verification tools.
}

\hypertarget{example-next-level-automation}{\subsection{Example: next-level
automation}\label{example-next-level-automation}}

Throughout history, programmers have always hoped for the next level of
``automatic programming''. As observed by Parnas \parencite{Euphemism},
``automatic programming has always been a euphemism for programming in a
higher-level language than was then available to the programmer''.

We may speculate whether Deep Learning will enable the next step of
automation. However, this would not be different in principle from
existing developments. We can see any level of automation as using
\emph{artificial intelligence} methods. This is the case for declarative
languages or constraint-based languages---where the inference engine
implements a traditional AI method (GOFAI, i.e., Good Old Fashioned AI).

\joel{include a definition and discussion of "boilerplate" code!}
\note{Tomas: I removed references here, because I could not think of anything else to add here. I guess it makes sense to keep those optional..}

\hypertarget{relations-3}{\subsection{Relations}\label{relations-3}}

\begin{itemize}
\tightlist
\item
  \emph{Conceptual structure} (Section~\ref{conceptual-structure}): In
  many cases, the factoring of complexity follows the conceptual
  structure of the programming system.
\item
  \emph{Flattening and factoring}
  (Section~\ref{examples-flattening-and-factoring}: One typically
  automates the thing at the lowest level in one's factoring (by making
  the lowest level a thing that exists outside of the program---in a
  system or a library)
\end{itemize}

\hypertarget{errors}{\section{Errors}\label{errors}}

\mybox{What does the system consider to be an \emph{error}? How are they prevented and handled?}

A computer system is not aware of human intentions. There will always be
human mistakes that the system cannot recognise as errors. Despite this,
there are many that it \emph{can} recognise, and its design will
determine \emph{which} human mistakes can become detectable program
errors. This revolves around several questions: What can cause an error?
Which ones can be prevented from happening? How should the system react
to errors?

Following the standard literature on errors \parencite{HumanError}, we
distinguish four kinds of errors: slips, lapses, mistakes and failures.
A \emph{slip} is an error caused by transient human attention failure,
such as a typo in the source code. A \emph{lapse} is similar but caused
by memory failure, such as an incorrectly remembered method name. A
\emph{mistake} is a logical error such as bad design of an algorithm.
Finally, a \emph{failure} is a system error caused by the system itself
that the programmer has no control over, e.g.~a hardware or a virtual
machine failure.

\hypertarget{dimensions-error-detection}{\subsection{Dimensions: error
detection}\label{dimensions-error-detection}}

Errors can be identified in any of the \emph{feedback loops} that the
system implements. This can be done either by a human or the system
itself, depending on the nature of the feedback loop.

Consider three examples. First, in live programming systems, the
programmer immediately sees the result of their code changes. Error
detection is done by a human and the system can assist this by
visualising as many consequences of a code change as possible. Second,
in a system with a static checking feedback loop (such as syntax checks,
static type systems), potential errors are reported as the result of the
analysis. Third, errors can be detected when the developed software is
run, either when it is tested by the programmer (manually or through
automated testing) or when it is run by a user.

Error detection in different feedback loops is suitable for detecting
different kinds of errors. Many slips and lapses can be detected by the
static checking feedback loop, although this is not always the case. For
example, consider a ``compact'' \emph{expression geography} where small
changes in code may result in large changes of behaviour. This makes it
easier for slips and lapses to produce hard to detect errors. Mistakes
are easier to detect through a live feedback loop, but they can also be
partly detected by more advanced static checking.

\hypertarget{example-static-typing}{\subsection{Example: static typing}\label{example-static-typing}}

In statically typed programming languages like Haskell and Java, types
are used to capture some information about the intent of the programmer.
The type checker ensures code matches the lightweight specification
given using types. In such systems, types and implementation serve as
two descriptions of programmer's intent that need to align; what varies
is the extent to which types can capture intent and the way in which the
two are constructed; that is, which of the two comes first.

\hypertarget{examples-tdd-repl-and-live-coding}{\subsection{Examples: TDD, REPL and live
coding}\label{examples-tdd-repl-and-live-coding}}

Whereas static typing aims to detect errors without executing code,
approaches based on immediate feedback typically aim to execute (a
portion of) the code and let the programmer see the error immediately.
This can be done in a variety of ways.

In case of \emph{test-driven development}, tests play the role of
specification (much like types) against which the implementation is
checked. Such systems may provide more or less immediate feedback,
depending on when tests are executed (automatically in the background,
or manually). Systems equipped with a read-eval-print loop (REPL) let
programmers run code on-the-fly and inspect results. For successful
error detection, the results need to be easily observable: a printed
output is more helpful than a hidden change of system state. Finally, in
live coding systems, code is executed immediately and the programmer's
ability to recognise errors depends on the extent to which the system
state is observable. In live coded music, for example, you \emph{hear}
that your code is not what you wanted, providing an easy-to-use
immediate error detection mechanism.

\hypertarget{remark-eliminating-latent-errors}{\subsection{Remark: eliminating latent
errors}\label{remark-eliminating-latent-errors}}

A common aim of error detection is to prevent \emph{latent errors},
i.e.~errors that occurred at some \emph{earlier} point during execution,
but only manifest themselves through an unexpected behaviour later on.
For example, we might dereference the wrong memory address and store a
junk value to a database; we will only find out upon accessing the
database. Latent errors can be prevented differently in different
feedback loops. In a live feedback loop, this can be done by visualising
effects that would normally remain hidden. When running software, latent
errors can be prevented through a mechanism that detects errors as early
as possible (e.g.~initialising pointers to \texttt{null} and stopping if
they are dereferenced.)

\emph{Elm and time-travel debugging.} One notable mechanism for
identifying latent errors is the concept of \emph{time-travel debugging}
popularised by the Elm programming language. In time-travel debugging,
the programmer is able to step back through time and see what execution
steps were taken prior to a certain point. This makes it possible to
break execution when a latent error manifests, but then retrace the
execution back to the actual source of the error.

\hypertarget{dimension-error-response}{\subsection{Dimension: error response}\label{dimension-error-response}}

When an error is detected, there are a number of typical ways in which
the system can respond. The following applies to systems that provide
some kind of error detection during execution.

\begin{itemize}
\tightlist
\item
  It may attempt to automatically recover from the error as best as
  possible. This may be feasible for simpler errors (slips and lapses),
  but also for certain mistakes (a mistake in an algorithm's concurrency
  logic may often be resolved by restarting the code.)
\item
  It may proceed as if the error did not happen. This can eliminate
  expensive checks, but may lead to latent errors later.
\item
  It may ask a human how to resolve the issue. This can be done
  interactively, by entering into a mode where the code can be
  corrected, or non-interactively by stopping the system.
\end{itemize}

Orthogonally to the above options, a system may also have a way to
recover from latent errors by tracing back through the execution in
order to find the root cause. It may also have a mechanism for undoing
all actions that occurred in the meantime, e.g.~through transactional
processing.

\emph{Interlisp and Do What I Mean (DWIM).} Interlisp's DWIM facility
attempts to automatically correct slips and lapses, especially
misspellings and unbalanced parentheses. When Interlisp encounters an
error, such as a reference to an undefined symbol, it invokes DWIM. In
this case, DWIM then searches for similarly named symbols frequently
used by the current user. If it finds one, it invokes the symbol
automatically, corrects the source code and notifies the user. In more
complex cases where DWIM cannot correct the error automatically, it
starts an interaction with the user and lets them correct it manually.

\hypertarget{relations-4}{\subsection{Relations}\label{relations-4}}

\begin{itemize}
\tightlist
\item
  \emph{Feedback loops}: Error detection always happens as part of an
  individual feedback loop. The feedback loops thus determine the
  structure at which error detection can happen.
  \note{- _Information loss_: Certain mechanism for error detection can only work if sufficient amount of information is available. For example, traveling debugger facility requires at least a form of execution log (but could also be easily implemented in a system based on bi-directional evaluation).}
\item
  \emph{Automation:} A semi-automatic error recovery system (such as
  DWIM) implements a form of automation. The concept of antifragile
  software \parencite{Antifragile} is a more sophisticated example of
  error recovery through automation.
\item
  \emph{Expression geography:} In an expression geography where small
  changes in notation lead to valid but differently behaved programs, a
  slip or lapse is more likely to lead to an error that is difficult to
  detect through standard mechanisms.
\end{itemize}

\hypertarget{references-3}{\subsection{References}\label{references-3}}

The most common error handling mechanism in conventional programming
languages is exception handling. The modern form of exception handling
has been described by Goodenough~\parencite{ExceptionHandling}; Ryder et
al.~\parencite{SweImpact} documents the history and influences of
Software Engineering on exception handling. The concept of
\emph{antifragile software} \parencite{Antifragile} goes further by
suggesting that software could improve in response to errors. Work on
Chaos Engineering \parencite{ChaosMonkey} is a step in this direction.

Reason~\parencite{HumanError} analyses errors in the context of human
errors and develops a classification of errors that we adopt. In the
context of computing, errors or \emph{miscomputation} has been analysed
from a philosophical perspective
\parencite{Miscomputation,MalfunctioningSW}. Notably, attitudes and
approaches to errors also differ for different programming subcultures
\parencite{LivingWithErrors}.

\hypertarget{adoptability}{\section{Adoptability}\label{adoptability}}

\mybox{How does the system facilitate or obstruct adoption by both individuals and communities?}

We consider adoption by individuals as the dimension of
\emph{Learnability}, and adoption by communities as the dimension of
\emph{Sociability}.

\hypertarget{dimension-learnability}{\subsection{Dimension: learnability}\label{dimension-learnability}}

Mainstream software development technologies require substantial effort
to learn. Systems can be made easier to learn in several ways:

\begin{itemize}
\tightlist
\item
  Specialising to a specific application domain.
\item
  Specialising to simple small-scale needs.
\item
  Leveraging the background knowledge, skills, and terminologies of
  specific communities.
\item
  Supporting learning with staged levels of complexity and assistive
  development tools \parencite{FullBrain}. Better \emph{Feedback Loops}
  can help (Section~\ref{interaction}).
\item
  Collapsing heterogeneous technology stacks into simpler unified
  systems. This relates to the dimensions under \emph{Conceptual
  Structure} (Section~\ref{conceptual-structure}).
\end{itemize}

FORTRAN was a breakthrough in programming because it specialised to
scientific computing and leveraged the background knowledge of
scientists about mathematical formulas. COBOL instead specialised to
business data processing and embraced the business community by
eschewing mathematics in favor of plain English.

LOGO was the first language explicitly designed for teaching children.
Later BASIC and Pascal were designed for teaching then-standard
programming concepts at the University level. BASIC and Pascal had
second careers on micropocessors in the 90's. These microprocessor
programming systems were notable for being complete solutions
integrating everything necessary, and so became home schools for a
generation of programmers. More recently languages like Racket, Pyret,
and Grace have supported learning by revealing progressive levels of
complexity in stages. Scratch returned to Logo's vision of teaching
children with a graphical programming environment emphasising
playfulness rather than generality.

Some programming languages have consciously prioritised the programmer's
experience of learning and using them. Ruby calls itself \emph{a
programmer's best friend} by focusing on simplicity and elegance. Elm
targets the more specialised but still fairly broad domain of web
applications while focusing on simplicity and programmer-friendliness.
It forgoes capabilities that would lead to run-time crashes. It also
tries hard to make error messages clear and actionable.

If we look beyond programming languages \emph{per se}, we find
programmable systems with better learnability. The best example is
spreadsheets, which offer a specialised computing environment that is
simpler and more intuitive. The visual metaphor of a grid leverages
human perceptual skills. Moving all programming into declarative
formulas and attributes greatly simplifies both creation and
understanding. Research on Live Programming
\parencite{Hancock2003,BretVictor} has sought to incorporate these
benefits into general purpose programming, but with limited success to
date.

HyperCard and Flash were both programming systems that found widespread
adoption by non-experts. Like spreadsheets they had an organising visual
metaphor (cards and timelines respectively). They both made it easy for
beginners to get started. Hypercard had layers of complexity intended to
facilitate gradual mastery.

Smalltalk and Lisp machines were complex but unified. After overcoming
the initial learning curve, their environments provided a complete
solution for building entire application systems of arbitrary complexity
without having to learn other technologies. Boxer
\parencite{BoxerDesign} is notable for providing a general-purpose
programming environment---albeit for small-scale applications---along
with an organising visual metaphor like that of spreadsheets.

\hypertarget{dimension-sociability}{\subsection{Dimension: sociability}\label{dimension-sociability}}

Over time, especially in the internet era, social issues have come to
dominate programming. Much programming technology is now developed by
open-source communities, and all programming technologies are now
embedded in social media communities of their users. Therefore,
technical decisions that impact socialibilty can be decisive
\parencite{SocioPLT}. These include:

\begin{itemize}
\tightlist
\item
  Compatibility: easy integration into standard technology stacks,
  allowing incremental adoption, and also easy exit if needed. This
  dynamic was discussed in the classic essay \emph{Worse is Better}
  \parencite{WIB} about how UNIX beat Lisp.
\item
  Developing with an open source methodology reaps volunteer labor and
  fosters a user community of enthusiasts. The technical advantages of
  open source development were first popularised in the essay \emph{The
  Cathedral and the Bazaar} \parencite{Cathedral}, which observed that
  ``given enough eyeballs, all bugs are shallow''. Open source has
  become the standard for software development tools, even those
  developed within large corporations.
\item
  Easy sharing of code via package repositories or open exchanges. Prior
  to the open-source era, commercial marketplaces were important, like
  VBX components for VisualBasic. Sharing is impeded when languages lack
  standard libraries, leading to competing dialects, like Scheme
  \parencite{LispCurse}.
\item
  Dedicated social media communities can be fostered by using them to
  provide technical support. Volunteer technical support, like volunteer
  code contributions, can multiply the impact of core developers. In
  some cases, social media like Stack Exchange has even come to replace
  documentation.
\end{itemize}

One could argue that socialibilty is not purely a \emph{technical}
dimension, as it includes aspects of product management. Rather, we
believe that sociability is a pervasive cross-cutting concern that
cannot be \emph{separated} from the technical.

The tenor of the online community around a programming system can be its
most public attribute. Even before social media, Flash developed a
vibrant community of amateurs sharing code and tips. The Elm language
invested much effort in creating a welcoming community from the outset
\parencite{WhatIsSuccess}. Attempts to reform older communities have
introduced Codes of Conduct, but not without controversy.

On the other hand, a cloistered community that turns its back on the
wider world can give its members strong feelings of belonging and
purpose. Examples are Smalltalk, Racket, Clojure, and Haskell. These
communities bear some resemblance to cults, with guru-like leaders, and
fierce group cohesion.

The economic sustainability of a programming system can be even more
important than strictly social and technical issues. Adopting a
technology is a costly investment in terms of time, money, and foregone
opportunities. Everyone feels safer investing in a technology backed by
large corporations that are not going away, or in technologies that have
such widespread adoption that they are guaranteed to persist. A vibrant
and mature open-source community backing a technology also makes it
safer.

Unfortunately, sociability is often in conflict with learnability.
Compatibility leads to ever increasing historical baggage for new
learners to master. Large internet corporations have invested mainly in
technologies relevant to their expert staff and high-end needs.
Open-source communities have mainly flourished around technologies for
expert programmers ``scratching their own itch''. While there has been a
flow of venture funding into ``no-code'' and ``low-code'' programming
systems, it is not clear how they can become economically and socially
sustainable. By and large, the internet era has seen the ascendancy of
expert programmers and the eclipsing of programming systems for ``the
rest of us''.
 
\hypertarget{evaluating-the-dark-programming-system}{\section{Evaluating the Dark Programming
System}\label{evaluating-the-dark-programming-system}}

This section demonstrates using the framework to analyse the recent
programming system \emph{Dark}~\parencite{DarkWeb}, explaining how it
relates to past work and how it contributes to the state of the art.

Dark is a programming system for building ``serverless backends'',
i.e.~services that are used by web and mobile applications. It aims to
make building such services easier by ``removing accidental
complexity''\footnote{\url{https://roadmap.darklang.com/goals-of-dark-v2.html}}
resulting from the large number of systems typically involved in their
deployment and operation. This includes infrastructure for
orchestration, scaling, logging, monitoring and versioning. Dark
provides integrated tooling (Figure~\ref{fig:dark}) for development and
is described as \emph{deployless}, meaning that deploying code to
production is instantaneous.

\begin{figure}
  \centering
  \includegraphics[width=1\linewidth]{dark-annotated.png}
  \caption[A simple Web service in Dark]{A simple web service in Dark consisting of two HTTP endpoints (1, 2), a database (3), and a worker (4).\label{fig:dark}}
  \note{FROM https://medium.com/@wilk/dark-lang-an-uncommon-step-towards-the-future-of-programming-921cf7f38baf}
\end{figure}

Dark illustrates the need for the broader perspective of programming
systems. Of course, it contains a programming language, which is
inspired by OCaml and F\#. But Dark's distinguishing feature is that it
eliminates the many secondary systems needed for deployment of modern
cloud-based services. Those exist outside of a typical programming
language, yet form a major part of the complexity of the overall
development process.

With technical dimensions, we can go beyond the ``sales pitch'', look
behind the scenes, and better understand the interesting technical
aspects of Dark as a programming system. Tables~\ref{tab:dark1}
and~\ref{tab:dark2} summarise the more detailed analysis that follows.

\newcommand{\wrap}[1]{\parbox[t]{5.6cm}{#1}}
\renewcommand{\arraystretch}{1.3}

\begin{table}
\centering
\caption[Dark dimensions summary]{Summary of where Dark lies on some of the dimensions.}
\begin{tabular}{ >{\raggedleft\arraybackslash}p{3.6cm} p{5.6cm}}
\hline
Dimension (CLUSTER) & Summary \\ 
\hline\hline
INTERACTION \\
Modes of Interaction & 
\parbox[t]{5.6cm}{Single integrated mode comprises development, debugging and operation ("deployless")} \\
Feedback Loops & \parbox[t]{5.6cm}{Code editing is triggered either by user or by unsupported HTTP request and changes are deployed automatically, allowing for \emph{immediate feedback}}\\
\hline
ERRORS  \\
Error Response & \parbox[t]{5.6cm}{When an unsupported HTTP request is received, programmer can write handler code using data from the request in the process}\\
\hline
CONCEPTUAL STRUCTURE    \\
Conceptual Integrity vs. Openness & \parbox[t]{5.6cm}{Abstractions at the domain specific high-level and the functional low-level are both carefully designed for conceptual integrity.}\\
Composability & \parbox[t]{5.6cm}{
User applications are composed from high-level primitives; the low-level uses composable functional abstractions (records, pipelines).}\\
Convenience & \parbox[t]{5.6cm}{Powerful high-level domain-specific abstractions are provided (HTTP, database, workers); core functional libraries exist for the low-level.} \\
\hline
ADOPTABILITY \\
Learnability & \parbox[t]{5.6cm}{High-level concepts will be immediately familiar to the target audience; low-level language has the usual learning curve of basic functional programming}\\
\end{tabular}
\label{tab:dark1}
\end{table}

\begin{table}
\centering
\caption[Dark dimensions summary]{Summary of where Dark lies on some of the dimensions.}
\begin{tabular}{ >{\raggedleft\arraybackslash}p{3.6cm} p{5.6cm}}
\hline
Dimension (CLUSTER) & Summary \\ 
\hline\hline
NOTATION    \\
Notational Structure & \parbox[t]{5.6cm}{Graphical notation for high-level concepts is complemented by structure editor for low-level code} \\
Uniformity & \parbox[t]{5.6cm}{Common notational structures are used for database and code, enabling the same editing construct for sequential structures (records, pipelines, tables)}\\
\hline
COMPLEXITY  \\
Factoring of Complexity & \parbox[t]{5.6cm}{Cloud infrastructure (deployment, orchestration, etc.) is provided by the Dark platform that is invisible to the programmer, but also cannot be modified}\\
Level of Automation & \parbox[t]{5.6cm}{Current implementation provides basic infrastructure, but a higher degree of automation in the platform can be provided in the future, e.g. for scalability} \\
\hline
CUSTOMISABILITY\\   
Staging of Customisation & \parbox[t]{5.6cm}{System can be modified while running and changes are persisted, but they have to be made in the Dark editor, which is distinct from the running service}
\end{tabular}
\label{tab:dark2}
\end{table}

\hypertarget{dimensional-analysis-of-dark}{\subsubsection{Dimensional analysis of
Dark}\label{dimensional-analysis-of-dark}}

\paragraph{Modes of interaction and feedback loops.}

Conventional \emph{modes of interaction}
(\ref{dimension-modes-of-interaction}) include running, editing and
debugging. For modern web services, running refers to operation in a
cloud-based environment that typically comes with further kinds of
feedback (logging and monitoring). The key design decision of Dark is to
integrate all these different modes of interaction into a single one.
This tight integration allows Dark to provide a more immediate
\emph{feedback loop} (\ref{dimension-feedback-loops}) where code changes
become immediately available not just to the developer, but also to
external users. The integrated mode of interaction is reminiscent of the
image-based environment in Smalltalk; Dark advances the state of art by
using this model in a multi-user, cloud-based context.

\paragraph{Feedback loops and error response.}

The integration of development and operation also makes it possible to
use \emph{errors} occurring during operation to drive development.
Specifically, when a Dark service receives a request that is not
supported, the user can build a handler~\parencite{DarkErrors} to
provide a response---taking advantage of the live data that was sent as
part of the request. In terms of our dimensions, this is a kind of
\emph{error response} (\ref{dimension-error-response}) that was
pioneered by the PILOT system for Lisp~\parencite{Pilot}. Dark does this
not just to respond to errors, but also as the primary development
mechanism, which we might call \emph{Error-Driven Development.} This
way, Dark users can construct programs with respect to sample input
values.

\paragraph{Conceptual structure and learnability.}

Dark programs are expressed using high-level concepts that are specific
to the domain of server-side web programming: HTTP request handlers,
databases, workers and scheduled jobs. These are designed to reduce
accidental complexity and aim for high \emph{conceptual integrity}
(\ref{dimension-conceptual-integrity-vs.-openness}). At the level of
code, Dark uses a general-purpose functional language that emphasises
certain concepts, especially records and pipelines. The high-level
concepts contribute to \emph{learnability}
(\ref{dimension-learnability}) of the system, because they are highly
domain-specific and will already be familiar to its intended users.

\paragraph{Notational structure and uniformity.}

Dark uses a combination of graphical editor and code. The two aspects of
the notation follow the \emph{complementing notations}
(\ref{dimension-notational-structure}) pattern. The windowed interface
is used to work with the high-level concepts and code is used for
working with low-level concepts. At the high level, code is structured
in freely positionable boxes on a 2D surface. Unlike
Boxer~\parencite{Boxer}, these boxes do not nest and the space cannot be
used for other content (say, for comments, architectural illustrations
or other media). Code at the low level is manipulated using a
syntax-aware structure editor, showing inferred types and computed live
values for pure functions. It also provides special editing support for
records and pipelines, allowing users to add fields and steps
respectively.

\paragraph{Factoring of complexity and automation.}

One of the advertised goals of Dark is to remove accidental complexity.
This is achieved by collapsing the heterogeneous stack of technologies
that are typically required for development, cloud deployment,
orchestration and operation. Dark hides this via \emph{factoring of
complexity} (\ref{dimension-factoring-of-complexity}). The advanced
infrastructure is provided by the Dark platform and is hidden from the
user. The infrastructure is programmed explicitly and there is no need
for sophisticated automation (\ref{dimension-level-of-automation}). This
factoring of functionality that was previously coded manually follows a
similar pattern as the development of garbage collection in high-level
programming languages.

\paragraph{Customisability.}

The Dark platform makes a clear distinction between the platform itself
and the user application, so \emph{self-sustainability}
(\ref{dimension-self-sustainability}) is not an objective. The strict
division between the platform and user (related to its aforementioned
\emph{factoring of complexity}) means that changes to Dark require
modifying the platform source code itself, which is available under a
license that solely allows using it for the purpose of contributing.
Similarly, applications themselves are developed by modifying and adding
code, requiring destructive access to it---so \emph{additive authoring}
(Section \ref{dimension-addressing-and-externalisability}) is not
exhibited at either level. Thanks to the integration of execution and
development, persistent changes may be made during execution (c.f.
\emph{staging of customisation},
Section~\ref{dimension-staging-of-customisation}) but this is done
through the Dark editor, which is separate from the running service.

\hypertarget{technical-innovations-of-dark}{\subsubsection{Technical innovations of
Dark}\label{technical-innovations-of-dark}}

This analysis reveals a number of interesting aspects of the Dark
programming system. The first is the tight integration of different
\emph{modes of interaction} which collapses a heterogeneous stack of
technologies, makes Dark \emph{learnable}, and allows quick feedback
from deployed services. The second is the use of \emph{error response}
to guide the development of HTTP handlers. Thanks to the technical
dimensions framework, each of these can be more precisely described. It
is also possible to see how they may be supported in other programming
systems. The framework also points to possible alternatives (and perhaps
improvements) such as building a more self-sustainable system that has
similar characteristics to Dark, but allows greater flexibility in
modifying the platform from within itself.
\clearpage{}
\cleardoublepage\clearpage{}\defbibheading{bibintoc}[\bibname]{\phantomsection
  \manualmark
  \markboth{\spacedlowsmallcaps{#1}}{\spacedlowsmallcaps{#1}}\addtocontents{toc}{\protect\vspace{\beforebibskip}}\addcontentsline{toc}{chapter}{\tocEntry{#1}}\chapter*{#1}}
\printbibliography[heading=bibintoc]

\clearpage{}
\cleardoublepage\clearpage{}\pagestyle{empty}

\hfill

\vfill


\pdfbookmark[0]{Colophon}{colophon}
\section*{Colophon}
This document was typeset using the typographical look-and-feel \texttt{classicthesis} developed by Andr\'e Miede and Ivo Pletikosić.
The style was inspired by Robert Bringhurst's seminal book on typography ``\emph{The Elements of Typographic Style}''.
\texttt{classicthesis} is available for both \LaTeX\ and \mLyX:
\begin{center}
\url{https://bitbucket.org/amiede/classicthesis/}
\end{center}
Happy users of \texttt{classicthesis} usually send a real postcard to the author, a collection of postcards received so far is featured here:
\begin{center}
\url{http://postcards.miede.de/}
\end{center}
Thank you very much for your feedback and contribution.

\bigskip

\noindent\finalVersionString



\clearpage{}
\end{document}
