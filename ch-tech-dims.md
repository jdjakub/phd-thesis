\hypertarget{tech-dims}{%
\chapter{Technical Dimensions of Programming Systems}\label{tech-dims}}

We introduced the concept of a *programming system* in Section\ \ref{programming-systems-vs-languages}. Not only is such a concept necessary for framing our work in Chapter\ \ref{bl}, there is also a growing interest in programming systems in both research and industry. Yet while programming *languages* are a well-established concept, analysed and compared with a common vocabulary, no similar foundation exists for the wider range of programming *systems.* In this chapter,^[Adapted from our paper for Programming 2023\ \parencite{TechDims}.] we will examine this problem and propose a framework of "Technical Dimensions" to kickstart systematic research on programming systems. We will then make our Three Properties (Section\ \ref{the-three-properties}) more precise as sets of dimensions under this framework. We will then use these dimensions to assess how BootstrapLab fulfils the Three Properties and evaluate it on that basis.^[It might seem appropriate to also perform an evaluation via the Cognitive Dimensions of Notation\ \parencite{CogDims}. However, this would not actually tell us anything interesting; the novel contribution of this system is not its notation. The interface is minimal and unpolished for reasons of expediency. The point is not that we have come up with a new notation or UI that will improve programming; the notation is something that each user should fit to themselves according to subjective preference. The important goal is that the system *supports* the usage of different notations for different contexts. Notations in BootstrapLab should be a free parameter, so it does not make sense to apply Cognitive Dimensions to BootstrapLab *itself*, and it does not provide any value to analyse the placeholder interface in this way.] 

# Barriers to Programming Systems Research
Researchers are studying topics such as *programming experience*\ \parencite{PX} and *live programming*\ \parencite{LIVE} that require considering not just the *language*, but further aspects of a given system. At the same time, companies are building new programming environments like Replit\ \parencite{ReplitWeb} or "low-code" tools like Dark\ \parencite{DarkWeb} and Glide\ \parencite{GlideWeb}.

However, the academic research on programming suffers from a lack of common vocabulary. While we may thoroughly assess programming *languages*, as soon as we add interaction or graphics into the picture, evaluation beyond subjective "coolness" becomes fraught with difficulty.^[The same difficulty in the context of user interface systems has been analysed by\ \textcite{EvUISR}. Interesting future work would be a detailed analysis of publications on programming systems to understand this issue in depth. One notable characteristic is that publications tend to present (parts of) new systems. This is the case for 5/6 and 6/7 papers in the LIVE 2020 and 2021 workshops respectively\ \parencite{LIVE20, LIVE21}. In contrast, publications in the field of programming *languages* often address specific issues of interest to a greater number of languages.] Comparisons make the most sense when comparing "like for like", yet graphical programming systems may be so varied that it is unclear what the stable points of comparison should be. Moreover, when designing new systems, inspiration is often drawn from the same few standalone sources of ideas. These might be influential past systems like Smalltalk, programmable end-user applications like spreadsheets, or motivational illustrations like those of\ \textcite{BretVictor}.

Instead of forming a solid body of work, the ideas that emerge are difficult to relate to each other. The research methods used to study programming *systems* lack the rigorous structure of programming *language* research methods. They tend to rely on singleton examples, which demonstrate their author's ideas, but are inadequate methods for comparing new ideas with the work of others. This makes it hard to build on top and thereby advance the state of the art.

Studying *programming systems* is not merely about taking a programming language and looking at the tools that surround it. It presents a *paradigm shift*\ \parencite{Kuhn} to a perspective that is  *incommensurable* with that of languages. When studying programming languages, what matters is in the program code; when studying programming systems, what matters is in the behaviour of the system. As documented by \textcite{PLrev}, looking at a *system* from a *language* perspective makes it impossible to think about concepts that arise from interaction with a system which are not reflected in the language.

# Our Proposal
We propose a common language as an initial step towards more progressive research on programming systems. Our set of *technical dimensions* seeks to break down the holistic view of systems along various specific "axes". The dimensions identify a range of possible design choices, characterised by two extreme points in the design space. They are not fully quantitative, but they do allow comparison by locating systems on a common axis. We do not intend for the extreme points to represent "good" or "bad" designs; we expect any position to be a result of design trade-offs. At this early stage in the life of such a framework, we encourage agreement on descriptions of systems first in order to settle any normative judgements later.

The set of dimensions can be understood as a map of the design space of programming systems. Past and present systems will serve as landmarks, and with enough of them, we may reveal unexplored or overlooked possibilities. In the absence of such a map, the field has not been able to establish a virtuous cycle of feedback; it is hard for practitioners to situate their work in the context of others' so that subsequent work can improve on it. Our aim is to provide foundations for the study of programming systems that would allow such development.

In short, while there is a theory for programming languages, programming *systems* deserve a theory too. It should apply from the vast scale of operating systems to the comparatively small scale of language implementations. It should be possible to analyse the common and unique features of different systems, to reveal new possibilities, and to build on past work in an effective manner. In Kuhnian terms\ \parencite{Kuhn}, it should enable a body of "normal science": filling in the map of the space of possible systems\ \joel{(Figure \ref{fig:tech-dims-diagram})}, thereby forming a knowledge repository for future designers.

\joel{CORRECTIONS NOTE: INCLUDE TECH DIMS DIAGRAM PICTURE FILE!!!}

We will develop *self-sustainability,* *notational freedom,* and *explicit structure* as Technical Dimensions, following on from the discussion in Section\ \ref{the-three-properties-in-more-detail}. For each one, we will give examples that illustrate the range of values it spans. Then we will apply them to BootstrapLab. The rest of our extensive catalogue of dimensions can be found in Appendix\ \ref{appendix-all-dims}, organised into related clusters: *interaction*, *notation*, *conceptual structure*, *customisability*, *complexity*, *errors*, and *adoptability*.

# Dimensions, Qualitative and Quantitative
There is a problem where the most easily *measurable* properties are not necessarily very interesting, while the interesting properties are not straightforwardly measurable. We have discussed our Three Properties intuitively and qualitatively in Chapters\ \ref{background} and\ \ref{analysis}. However, as they stand there is too much ambiguity for anything resembling an objective, plausible consensus on how much they are present in a given system. Therefore, in the next section we will break them down into narrower dimensions that we can apply for evaluating BootstrapLab. A few of these will be boolean (asking whether something is possible or present in a system) but most will be quantitative *penalty* dimensions. This means that maximising the value of one of our Three Properties (\eg{} Self-Sustainability) will correspond to *minimising* its constituent penalty dimensions.

## How We Define and Apply the Dimensions
We say a penalty dimension is "quantitative" in that its definition intuitively describes an amount of which there can be more or less, even if we leave the question of how to actually measure it numerically as future work. We do not have the scope to compare the various ways these quantities could be defined for measurement, and it would be misguided to pick one simply for the sake of having numbers. Where a relevant quantity does already exist (\eg{} lines of code) we may propose it as a measure for the dimension. Otherwise, we will use a variation on the Likert scale used in psychology\ \parencite{Likert}. Instead of "strongly agree" to "strongly disagree", we will assign the scores "minimal", "low", "moderate", "high" and "infinite".

With such a scale, it would be possible to rigorously measure a system against the dimensions by means of a questionnaire and analysing the distribution of responses (expecting consensus around a single score, and perhaps re-working the dimensions for which this is not the case). However, such an approach is beyond the scope of this work. Instead, when we apply these dimensions to evaluate BootstrapLab in Chapter\ \ref{bl}, we will give our own personal assessment of each score along with its justification. We think that the narrow focus of the dimensions makes it likely that such judgements would be aligned with those of the reader. Even in the case of serious disagreement, this narrow focus would make it easier to productively reach agreement in a way that would be much harder for the complex, qualitative definitions of the Three Properties from which they derive (Section\ \ref{the-three-properties-in-more-detail}). Therefore, while we agree that giving our personal assessment in terms of the Three Properties directly would be hard to judge objectively, we believe that doing so on the finer scale of the dimensions is appropriate. Further discussion of these issues and suggestions for future work will be found in Section\ \ref{improving-the-technical-dimensions}.

## Aggregation and Simplification
It is worth noting that even once we have broken down a high-level concept into several low-level dimensions, the high-level concept can still be considered a *dimension* if we define some suitable aggregation of the scores of its constituent dimensions (this could be a simple sum, a weighted average, or something more sophisticated). We will not practice this, but it is worth keeping in mind as we encounter complications and decide how to respond to them.

For example, it might be objected that a dimension cannot simply apply to a system as a whole, but actually takes different scores for different *parts* of a system. We can answer this objection with an interpretation of the dimension as precisely such an aggregate of its application across different parts of the system. Ultimately, programming systems are complex and any property we speak of may apply at multiple levels. For practical purposes including those of our evaluation of BootstrapLab, we must make simplifications and apply our dimensions to an entire system as best we can. Later in Section\ \ref{improving-the-technical-dimensions}, we will return to the complexities we have elided here.

# The Three Properties as Dimensions
We will now proceed to break down each of our Three Properties into dimensions (or, in the boolean case, "criteria", but we will stick to the general term).

## Dimensions Constituting Self-Sustainability
In light of the points in Section\ \ref{self-sustainability}, we can discover some key dimensions of self-sustainability with the help of an existing programming system that is not self-sustainable. Using the terminology from Section\ \ref{user-vs.-implementation-levels}, let us cast the *Web browser* as the *product system* (\ie{} that which we wish to make self-sustainable) and C++ as the *platform* (\ie{} the system we use to implement the product). What would it take to make the browser self-sustainable? 

### Minimise The Substrate Size
Recall from Section\ \ref{platforms-and-substrates} that the *substrate* is the portion of the product system not accessible from its user level. In the case of the web browser, it is the C++ code constituting its implementation. To get a self-sustainable system, the substrate must be minimised by shifting implementation out of it and into the programming capabilities of the product system. In this case, most of the named entities in the C++ code are stuck at the implementation level, inaccessible at the user level of \ac{JS}, so we must move the former into the latter.

To sketch how this process could be carried out systematically, we can begin with the graphical surface of the product system. For each graphical element, we inquire into the causes of its display; this will include graphical rendering code, but also the data that is being rendered and the code that generated it. By tracing backwards in this way we discover the web of causes that produced the shape on the screen. This will often go through the user level (\ac{JS}), but if we keep tracing back, we will hit the implementation level. Each time this happens, we port the code from the implementation level to the user level.

We continue this until it is no longer feasible; for example, there will ultimately have to be some native machine-code interpreter for \ac{JS} in the running system. In practice, there would need to be the usual investments in JIT compilation and optimisation technology as seen in VMs for Smalltalk and other languages.

These ideas suggest a dimension of *substrate size* as a penalty for self-sustainability. In other words, a self-sustainable system minimises this dimension. We already compared the strategies of doing this minimisation earlier or later in Section\ \ref{the-major-design-conflict}. A reasonable measure of substrate size does exist as the number of lines of code that implement it, so we will use this measure in our evaluations later. 

### Minimise Persistence Effort to Fix "Delete By Default"
As we discussed from Section\ \ref{assumptions-and-consequences-in-batch-mode} onward, the activities of a running process under Unix are considered disposable. In order for a system to be self-sustainable, it has to be able to preserve developments of its state through process termination. The standard VM solution is to have most of the system state saved in an "image" file and concentrate the substrate in a runnable binary that need not be changed. However this is accomplished, *persistence* of run-time changes is necessary to encourage indefinite evolution of the system. This applies to the whole browser, but could also be a concern for individual tabs or web pages that can be closed or refreshed.

This suggests another penalty dimension of *persistence effort.* To illustrate the range of values, we offer the following examples:

* Any system which automatically persists to an "image" (Lisp, Smalltalk) or otherwise (Webstrates;\ \cite{Webstrates}) causes *minimal* persistence effort on the part of the user.^[Arguably, this effort is zero, since the user does not have to think about it. However, we will stick to the term "minimal" for consistency with our stated scoring terminology.]
* A system with a manual "save" button that persists all state would have almost-minimal persistence effort. This comprises both the need to remember to save and the act of pressing the button.
* A system where one must repeat a manual procedure over different parts of the state to persist all of it would have *moderate* persistence effort.
* A typical programming language in a "vanilla" state (\eg{} excluding third-party libraries) has *high* persistence effort for its runtime data structures, owing to the "Delete By Default" policy of the Unix Paradigm (Section\ \ref{the-unix-paradigm}). With the use of a specific third-party library or framework (such as an Object-Relational Mapper) this persistence effort may be reduced. In the absence of such a framework, the programmer would have a lot of work to do in order to persist all state (wrap every variable and stack frame in code for loading and saving its value).
* We could ascribe *infinite*^[An infinite score can be interpreted as saying: it would take less effort to duplicate the source code of the system and add persistence at its implementation level, than it would to persist state using user-level functionality.] persistence effort where it is impossible to persist state. This is easier to imagine in the case of an end-user application with no scripting capability; if the developers failed to persist something (\eg{} the position or sizing of a window) then the user cannot do anything about it. In the case of a programming system, hard barriers to persistence include inaccessible state (\eg{} in \ac{JS}, one cannot refer to stack frames or read their state) or a lack of enumerability (\eg{} there is no way to traverse all objects in the system and thereby persist them).

It may be objected that this measure should be considered on a piecemeal basis *per piece of state* instead of on the system as a whole. For example, a system could have infinite persistence effort with respect to some state (\eg{} stack frames;\ \cite{Externalize}) but low persistence effort with respect to everything else (this being the effort invested to set up an Object-Relational Mapper for the rest of the state). As mentioned in Section\ \ref{aggregation-and-simplification}, given such a fine-grained application of this measure and a method of weighting each contribution, we could derive a convenient aggregate measure of persistence effort for the whole system. However, this is too complicated for the scope of our work here, so we will give an overall impression of the property without systematically going into finer detail.

### Support Code Viewing and Editing
The browser's \ac{JS} console makes it possible to make some changes expressible as \ac{JS} commands, modulo the caveats in Section\ \ref{web-pages-web-apps-and-browsers}; these would need mitigating. The source code can be viewed but not edited; we would need to make a small change so that the source code viewer could also be used to make persistent edits to code. These points suggest boolean dimensions of *code viewing* and *code editing.* An example of a system that has both is Smalltalk with its class browser.

### Support the Manipulation of Code as Data
Once we can type text inside the system, we will be able to write code. However, this code will be inert unless the system can interpret data structures as programs and actually execute them. This is the case whether these data structures were created manually or by a program. If this is not possible, re-programming the system will not be possible (beyond selecting from a predefined list of behaviours). The browser does already satisfy this criterion since \ac{JS} has an `eval()` function that can execute a string of \ac{JS} code. This suggests a boolean dimension of *data execution.*

Any system with an `eval` function has this property, such as Lisp. In the low-level binary world (Section\ \ref{the-low-level-binary-world}) the fact that the *instruction pointer* can be pointed at bytes in memory and interpret them as instructions also qualifies. A negative example exists in a language like C, where there is no `eval` function. In such a case, one may employ the workaround of defining a mini-language (whether textual, or a binary bytecode) and an interpreter C function. It is important to be clear on which level the property would be thus established: what we called the *product system* (the program being implemented by the C code) would have data execution but the *platform* (the C language itself) would remain without it.

\joel{
1. *Can you add new items to system namespaces without a restart?* The canonical example of this is in JavaScript, where "built-in" classes like `Array` or `Object` can be augmented at will (and destructively modified, but that would be a separate point). Concretely, if a user wishes to make a new `sum` operation available to all Arrays, they are not *prevented* from straightforwardly adding the method to the Array prototype as if it were just an ordinary object (which it is). Having to re-compile or even restart the system would mean that this cannot be meaningfully achieved from within the system. Conversely, being able to do this means that even "built-in" namespaces are modifiable by ordinary programs, which indicates less of a implementation level vs. user level divide and seems important for self-sustainability.
2. *Can programs generate programs and execute them?* This property, related to "code as data" or the presence of an `eval()` function, is a key requirement of self-sustainability. Otherwise, re-programming the system, beyond selecting from a predefined list of behaviors, will require editing an external representation and restarting it. If users can type text inside the system then they will be able to write code---yet this code will be inert unless the system can interpret internal data structures as programs and actually execute them.
3. *Are changes persistent enough to encourage indefinite evolution?* If initial tinkering or later progress can be reset by accidentally closing a window, or preserved only through a convoluted process, then this discourages any long-term improvement of a system from within. For example, when developing a JavaScript application with web browser developer tools, it is possible to run arbitrary JavaScript in the console, yet these changes apply only to the running instance. After tinkering in the console with the advantage of concrete system state, one must still go back to the source code file and make the corresponding changes manually. When the page is refreshed to load the updated code, it starts from a fresh initial state. This means it is not worth using the *running* system for any programming beyond tinkering.
4. *Can you reprogram low-level infrastructure within the running system?* This is a hopefully faithful summary of how the COLAs work aims to go beyond Lisp and Smalltalk in this dimension.
5. *Can the user interface be arbitrarily changed from within the system?* Whether classed as "low-level infrastructure" or not, the visual and interactive aspects of a system are a significant part of it. As such, they need to be as open to re-programming as any other part of it to classify as truly self-sustainable.}

## Dimensions Constituting Notational Freedom
In Section\ \ref{notational-freedom} we mentioned the salient stages prior to notational freedom, namely syntactic and linguistic freedom. Recall that *syntactic* freedom involves specifying grammars for textual languages, while *linguistic* freedom adds custom layout, rendering and editing of textual symbols. In Section\ \ref{what-it-means-to-support-local-notations} we framed the issue as one of *removing* artificial barriers to using local notations, while respecting the essential complexity of implementing a notation itself. This suggests three penalty dimensions for the effort involved in using custom syntax, linguistic forms, and general graphical notations. One complication is that we defined these stages as successive generalisations, \ie{} notational freedom includes and implies linguistic freedom which includes syntactic freedom. It would not be very helpful to observe that a system has high syntactic freedom and then claim this gives it high linguistic freedom by virtue of the former being contained within the latter. That is not quite what we intend by the term "linguistic freedom". Instead, we would be concerned with linguistic freedom *above* the syntactic and notational freedom *above* the linguistic.

Therefore, our dimensions (all penalties) are as follows. They are minimised if a custom syntax, language, or notation can be "slotted in" once it exists, with no resistance from the system:

\paragraph{Custom Syntax Effort.} The work required to use a custom syntax, not counting that required to specify the syntax itself (\eg{} as a grammar). \ac{COLA}\ \parencite{COLAs} and OMeta\ \parencite{OMeta} score low on this, since they are specifically designed for this purpose. Most programming languages have *infinite* custom syntax effort, because their parsers are separate programs that adhere to a fixed grammar that cannot be changed by statements in the language. This includes \ac{JS} despite its inclusion of a regex sub-syntax, HTML despite its inclusion of \ac{JS} and CSS, and C# despite its LINQ sub-language for queries; these examples may exhibit syntactic *plurality*, but there is no way to include a user-supplied syntax for use in the source code.

\paragraph{Custom Language Effort.} The work required to use custom language-like notation beyond syntax, not counting that required to implement the rendering and interaction. Most programming languages, \ac{COLA}, and OMeta get an infinite score here, while MPS\ \parencite{MPS} and Eco score low.

\paragraph{Custom Notation Effort.} The work required to use custom graphical notation beyond what we called language in Section\ \ref{linguistic-freedom}, not counting that required to implement the rendering and interaction. Only Eco, owing to a screenshot showing inclusion of a picture, scores non-infinite on this dimension. From their discussion in Section\ 9.2 of the paper\ \parencite{Eco}, it is likely to score High or Moderate rather than Low because arbitrary graphical notations are a novel unexplored use case for the system for which it has not been optimised.

\joel{
Consider the Web browser again; what would it take to achieve notational freedom in its JavaScript editor?

1. Again, we see that it does not yet satisfy the more modest condition of *syntactic freedom*. To achieve this, it would need to support *mood-specific languages* (see Section\ \ref{colas} below.) This means it would need some way of accepting user-supplied grammars (*Custom Grammars*) and some way of detecting which should be used for different parts of the source code (*Grammar Map.*) This latter task is made particularly troublesome because of a reliance on Implicit Structure (see Section\ \ref{explicit-structure}.)
2. *Even if* we get this syntactic freedom, we probably still have to force everything to fit in monospaced ASCII (or perhaps Unicode, as we see in the Nile/Gezira projects \parencite{Nile,Gezira}.) We still do not have full *linguistic freedom,* whereby we could, for example, render mathematics with the proper layout and formatting (as this does not quite fit into a horizontal list of non-overlapping characters.) This may require a leap from specifying grammars (which describe legal symbol sequences) to interfaces (how input causes shapes to appear, and how these are rendered.) Call these *Custom Interfaces* and *Interface Map.*
3. Once we have such infrastructure in place, it is not so small a step to generalise these interfaces to things that need not resemble a language (\eg{} a colour picker.) This gives us full *notational freedom.*

1. *Are there multiple syntaxes for textual notation?* Obviously, having more than one textual notation should count for notational diversity. However, for this dimension we want to take into account notations beyond the strictly textual, so we do not want this to be the only relevant question. Ideally, things should be weighted so that having a wide diversity of notations within some *narrow class* is not mistaken for notational diversity in a more global sense. We want to reflect that Unix, with its vast array of different languages for different situations, can never be as notationally diverse as a system with many languages *and* many graphical notations, for example.
2. *Does the system make use of GUI elements?* This is a focused class of non-textual notations that many of our example systems exhibit.
3. *Is it possible to view and edit data as tree structures?* Tree structures are extremely common in programming, but they are usually worked with as text in some way. A few of our examples provide a graphical notation for this common data structure, so this is one way they can be differentiated from the rest.
4. *Does the system allow freeform arrangement and sizing of data items?* We still felt Boxer and spreadsheets exhibited something not covered by the previous three questions, which is this. Within their respective constraints of rendering trees as nested boxes and single-level grids, they both provide for notational variation that can be useful to the user's context. These systems *could* have decided to keep boxes neatly placed or cells all the same size, but the fact that they allow these to vary scores an additional point for notational diversity.
}

## Dimensions Constituting Explicit Structure
The best way we have found to detect Explicit Structure is as a lack of Implicit Structure, which we break down into *producer* and *consumer* concerns. On the producer side, we have an editor with an interface creating and changing a data structure. This is saved and passed onto consumers, which can be collaborators using editors or a programmer writing code to use the data structure.

It is tempting to define Implicit Structure in terms of the producer's editing interface: a text editor has lots of it, while a structured or projectional editor lacks it. But this is incompatible with our desire for Notational Freedom; if someone wishes to use a text editor *interface* to type their data structures into existence, they should be free to do so.

Equally tempting is to locate Implicit Structure in the interchange file format, such as whether it is a text file. Yet as long as the system handles the loading and saving for this file format, it makes no difference from a consumer's point of view and they do not *experience* the downsides associated with Implicit Structure.

So if Implicit Structure is not about the interface, or how the data is really stored, what is it? The definition we are interested in is about how much users or programmers must be *aware* of it and devote cognitive resources to working with it. On the producer side, this manifests as which types of syntax errors or more general *format* errors they are able to save and pass on to consumers (Section\ \ref{precursors-of-explicit-structure}). On the consumer side, Implicit Structure is revealed by the amount of code we have to write to deal with parsing, serialising, escaping, loading and saving, and so on. Therefore we declare two penalty dimensions:

\paragraph{Format errors.} How many different types of format errors can be introduced, saved as invalid structures, and passed to consumers, such that they will halt with an error? For example, text editors allow all possible syntax errors to be saved and several format errors (\eg{} type mismatches and use of undeclared names). However, a text editor interface that refused to save invalid files could form part of a system with Explicit Structure. Block or structure editors may prevent all format errors from being saved, which would constitute the minimal value of this dimension.

\paragraph{String wrangling effort.} How much code has to be written to convert between Implicit and Explicit Structure? Explicit Structure implies a minimal value for this and would look something like the following:

\begin{lstlisting}[language=JavaScript]
data = load('filename')
\end{lstlisting}

Here, there are zero lines of string wrangling. Only one line, translating between the filesystem and the internal system namespaces, is required to prepare the data structure for use.

If such a `load` function is already present, then users experience no string wrangling effort for the use cases of this function, \ie{} the file formats it supports. If the function does not exist, and a user must write string wrangling code on an ad-hoc basis, this dimension is correspondingly high relative to that format. Suppose the user factors this ad-hoc string wrangling into their *own* implementation of the `load` function; this implementation effort would count towards the dimension, but would pay for itself in the reduced string wrangling effort thereafter; this situation would lie somewhere between the previous two.

These considerations all establish scores for this dimension *relative* to a particular file format or string syntax. These could be aggregated to form a score for a particular program which uses several such formats. However, if we are trying to assess the *programming system* along this dimension, we would have to somehow aggregate across all possible programs one could create with the system, including the various different formats they are likely to include.^[There is a large variety of *existing* data storage formats (\eg{} JSON and XML) and an infinite variety of potential *custom* formats that could be created on an ad-hoc basis (\eg{} chat messages containing special escape sequences).]

Recognising that different programming systems are targeted at different goals and have differing strengths and weaknesses, the possibility space could be refined into all *likely* programs or use cases of the programming system, weighted by the probability of a user of the system wanting to create such a program. This opens up further decisions about this user and whether we should additionally aggregate across possible (or likely) users of the system. We could go further, but we think the complexity is clear; as mentioned in Section\ \ref{dimensions-qualitative-and-quantitative}, we will simply give our judgement about how BootstrapLab as a whole scores on this dimension and leave more sophisticated approaches to future work (Section\ \ref{improving-the-technical-dimensions}).

\joel{
How can we detect explicit structure in a programming system? Consider once again the Web browser. It has two major subdivisions of state: the DOM tree and the JavaScript object graph. For change, it only has those special JavaScript objects known as functions, worked on via the console and the source code view. We can examine these three areas separately:

\paragraph{DOM Tree.} The DOM tree is accessed manually through the Element Inspector and programmatically through JavaScript APIs, but is in both cases largely explicitly structured. The main exception involves the APIs taking HTML strings to create elements, and the initial stage of loading the HTML and JS source files. But once these structures have been recovered and built, much can take place without the intermediary of strings.

The other important exception to this occurs in SVG structures. SVG uses element *attributes* for composite data like matrix transformations, and hence has to store these as strings. For example, a node might have a `transform` of `translate(100,200)`. This means that, in order to move the element 10 units horizontally, the programmer must write code to extract the first co-ordinate as a number, add 10, and render the whole expression back to a string.

Related to attributes, CSS classes are a mixed case; on the one hand, the `style` attribute contains CSS source code, yet the JavaScript API does include properties for accessing this information explicitly.

\paragraph{JSOG.} The JavaScript object graph is also explicitly structured at runtime, while object definitions in the source code are obviously not.

\paragraph{JS Code.} Unlike the other two areas, JavaScript code is not explicitly structured even in the running system. There is a minimal level of structure: namely, the source file is split into Function objects (intervening lines with any side effects have already been executed and are inaccessible.) Beyond this, however, the body of each function is only accessible as a string. The obvious condition to meet here is that the AST should be navigable via some JavaScript API (*AST Access.*) Such a single level of explicit structure is shared with spreadsheets (where any structure within a cell is implicit) and databases (data within a column is implicitly structured.)

It appears that there are two realms in which explicit structure may be sought, corresponding to the Volatility Split: the contents of the source files vs. the content of the running system. Each of these could be further split between State and Change; in the Web browser, State largely has explicit structure in memory, but not on disk, and Change lacks it in both places.

\todo{Unix Files, spreadsheet, database}
}

# Evaluating BootstrapLab
Having finally distilled the Three Properties into Technical Dimensions, we will now apply them to BootstrapLab to gauge how far we succeeded at our goals.

## Measures of Self-Sustainability
\criterion{Substrate Size: 1550 LoC.}
BootstrapLab's homogeneity of state contributes to a smaller substrate than a design where system registers and user data lived in two separate partitions of state. There is deliberately only one system namespace: the state graph rooted at the top-level registers. Some of these names have special functions in the low-level ASM, but otherwise this namespace is free for user additions. These can be added manually in the in-system editor or in code by the primitive `store` instruction.

The present graphical state of the system lives entirely in a special part of the system state: the `scene` tree. Therefore, at any given moment, it is possible to change what the graphics window will display. However, there are two limitations:

1. The range of these changes is constrained to the range of graphical primitives currently understood by the substrate which it passes on to THREE.js. Currently these are limited to axis-aligned flat-coloured rectangles and basic text of a uniform size, style, colour, etc.
2. The behaviour that affects the graphics currently lives in \ac{JS}. This means that the logic according to which the tree editor renders map entries is inaccessible to in-system code.

Indeed, there are about 1550 lines of \ac{JS} off-limits to the actions of the system. At least 33% of this, however, constitutes our substrate debt (Section\ \ref{substrate-debt-in-bootstraplab}): the Masp interpreter and tree editor. In a further-developed version, these could be moved out. Even so, in such a further-developed version, the substrate may be larger anyway by exposing more types of graphical primitives. This suggests that capabilities of the platform provide a lower bound on the substrate size: if the platform provides a way to draw a circle, but the substrate does not expose this to the system, then we have reason to interpret this as an incomplete programming system. On the other hand, the substrate may expose a more general set of graphics operations that allow the system to draw circles itself, say to a pixel surface.

\criterion{Persistence Effort: Moderate.} Part or all of the state graph can be manually persisted via the `export_state()` function in the browser console. This means that in-system progress can be saved, even though it would be better for the user experience to have this done automatically. It is clear that indefinite evolution is *permitted* but perhaps not quite *encouraged*.

\criterion{Code Editing: present.} Code editing is crude but feasible via the in-system tree editor for most use cases. In rare cases, the \ac{JS} console must be used.

\criterion{Data Execution: Present.} Because of Alignment (Force\ \ref{alignment}), low-level instructions that change state are represented as ordinary maps with certain format constraints. The instruction set is sufficient for constructing arbitrary graph structures in the state, including programs composed of instructions. The `next_instruction` register can be pointed at such a list and execution can be started using `run_and_render()` in the \ac{JS} console. The analogous properties hold for high-level Masp code which is also represented as maps.

\paragraph{Verdict.} BootstrapLab's practical capacity to change its implementation is limited by its substrate debt and its manual persistence adds friction to working within the system. Still, there are no hard barriers to self-sustainability.

## Measures of Notational Freedom
\criterion{Custom syntax effort: moderate.} Because of substrate debt, it may not be possible to make changes at the user level such that a string can be "executed" according to custom syntax and semantics via a click or key combination. However, it is possible to use the `js` "escape hatch" instruction to embed arbitrary \ac{JS} code to do the appropriate processing. In the absence of substrate debt, it would be possible to edit the relevant parts of the system to support custom syntaxes---both textual, as strings, but also "structural" with different map structures to those that Masp expects. This direct editing of the system could still be costly, and adopting the techniques in the Lisp half of \ac{COLA} \parencite{OECM} or OMeta \parencite{OMeta} could bring custom syntaxes closer to being "slotted in" without difficulty.

\criterion{Custom language effort: moderate.} This follows similar considerations, except the substrate debt related to graphical capabilities and the lack of exposure of certain platform graphical primitives are also relevant here. However, implementing language-like notations may be aided by the existing layout capabilities of the tree editor.

\criterion{Custom notation effort: moderate.} Again the reasoning is similar, but in this case the tree editor layout capabilities may not be directly helpful. Here, the lack of exposure of platform graphics primitives limits what can be achieved. Still, as shown in Section\ \ref{real-example-colour-preview}, use of custom notations is *feasible* as long as the appropriate "hook point" is available, which we added to the substrate specifically for the proof-of-concept.

\paragraph{Verdict.} BootstrapLab in its current state *permits* notational freedom but at a moderate cost. This is still an improvement on the norm of *infinite* cost in programming systems (recall the examples in Section\ \ref{dimensions-constituting-notational-freedom}).

\joel{
\criterion{Are there multiple syntaxes for textual notation? No.} Only JavaScript syntax is available in the special `js` instruction. However, the system is built on explicit structure, so syntax does not make much of an appearance at all.

\criterion{Does the system make use of GUI elements? Yes.}
BootstrapLab's graphics window is a zoomable/draggable view containing a crude tree editor. Next to it is a rendering of the state tree in ordinary web HTML elements.

\criterion{Is it possible to view and edit data as tree structures? Yes.}
Tree-structured data can be viewed in the HTML-rendered tree view and the in-system tree editor. It can be edited only in the latter.

\criterion{Does the system allow freeform arrangement and sizing of data items? No.}
We did not have enough time to support the moving and resizing of items in the graphics window.

\criterion{Is there support for custom user-supplied notations? Potentially.}
The code for rendering the tree editor and accepting user input currently lives in the substrate. However, we gave a proof-of-concept in\ Section\ref{provide-for-domain-specific-notations} for how this could be moved in-system. Because of this, there is no inherent barrier to custom notations.

\criterion{Is there support for custom user-supplied grammars? Potentially.} Ditto.
}

## Measures of Explicit Structure
\criterion{Format errors: low.} The structure editing interface of the tree editor eliminates the existence of syntax errors for data, Masp code, and instructions. Within these structures, certain format errors are possible (\eg{} failing to supply required arguments to an instruction).

\criterion{String wrangling effort: low.} Because all data, including instructions and Masp code, is embedded in map data structures edited structurally, there is little need for the user to write parsing or serialising code. The sole exceptions are with hexadecimal colour codes, where the initial `#` character may need stripping, and rendered map entries, where the colon `:` needs attaching and stripping. Strings are of course present, but as primitive values without substructure (\eg{} names). 

\paragraph{Verdict.} BootstrapLab succeeds at our goal of being based on explicit structure. All "code" or "language" structures are represented directly instead of as text strings.

# Conclusions
BootstrapLab embodies our Three Properties to a satisfactory extent; it is strongest on Explicit Structure and weaker on Notational Freedom and Self-Sustainability. In a system developed without attention to these properties, the default practices of programming would end up raising barriers to their realisation (Section\ \ref{accidental-complexity-beyond-languages}). We deliberately designed BootstrapLab to support these properties and avoid hard barriers to them, so there is significant potential for improvement from further development efforts. We will outline this future work in\ Section\ \ref{improving-bootstraplab}.

Beyond this dissertation, there is interest in developing new programming systems. Such systems go beyond the simple model of code written in a programming language using a more or less sophisticated text editor. They combine textual and visual notations, create programs through rich graphical interactions, and challenge accepted assumptions about program editing, execution and debugging. Despite the growing number of novel programming systems, it remains difficult to evaluate the design of programming systems and to see how they improve over work done in the past. To address the issue, we proposed a framework of "technical dimensions" that captures essential characteristics of programming systems in a systematic fashion.

This framework puts the vast variety of programming systems, past and present, on a common footing of commensurability. As more and more systems are assessed in the framework, a picture of the space of possibilities will gradually emerge. Some regions will be conspicuously empty, indicating unrealised possibilities that could be worth trying; this is how we regard BootstrapLab. In this way, a domain of "normal science" is created for the design space. Designers of the next generation of programming systems can then build upon the successes and lessons of those that came before.
