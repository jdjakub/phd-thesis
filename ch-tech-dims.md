\hypertarget{tech-dims}{%
\chapter{Technical Dimensions of Programming Systems}\label{tech-dims}}

We introduced the concept of a *programming system* in Section\ \ref{programming-systems-vs-languages}. Not only is such a concept necessary for framing the work in this dissertation, there is also a growing interest in programming systems in both research and industry. Yet while programming *languages* are a well-established concept, analysed and compared with a common vocabulary, no similar foundation exists for the wider range of programming *systems.* In this chapter,^[Adapted from our paper for Programming 2023\ \parencite{TechDims} which won the Editors' Choice Award for the journal.] we will examine this problem and propose a framework of "Technical Dimensions" to kickstart systematic research on programming systems. We will then make our Three Properties (Section\ \ref{the-three-properties}) more precise as sets of dimensions under this framework.

# Barriers to Programming Systems Research
Researchers are studying topics such as *programming experience*\ \parencite{PX} and *live programming*\ \parencite{LIVE} that require considering not just the *language*, but further aspects of a given system. At the same time, companies are building new programming environments like Replit\ \parencite{ReplitWeb} or "low-code" tools like Dark\ \parencite{DarkWeb} and Glide\ \parencite{GlideWeb}.

However, the academic research on programming suffers from a lack of common vocabulary. While we may thoroughly assess programming *languages*, as soon as we add interaction or graphics into the picture, evaluation beyond subjective "coolness" becomes fraught with difficulty.^[The same difficulty in the context of user interface systems has been analysed by Olsen\ \parencite{EvUISR}. Interesting future work would be a detailed analysis of publications on programming systems to understand this issue in depth. One notable characteristic is that publications tend to present (parts of) new systems. This is the case for 5/6 and 6/7 papers in the LIVE 2020 and 2021 workshops respectively\ \parencite{LIVE20, LIVE21}. In contrast, publications in the field of programming *languages* often address specific issues of interest to a greater number of languages.] Comparisons make the most sense when comparing "like for like", yet graphical programming systems may be so varied that it is unclear what the stable points of comparison should be. Moreover, when designing new systems, inspiration is often drawn from the same few standalone sources of ideas. These might be influential past systems like Smalltalk, programmable end-user applications like spreadsheets, or motivational illustrations like those of Bret Victor\ \parencite{BretVictor}.

Instead of forming a solid body of work, the ideas that emerge are difficult to relate to each other. The research methods used to study programming systems lack the rigorous structure of programming language research methods. They tend to rely on singleton examples, which demonstrate their author's ideas, but are inadequate methods for comparing new ideas with the work of others. This makes it hard to build on top and thereby advance the state of the art.

Studying *programming systems* is not merely about taking a programming language and looking at the tools that surround it. It presents a *paradigm shift*\ \parencite{Kuhn} to a perspective that is, at least partly, *incommensurable* with that of languages. When studying programming languages, everything that matters is in the program code; when studying programming systems, everything that matters is in the *interaction* between the programmer and the system. As documented by Gabriel\ \parencite{PLrev}, looking at a *system* from a *language* perspective makes it impossible to think about concepts that arise from interaction with a system which are not reflected in the language.

# Contributions
While we do have new ideas to propose, our key contribution is integrating a wide range of existing concepts under a common umbrella. Our work is spread out across different domains, but each part connects to programming systems or focuses on a specific characteristic they may have.

We propose a common language as an initial step towards a more progressive research on programming systems. Our set of *technical dimensions* seeks to break down the holistic view of systems along various specific "axes". The dimensions identify a range of possible design choices, characterised by two extreme points in the design space. They are not quantitative, but they allow comparison by locating systems on a common axis. We do not intend for the extreme points to represent "good" or "bad" designs; we expect any position to be a result of design trade-offs. At this early stage in the life of such a framework, we encourage agreement on descriptions of systems first in order to settle any normative judgements later.

The set of dimensions can be understood as a map of the design space of programming systems. Past and present systems will serve as landmarks, and with enough of them, we may reveal unexplored or overlooked possibilities. In the absence of such a map, the field has not been able to establish a virtuous cycle of feedback; it is hard for practitioners to situate their work in the context of others' so that subsequent work can improve on it. Our aim is to provide foundations for the study of programming systems that would allow such development.

In this chapter, we develop *self-sustainability,* *notational freedom,* and *explicit structure* as Technical Dimensions, following on from the discussion in Section\ \ref{the-three-properties-in-more-detail}. For each one, we give examples that illustrate the range of values it spans. The rest can be found in Appendix\ \ref{appendix-all-dims}, organised into related clusters: *interaction*, *notation*, *conceptual structure*, *customisability*, *complexity*, *errors*, and *adoptability*.
\joel{
2. In Section\ \ref{evaluation}, we sketch two ways of using the framework. In Section\ \ref{evaluating-the-dark-programming-system}, we use it to evaluate a recent interesting programming system. In Section\ \ref{exploring-the-design-space}, we use it to make Section\ \ref{the-missing-synthesis}'s "missing synthesis" idea more precise by plotting the unexplored part of the design space. This will let us envision a potential novel programming system to be developed in Chapters\ \ref{the-state-first-approach-to-bootstraplab} and\ \ref{the-code-first-approach-to-bootstraplab}.

\begin{figure}
  \centering
  \includegraphics[width=0.6\linewidth]{plot-figure0.pdf}
  \caption{One 2-dimensional slice of the space of possible systems, to be examined in more detail in Section\ \ref{exploring-the-design-space}.\label{fig:tech-dims-diagram}}
\end{figure}
}

# Related work

While we do have new ideas to propose, part of our contribution is integrating a wide range of *existing* concepts under a common umbrella. This work is spread out across different domains, but each part connects to programming systems or focuses on a specific characteristic they may have.

\paragraph{From languages to systems.}
Our approach lies between a narrow focus on programming languages and a broad focus on programming as a socio-political and cultural subject. The concept of a programming system is technical in scope, although we acknowledge the technical side often has important social implications as in the case of the "Adoptability" dimension (Section\ \ref{adoptability}). This contrasts with the more socio-political focus found in Tchernavskij\ \parencite{TcherDiss} or in software studies\ \parencite{SwStudies}. It overlaps with Kell's conceptualisation of Unix, Smalltalk, and Operating Systems generally\ \parencite{Kell-OS}, and we have ensured that Unix has a place in our framework.

The distinction between more narrow _programming languages_ and broader _programming systems_ is more subtle. Richard Gabriel noted an invisible paradigm shift from the study of "systems" to the study of "languages" in computer science during the 1990s\ \parencite{PLrev}, and this observation informs our distinction here. One consequence of the change is that a *language* is often formally specified apart from any specific implementations, while *systems* resist formal specification and are often *defined by* an implementation. We recognise typical programming language implementations (\eg{} including an ordinary compiler and text editor) as a *small region* of the space of possible systems, at least as far as interaction and notations might go. Hence we refer to the *interactive programming system* aspects of languages, such as text editing and command-line workflow.

\paragraph{Programming systems research.}
There is renewed interest in programming systems in the form of recent non-traditional programming tools:

- Computational notebooks such as Jupyter\ \parencite{Jupyter} facilitate data analysis by combining code snippets with text and visual output, in a manner reminiscent of Literate Programming\ \parencite{LitProg}. They are backed by stateful "kernels" and used interactively.
- "Low code" end-user programming systems allow application development (mostly) through a GUI. One example is Coda\ \parencite{CodaWeb}, which combines tables, formulas, and scripts to enable non-technical people to build "applications as documents".
- Domain-specific programming systems such as Dark\ \parencite{DarkWeb}, which claims a "holistic" programming experience for cloud API services. This includes a language, a direct manipulation editor, and near-instantaneous building and deployment.
- Even for general purpose programming with conventional tools, systems like Replit\ \parencite{ReplitWeb} have demonstrated the benefits of integrating all needed languages, tools, and user interfaces into a seamless experience, available from the browser, that requires no setup.

Research that follows the programming systems perspective can be found in a number of research venues. Those include Human-Computer Interaction conferences such as [UIST](https://uist.acm.org/)^[ACM Symposium on User Interface Software and Technology] and [VL/HCC](https://conferences.computer.org/VLHCC/)^[IEEE Symposium on Visual Languages and Human-Centric Computing]. However, work in those often emphasises the user experience over technical description. Programming systems are often presented in workshops such as [LIVE](https://liveprog.org/) and [PX](https://2021.programming-conference.org/home/px-2021)^[Programming eXperience]. However, work in those venues is often limited to the authors' individual perspectives and suffers from the aforementioned difficulty of comparing to other systems.

Concrete examples of systems appear throughout the paper. Recent systems which motivated some of our dimensions include Subtext\ \parencite{Subtext}, which combines code with its live execution in a single editable representation; Sketch-n-sketch\ \parencite{SnS}, which can synthesise code by direct manipulation of its outputs; Hazel\ \parencite{Hazel}, a live functional programming environment with typed holes to enable execution of incomplete or ill-typed programs; and Webstrates\ \parencite{Webstrates}, which extends Web pages with real-time sharing of state.

\paragraph{Already-known characteristics.}
There are several existing projects identifying characteristics of programming systems. Some revolve around a single one, such as levels of liveness\ \parencite{Liveness}, or plurality and communicativity\ \parencite{Kell-C}. Others propose an entire collection. *Memory Models of Programming Languages*\ \parencite{Mem-mods} identifies the "everything is an X" metaphors underlying many programming systems; for example, the "everything is a file" of Unix and the "everything is an object" of Smalltalk. The *Design Principles of Smalltalk*\ \parencite{STdesign} documents the philosophical goals and dicta used in the design of Smalltalk; the "Gang of Four" *Design Patterns*\ \parencite{DesPats} catalogues specific implementation tactics; and the *Cognitive Dimensions of Notation*\ \parencite{CogDims} introduces a common vocabulary for software's *notational surface* and for identifying their trade-offs.

The latter two directly influence our proposal. Firstly, the Cognitive Dimensions are a set of qualitative properties which can be used to analyse *notations*. We are extending this approach to the "rest" of a system, beyond its notation, with *Technical* Dimensions. Secondly, our individual dimensions naturally fall under larger *clusters* that we present in a regular format, similar to the presentation of the classic Design Patterns. As for characteristics identified by others, part of our contribution is to integrate them under a common umbrella: the existing concepts of liveness, pluralism, and uniformity metaphors ("everything is an X") become dimensions in our framework.

\paragraph{Methodology.}
We follow the attitude of *Evaluating Programming Systems*\ \parencite{EvProgSys} in distinguishing our work from HCI methods and empirical evaluation. We are generally concerned with characteristics that are not obviously amenable to statistical analysis (\eg{} mining software repositories) or experimental methods like controlled user studies, so numerical quantities are generally not featured.

Similar development seems to be taking place in HCI research focused on user interfaces. The UIST guidelines\ \parencite{UISTAuthor} instruct authors to evaluate system contributions holistically, and the community has developed heuristics for such evaluation, such as *Evaluating User Interface Systems Research*\ \parencite{EvUISR}. Our set of dimensions offers similar heuristics for identifying interesting aspects of programming systems, though they focus more on underlying technical properties than the surface interface.

Finally, we believe that the aforementioned paradigm shift from programming systems to programming languages has hidden many ideas about programming that are worthwhile recovering and developing further\ \parencite{ComplementaryBasic}. Thus our approach is related to the idea of _complementary science_ developed by Chang\ \parencite{Chang} in the context of history and philosophy of science. Chang argues that even in disciplines like physics, superseded or falsified theories may still contain interesting ideas worth documenting. In the field of programming, where past systems are discarded for many reasons besides empirical failure, Chang's _complementary science_ approach seems particularly suitable.

\paragraph{Programming systems deserve a theory too!}
In short, while there is a theory for programming languages, programming *systems* deserve a theory too. It should apply from the the vast scale of operating systems to the comparatively small scale of language implementations. It should be possible to analyse the common and unique features of different systems, to reveal new possibilities, and to build on past work in an effective manner. In Kuhnian terms\ \parencite{Kuhn}, it should enable a body of "normal science": filling in the map of the space of possible systems \joel{(Figure \ref{fig:tech-dims-diagram})}, thereby forming a knowledge repository for future designers.

# Dimensions, Qualitative and Quantitative
There is a problem where the most easily *measurable* properties are not necessarily very interesting, while the interesting properties are not straightforwardly measurable. We have discussed our Three Properties intuitively and qualitatively in Chapters\ \ref{background} and\ \ref{analysis}. However, as they stand there is too much ambiguity for anything resembling an objective, plausible consensus on how much they are present in a given system. Therefore, in the next section we will break them down into narrower dimensions that we can apply for evaluating BootstrapLab. A few of these will be boolean (asking whether something is possible or present in a system) but most will be quantitative *penalty* dimensions. This means that maximising the value of one of our Three Properties (\eg{} Self-Sustainability) will correspond to *minimising* its constituent penalty dimensions.

## How We Define and Apply the Dimensions
We say a penalty dimension is "quantitative" in that its definition intuitively describes an amount of which there can be more or less, even if we leave the question of how to actually measure it numerically as future work. We do not have the scope to compare the various ways these quantities could be defined for measurement, and it would be misguided to pick one simply for the sake of having numbers. Where a relevant quantity does already exist (\eg{} lines of code) we may propose it as a measure for the dimension. Otherwise, we will use a variation on the Likert scale used in psychology\ \parencite{Likert}. Instead of "strongly agree" to "strongly disagree", we will assign the scores "minimal", "low", "moderate", "high" and "infinite".

With such a scale, it would be possible to rigorously measure a system against the dimensions by means of a questionnaire and analysing the distribution of responses (expecting consensus around a single score, and perhaps re-working the dimensions for which this is not the case). However, such an approach is beyond the scope of this work. Instead, when we apply these dimensions to evaluate BootstrapLab in Chapter\ \ref{bl}, we will give our own personal assessment of each score along with its justification. We think that the narrow focus of the dimensions makes it likely that such judgements would be aligned with those of the reader. Even in the case of serious disagreement, this narrow focus would make it easier to productively reach agreement in a way that would be much harder for the complex, qualitative definitions of the Three Properties from which they derive (Section\ \ref{the-three-properties-in-more-detail}). Therefore, while we agree that giving our personal assessment in terms of the Three Properties directly would be hard to judge objectively, we believe that doing so on the finer scale of the dimensions is appropriate. Further discussion of these issues and suggestions for future work will be found in Chapter\ \ref{future-work}.

## Aggregation and Simplification
It is worth noting that even once we have broken down a high-level concept into several low-level dimensions, the high-level concept can still be considered a *dimension* if we define some suitable aggregation of the scores of its constituent dimensions (this could be a simple sum, a weighted average, or something more sophisticated). We will not practice this, but it is worth keeping in mind as we encounter complications and decide how to respond to them.

For example, it might be objected that a dimension cannot simply apply to a system as a whole, but actually takes different scores for different parts of a system. We can answer this objection with an interpretation of the dimension as precisely such an aggregate of its application across different parts of the system. Ultimately, programming systems are complex and any property we speak of may apply at multiple levels. For practical purposes including those of our evaluation of BootstrapLab, we must make simplifications and apply our dimensions to an entire system as best we can.

# The Three Properties as Dimensions
We will now proceed to break down each of our Three Properties into dimensions (or, in the boolean case, "criteria", but we will stick to the general term).

## Dimensions Constituting Self-Sustainability
In light of the points in Section\ \ref{self-sustainability}, we can discover some key dimensions of self-sustainability with the help of an existing programming system that is not self-sustainable. Using the terminology from Section\ \ref{user-vs.-implementation-levels}, let us cast the *Web browser* as the *product system* (\ie{} that which we wish to make self-sustainable) and C++ as the *platform* (\ie{} the system we use to implement the product). What would it take to make the browser self-sustainable? 

### Minimise The Substrate Size
Recall from Section\ \ref{platforms-and-substrates} that the *substrate* is the portion of the product system not accessible from its user level. In the case of the web browser, it is the C++ code constituting its implementation. To get a self-sustainable system, the substrate must be minimised by shifting implementation out of it and into the programming capabilities of the product system. In this case, most of the named entities in the C++ code are stuck at the implementation level, inaccessible at the user level of JavaScript, so we must move the former into the latter.

To sketch how this process could be carried out systematically, we can begin with the graphical surface of the product system. For each graphical element, we inquire into the causes of its display; this will include graphical rendering code, but also the data that is being rendered and the code that generated it. By tracing backwards in this way we discover the web of causes that produced the shape on the screen. This will often go through the user level (JavaScript), but if we keep tracing back, we will hit the implementation level. Each time this happens, we port the code from the implementation level to the user level.

We continue this until it is no longer feasible; for example, there will ultimately have to be some native machine-code interpreter for JavaScript in the running system. In practice, there would need to be the usual investments in JIT compilation and optimisation technology as seen in VMs for Smalltalk and other languages.

These ideas suggest a dimension of *substrate size* as a penalty for self-sustainability. In other words, a self-sustainable system minimises this dimension. Later on, we will compare the strategies of doing this minimisation earlier or later in Section\ \ref{the-major-design-conflict}. A reasonable measure of substrate size does exist as the number of lines of code that implement it, so we will use this measure in our evaluations later. 

### Minimise Persistence Effort to Fix "Delete By Default"
As we discussed from Section\ \ref{assumptions-and-consequences-in-batch-mode} onward, the activities of a running process under Unix are considered disposable. In order for a system to be self-sustainable, it has to be able to preserve developments of its state through process termination. The standard VM solution is to have most of the system state saved in an "image" file and concentrate the substrate in a runnable binary that need not be changed. However this is accomplished, *persistence* of run-time changes is necessary to encourage indefinite evolution of the system. This applies to the whole browser, but could also be a concern for individual tabs or web pages that can be closed or refreshed.

This suggests another penalty dimension of *persistence effort.* To illustrate the range of values, we offer the following examples:

* Any system which automatically persists to an "image" (Lisp, Smalltalk) or otherwise (Webstrates\ \parencite{Webstrates}) causes *minimal* persistence effort on the part of the user (arguably zero, since the user does not have to think about it).
* A system with a manual "save" button that persists all state would have almost-minimal persistence effort. This comprises both the need to remember to save and the act of pressing the button.
* A system where one must repeat a manual procedure over different parts of the state to persist all of it would have *moderate* persistence effort.
* A typical programming language in a "vanilla" state (\eg{} excluding third-party libraries) has *high* persistence effort for its runtime data structures, owing to the "Delete By Default" policy of the Unix Paradigm (Section\ \ref{the-unix-paradigm}). With the use of a specific third-party library or framework (such as an Object-Relational Mapper) this persistence effort may be reduced. In the absence of such a system, the programmer would have a lot of work to do in order to persist all state (wrap every variable and stack frame in code for loading and saving its value).
* We could ascribe *infinite*^[Perhaps an infinite score could be interpreted as saying: it would take less effort to duplicate the source code of the system and add persistence at its implementation level, than it would to persist state using user-level functionality.] persistence effort where it is impossible to persist state. This is easier to imagine in the case of an end-user application with no scripting capability; if the developers failed to persist something (\eg{} the position or sizing of a window) then the user cannot do anything about it. In the case of a programming system, hard barriers to persistence include inaccessible state (\eg{} in JavaScript, one cannot refer to stack frames or obtain a JSON representation thereof) or a lack of enumerability (\eg{} there is no way to visit all objects in the system and thereby persist them).

It is true that this measure could be considered on a piecemeal basis *per piece of state* instead of on the system as a whole. For example, a system could have infinite persistence effort with respect to some state (\eg{} stack frames\ \parencite{Externalize}) but low persistence effort with respect to everything else (this being the effort invested to set up an Object-Relational Mapper for the rest of the state). As mentioned in Section\ \ref{aggregation-and-simplification}, given such a fine-grained application of this measure and a method of weighting each contribution, we could derive a convenient aggregate measure of persistence effort for the whole system. However, this is too complicated for the scope of our work here, so we will give an overall impression of the property without systematically going into finer detail.

### Support Code Viewing and Editing
The browser's JS console makes it technically possible to make arbitrary changes expressible as JS commands, and the source code can be viewed but not edited. We would need to make a small change so that the source code viewer could also be used to edit code in a persistent manner. This suggests boolean dimensions of *code viewing* and *code editing.* An example of a system that has both is Smalltalk with its class browser.

### Support the Manipulation of Code as Data
Once we can type text inside the system, we will be able to write code. However, this code will be inert unless the system can interpret data structures as programs and actually execute them. This is the case whether these data structures were created manually or by a program. If this is not possible, re-programming the system will not be possible (beyond selecting from a predefined list of behaviours). The browser does already satisfy this criterion since JS has an `eval()` function that can execute a string of JS code. This suggests a boolean dimension of *data execution.*

Any system with an `eval` function has this property, such as Lisp. In the low-level binary world (Section\ \ref{the-low-level-binary-world}) the fact that the *instruction pointer* can be pointed at bytes in memory and interpret them as instructions also qualifies. A negative example exists in a language like C, where there is no `eval` function. In such a case, one may employ the workaround of defining a mini-language (whether textual, or a binary bytecode) and an interpreter C function. It is important to be clear on which level the property would be thus established: what we called the *product system* (the program being implemented by the C code) would have data execution but the *platform* (the C language itself) would remain without it.

\joel{
1. *Can you add new items to system namespaces without a restart?* The canonical example of this is in JavaScript, where "built-in" classes like `Array` or `Object` can be augmented at will (and destructively modified, but that would be a separate point). Concretely, if a user wishes to make a new `sum` operation available to all Arrays, they are not *prevented* from straightforwardly adding the method to the Array prototype as if it were just an ordinary object (which it is). Having to re-compile or even restart the system would mean that this cannot be meaningfully achieved from within the system. Conversely, being able to do this means that even "built-in" namespaces are modifiable by ordinary programs, which indicates less of a implementation level vs. user level divide and seems important for self-sustainability.
2. *Can programs generate programs and execute them?* This property, related to "code as data" or the presence of an `eval()` function, is a key requirement of self-sustainability. Otherwise, re-programming the system, beyond selecting from a predefined list of behaviors, will require editing an external representation and restarting it. If users can type text inside the system then they will be able to write code---yet this code will be inert unless the system can interpret internal data structures as programs and actually execute them.
3. *Are changes persistent enough to encourage indefinite evolution?* If initial tinkering or later progress can be reset by accidentally closing a window, or preserved only through a convoluted process, then this discourages any long-term improvement of a system from within. For example, when developing a JavaScript application with web browser developer tools, it is possible to run arbitrary JavaScript in the console, yet these changes apply only to the running instance. After tinkering in the console with the advantage of concrete system state, one must still go back to the source code file and make the corresponding changes manually. When the page is refreshed to load the updated code, it starts from a fresh initial state. This means it is not worth using the *running* system for any programming beyond tinkering.
4. *Can you reprogram low-level infrastructure within the running system?* This is a hopefully faithful summary of how the COLAs work aims to go beyond Lisp and Smalltalk in this dimension.
5. *Can the user interface be arbitrarily changed from within the system?* Whether classed as "low-level infrastructure" or not, the visual and interactive aspects of a system are a significant part of it. As such, they need to be as open to re-programming as any other part of it to classify as truly self-sustainable.}

## Dimensions Constituting Notational Freedom
In Section\ \ref{notational-freedom} we mentioned the salient stages prior to notational freedom, namely syntactic and linguistic freedom. Recall that *syntactic* freedom involves specifying grammars for textual languages, while *linguistic* freedom adds custom layout, rendering and editing of textual symbols. In Section\ \ref{what-it-means-to-support-local-notations} we framed the issue as one of *removing* artificial barriers to using local notations, while respecting the essential complexity of implementing a notation itself. This suggests three penalty dimensions for the effort involved in using custom syntax, linguistic forms, and general graphical notations. One complication is that we defined these stages as successive generalisations, \ie{} notational freedom includes and implies linguistic freedom which includes syntactic freedom. It would not be very helpful to observe that a system has high syntactic freedom and then claim this gives it high linguistic freedom by virtue of the former being contained within the latter. That is not quite what we intend by the term "linguistic freedom". Instead, we would be concerned with linguistic freedom *above* the syntactic and notational freedom *above* the linguistic.

Therefore, our dimensions (all penalties) are as follows. They are minimised if a custom syntax, language, or notation can be "slotted in" once it exists, with no resistance from the system:

\paragraph{Custom Syntax Effort.} The work required to use a custom syntax, not counting that required to specify the syntax itself (\eg{} as a grammar). COLA\ \parencite{COLAs} and OMeta\ \parencite{OMeta} score low on this, since they are specifically designed for this purpose. Most programming languages have *infinite* custom syntax effort, because their parsers are separate programs that adhere to a fixed grammar that cannot be changed by statements in the language. This includes JavaScript despite its inclusion of a regex sub-syntax, HTML despite its inclusion of JavaScript and CSS, and C# despite its LINQ sub-language for queries; these examples may exhibit syntactic *diversity*, but there is no way to include a user-supplied syntax for use in the source code.

\paragraph{Custom Language Effort.} The work required to use custom language-like notation beyond syntax, not counting that required to implement the rendering and interaction. Most programming languages, COLA and OMeta get an infinite score here, while MPS\ \parencite{MPS} and Eco\ \parencite{Eco} score low.

\paragraph{Custom Notation Effort.} The work required to use custom graphical notation beyond what we called language in Section\ \ref{linguistic-freedom}, not counting that required to implement the rendering and interaction. Only Eco, owing to a screenshot showing inclusion of a picture, scores non-infinite on this dimension. From their discussion in Section\ 9.2 of the paper\ \parencite{Eco}, it is likely to score High or Moderate rather than Low because arbitrary graphical notations are a novel unexplored use case for the system.

\joel{
Consider the Web browser again; what would it take to achieve notational freedom in its JavaScript editor?

1. Again, we see that it does not yet satisfy the more modest condition of *syntactic freedom*. To achieve this, it would need to support *mood-specific languages* (see Section\ \ref{colas} below.) This means it would need some way of accepting user-supplied grammars (*Custom Grammars*) and some way of detecting which should be used for different parts of the source code (*Grammar Map.*) This latter task is made particularly troublesome because of a reliance on Implicit Structure (see Section\ \ref{explicit-structure}.)
2. *Even if* we get this syntactic freedom, we probably still have to force everything to fit in monospaced ASCII (or perhaps Unicode, as we see in the Nile/Gezira projects \parencite{Nile,Gezira}.) We still do not have full *linguistic freedom,* whereby we could, for example, render mathematics with the proper layout and formatting (as this does not quite fit into a horizontal list of non-overlapping characters.) This may require a leap from specifying grammars (which describe legal symbol sequences) to interfaces (how input causes shapes to appear, and how these are rendered.) Call these *Custom Interfaces* and *Interface Map.*
3. Once we have such infrastructure in place, it is not so small a step to generalise these interfaces to things that need not resemble a language (\eg{} a colour picker.) This gives us full *notational freedom.*

1. *Are there multiple syntaxes for textual notation?* Obviously, having more than one textual notation should count for notational diversity. However, for this dimension we want to take into account notations beyond the strictly textual, so we do not want this to be the only relevant question. Ideally, things should be weighted so that having a wide diversity of notations within some *narrow class* is not mistaken for notational diversity in a more global sense. We want to reflect that Unix, with its vast array of different languages for different situations, can never be as notationally diverse as a system with many languages *and* many graphical notations, for example.
2. *Does the system make use of GUI elements?* This is a focused class of non-textual notations that many of our example systems exhibit.
3. *Is it possible to view and edit data as tree structures?* Tree structures are extremely common in programming, but they are usually worked with as text in some way. A few of our examples provide a graphical notation for this common data structure, so this is one way they can be differentiated from the rest.
4. *Does the system allow freeform arrangement and sizing of data items?* We still felt Boxer and spreadsheets exhibited something not covered by the previous three questions, which is this. Within their respective constraints of rendering trees as nested boxes and single-level grids, they both provide for notational variation that can be useful to the user's context. These systems *could* have decided to keep boxes neatly placed or cells all the same size, but the fact that they allow these to vary scores an additional point for notational diversity.
}

## Dimensions Constituting Explicit Structure
The best way we have found to detect Explicit Structure is as a lack of Implicit Structure, which we break down into *producer* and *consumer* concerns. On the producer side, we have an editor with an interface creating and changing a data structure. This is saved and passed onto consumers, which can be collaborators using editors or a programmer writing code to use the data structure.

It is tempting to define Implicit Structure in terms of the producer's editing interface: a text editor has lots of it, while a structured or projectional editor lacks it. But this is incompatible with our desire for Notational Freedom; if someone wishes to use a text editor *interface* to type their data structures into existence, they should be free to do so.

Equally tempting is to locate Implicit Structure in the interchange file format, such as whether it is a text file. Yet as long as the system handles the loading and saving for this file format, it makes no difference from a consumer's point of view and they do not *experience* the downsides associated with Implicit Structure.

So if Implicit Structure is not about the interface, or how the data is really stored, what is it? The definition we are interested in is about how much users or programmers must be *aware* of it and devote cognitive resources to working with it. On the producer side, this manifests as which types of syntax errors or more general *format* errors they are able to save and pass on to consumers (Section\ \ref{precursors-of-explicit-structure}). On the consumer side, Implicit Structure is revealed by the amount of code we have to write to deal with parsing, serialising, escaping, loading and saving, and so on. Therefore we declare two penalty dimensions:

\paragraph{Format errors.} How many different types of format errors can be introduced, saved as invalid structures, and passed to consumers, such that they will halt with an error? For example, text editors allow all possible syntax errors to be saved and several format errors (\eg{} type mismatches and use of undeclared names). However, a text editor interface that refused to save invalid files could form part of a system with Explicit Structure. Block or structure editors may prevent all format errors from being saved, which would constitute the minimal value of this dimension.

\paragraph{String wrangling effort.} How much code has to be written to convert between implicit and explicit structure? Explicit Structure implies a minimal value for this and would look something like the following:

```
data = load('filename')
data.foo.bar = 'baz';
```

Here, there are zero lines of string wrangling. Only one line, translating between the filesystem and the internal system namespaces, is required to prepare the data structure for use.

If such a `load` function is already present, then users experience no string wrangling effort for the use cases of this function, \ie{} the file formats it supports. If the function does not exist, and a user must write string wrangling code on an ad-hoc basis, this dimension is correspondingly high relative to that format. Suppose the user factors this ad-hoc string wrangling into their own implementation of the `load` function; this implementation effort would count towards the dimension, but would pay for itself in the reduced string wrangling effort thereafter; this situation would lie somewhere between the previous two.

These considerations all establish scores for this dimension *relative* to a particular file format or string syntax. These could be aggregated to form a score for a particular program which uses several such formats. However, if we are trying to assess the *programming system* along this dimension, we would have to somehow aggregate across all possible programs one could create with the system, including the various different formats they are likely to include.^[There is a large variety of *existing* data storage formats (\eg{} JSON and XML) and an infinite variety of potential *custom* formats that could be created on an ad-hoc basis (\eg{} chat messages containing special escape sequences).]

Recognising that different programming systems are targeted at different goals and have differing strengths and weaknesses, the possibility space could be refined into all *likely* programs or use cases of the programming system, weighted by the probability of a user of the system wanting to create such a program. This opens up further decisions about this user and whether we should additionally aggregate across possible (or likely) users of the system. We could go further, but we think the complexity is clear; as mentioned in Section\ \ref{dimensions-qualitative-and-quantitative}, we will simply give our judgement about how BootstrapLab as a whole scores on this dimension and leave more sophisticated approaches to future work.

\joel{
How can we detect explicit structure in a programming system? Consider once again the Web browser. It has two major subdivisions of state: the DOM tree and the JavaScript object graph. For change, it only has those special JavaScript objects known as functions, worked on via the console and the source code view. We can examine these three areas separately:

\paragraph{DOM Tree.} The DOM tree is accessed manually through the Element Inspector and programmatically through JavaScript APIs, but is in both cases largely explicitly structured. The main exception involves the APIs taking HTML strings to create elements, and the initial stage of loading the HTML and JS source files. But once these structures have been recovered and built, much can take place without the intermediary of strings.

The other important exception to this occurs in SVG structures. SVG uses element *attributes* for composite data like matrix transformations, and hence has to store these as strings. For example, a node might have a `transform` of `translate(100,200)`. This means that, in order to move the element 10 units horizontally, the programmer must write code to extract the first co-ordinate as a number, add 10, and render the whole expression back to a string.

Related to attributes, CSS classes are a mixed case; on the one hand, the `style` attribute contains CSS source code, yet the JavaScript API does include properties for accessing this information explicitly.

\paragraph{JSOG.} The JavaScript object graph is also explicitly structured at runtime, while object definitions in the source code are obviously not.

\paragraph{JS Code.} Unlike the other two areas, JavaScript code is not explicitly structured even in the running system. There is a minimal level of structure: namely, the source file is split into Function objects (intervening lines with any side effects have already been executed and are inaccessible.) Beyond this, however, the body of each function is only accessible as a string. The obvious condition to meet here is that the AST should be navigable via some JavaScript API (*AST Access.*) Such a single level of explicit structure is shared with spreadsheets (where any structure within a cell is implicit) and databases (data within a column is implicitly structured.)

It appears that there are two realms in which explicit structure may be sought, corresponding to the Volatility Split: the contents of the source files vs. the content of the running system. Each of these could be further split between State and Change; in the Web browser, State largely has explicit structure in memory, but not on disk, and Change lacks it in both places.

\todo{Unix Files, spreadsheet, database}
}

\joel{
# Exploring the Design Space
Here, we use technical dimensions to identify a new unexplored point in the design space of programming systems and envision a new design that could emerge from the analysis.

With a little work, technical dimensions can let us see patterns or gaps in the design space by plotting their values on a simple scatterplot. Here, we will look at two dimensions, *notational diversity*^[This is simply the dimension we named as *uniformity of notations* (\ref{dimension-uniformity-of-notations}), but flipped in the opposite direction.] and *self-sustainability*, for the following programming systems: Haskell, Jupyter notebooks, Boxer, HyperCard, the Web, spreadsheets, Lisp, Smalltalk, UNIX, and COLAs.

While our choice to describe dimensions as qualitative concepts was necessary for coming up with them, *some* way of generating numbers is clearly necessary for visualizing their relationships like this. For simplicity,^[There are undoubtedly many ways to turn our descriptions into various measures, with strengths and weaknesses for different purposes, but this is beyond the scope of the present paper. Here, we merely wish to demonstrate that such a thing is possible and show what one can do with the results.] we adopt the following scheme. For each dimension, we distill the main idea into several yes/no questions (Appendix\ \ref{making-dimensions-quantitative}) that capture enough of the distinctions we observe between the systems we wish to plot. Then, for each system, we add up the number of "yes" answers and obtain a plausible score for the dimension.

\begin{figure}
  \centering
  \includegraphics[width=0.6\linewidth]{plot-figure0.pdf}
  \caption{Example programming systems (or system families) measured against \emph{self-sustainability} and \emph{notational diversity}, revealing an absence of systems with a high degree of both. \label{fig:design-space-plot}}
\end{figure}

Figure\ \ref{fig:design-space-plot} shows the results we obtained with our sets of questions. It shows that application-focused systems span a range of notational diversity, but only within fairly low self-sustainability. The "OS-likes" (Section \ref{os-like-programming-systems}) cluster in an "island" at the right, sharing identical notational diversity and near-identical self-sustainability. There is also a conspicuous blank space at the top-right, representing an unexplored combination of high values on both dimensions. With other pairs of dimensions, we might take this as evidence of an oppositional relationship, such that more of one inherently means less of the other (perhaps looking for a single new dimension that describes this better.) In this case, though, there is no obvious conflict between having many notations and being able to change a system from within. Therefore, we interpret the gap as a new opportunity to try out: combine the self-sustainability of COLAs with the notational diversity of Boxer and Web development. In fact, this is more or less the forthcoming dissertation of the primary author.
}

# Conclusions
There is a renewed interest in developing new programming systems. Such systems go beyond the simple model of code written in a programming language using a more or less sophisticated text editor. They combine textual and visual notations, create programs through rich graphical interactions, and challenge accepted assumptions about program editing, execution and debugging. Despite the growing number of novel programming systems, it remains difficult to evaluate the design of programming systems and see how they improve over work done in the past. To address the issue, we proposed a framework of “technical dimensions” that captures essential characteristics of programming systems in a qualitative but rigorous way.

The framework of technical dimensions puts the vast variety of programming systems, past and present, on a common footing of commensurability. This is crucial to enable the strengths of each to be identified and, if possible, combined by designers of the next generation of programming systems. As more and more systems are assessed in the framework, a picture of the space of possibilities will gradually emerge. Some regions will be conspicuously empty, indicating unrealized possibilities that could be worth trying. In this way, a domain of "normal science" is created for the design of programming systems.

Specifically for this dissertation, however, we can note the following: now that we have defined dimensions for our Three Properties, we can use these in the next two chapters to evaluate our prototype programming systems.
